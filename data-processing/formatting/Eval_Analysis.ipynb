{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json, os, sys, re, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2  \n",
    "from shutil import copy\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "\n",
    "def plot_hist(data, xlab, ylab, title, width, density=True):\n",
    "    plt.figure()\n",
    "    n, bins, patches = plt.hist(data, np.arange(0, max(data), width), density=density, facecolor='g', alpha=0.75)\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(np.arange(0, max(data), width))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print([int(x) for x in n])\n",
    "    print(patches, bins)\n",
    "    \n",
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "#     print(bb1,bb2)\n",
    "    assert bb1['x1'] <= bb1['x2']\n",
    "    assert bb1['y1'] <= bb1['y2']\n",
    "    assert bb2['x1'] <= bb2['x2']\n",
    "    assert bb2['y1'] <= bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou\n",
    "\n",
    "def findIOU(pred, truths):\n",
    "    if len(truths)==0:\n",
    "        return 0,None\n",
    "    ious = []\n",
    "    for truth in truths:\n",
    "        ious.append(get_iou(pred, truth))\n",
    "        \n",
    "    winner = max(ious)\n",
    "    if winner ==0:\n",
    "        return (0,None)\n",
    "    else:    \n",
    "        return (winner,ious.index(winner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion(papers,iou_thresh=0.5,score_thresh=0.8):\n",
    "    papers_df = pd.DataFrame()\n",
    "    '''\n",
    "    True Positive (TP): A correct detection. Detection with IOU â‰¥ threshold\n",
    "    False Positive (FP): A wrong detection. Detection with IOU < threshold\n",
    "    False Negative (FN): A ground truth not detected\n",
    "    '''\n",
    "    tp_total=0\n",
    "    fp_total=0\n",
    "    fn_total=0\n",
    "    \n",
    "    p_papers=[]\n",
    "    r_papers=[]\n",
    "    \n",
    "    \n",
    "    p_pages=[]\n",
    "    r_pages=[]\n",
    "    \n",
    "    \n",
    "    for paper in papers:\n",
    "        tp_paper = 0\n",
    "        fp_paper = 0\n",
    "        fn_paper = 0\n",
    "        \n",
    "        for page in papers[paper]['truth']:\n",
    "#             print(paper,page)\n",
    "            eqns_truth = [i for i,e in enumerate(papers[paper]['truth'][page])]\n",
    "            eqns_pred_o = [(i,e['iou'],e['eqn_idx'],e['score']) for i,e in enumerate(papers[paper]['preds'][page])]\n",
    "\n",
    "\n",
    "            # score_thresh\n",
    "            eqns_pred = [e for e in  eqns_pred_o if e[3]>score_thresh]\n",
    "\n",
    "            #TP, FP, FN\n",
    "            tp_temp = len([e for e in  eqns_pred if e[1]> iou_thresh])\n",
    "            tp_ids = list(set([e[2] for e in eqns_pred if e[1]> iou_thresh]))\n",
    "            fp_temp = len([e for e in  eqns_pred if e[1]<= iou_thresh])\n",
    "\n",
    "            if len(eqns_truth)==0:\n",
    "                fn_temp = 0\n",
    "            else:\n",
    "                fn_temp = len([e for e in eqns_truth if e not in tp_ids])\n",
    "\n",
    "            tp_total+=tp_temp\n",
    "            fp_total+=fp_temp\n",
    "            fn_total+=fn_temp\n",
    "            \n",
    "            tp_paper+=tp_temp\n",
    "            fp_paper+=fp_temp\n",
    "            fn_paper+=fn_temp\n",
    "            \n",
    "            if tp_temp + fp_temp ==0:\n",
    "                p_pages.append(1)\n",
    "            else:\n",
    "                p_pages.append(tp_temp/(tp_temp + fp_temp))\n",
    "            \n",
    "            if tp_temp + fn_temp ==0:\n",
    "                r_pages.append(1)\n",
    "            else:\n",
    "                r_pages.append(tp_temp/(tp_temp + fn_temp))\n",
    "            papers_df = papers_df.append({'paper':paper,'page':page,'total_truth':len(eqns_truth)\\\n",
    "                                         ,'total_pred':len(eqns_pred_o),'total_pred_thresh':len(eqns_pred)\\\n",
    "                                          ,'tp':tp_temp,'fp':fp_temp,'fn':fn_temp}, ignore_index=True)\n",
    "                \n",
    "        if tp_paper + fp_paper ==0:\n",
    "            p_papers.append(1)\n",
    "        else:\n",
    "            p_papers.append(tp_paper/(tp_paper + fp_paper))\n",
    "\n",
    "        if tp_paper + fn_paper ==0:\n",
    "            r_papers.append(1)\n",
    "        else:\n",
    "            r_papers.append(tp_paper/(tp_paper + fn_paper))\n",
    "\n",
    "#             print(eqns_truth, eqns_pred)\n",
    "#             print(tp_temp, fp_temp, fn_temp)\n",
    "        \n",
    "#         break\n",
    "    if tp_total+fp_total==0:\n",
    "        p = 1\n",
    "    else:\n",
    "        p = tp_total/(tp_total+fp_total)\n",
    "    if tp_total+fn_total==0:\n",
    "        r = 1\n",
    "    else:\n",
    "        r = tp_total/(tp_total+fn_total)\n",
    "    \n",
    "    return p,r,p_papers, r_papers, p_pages, r_pages, papers_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_statistics(path, valid_bbs, predictions):\n",
    "    papers = {}\n",
    "    i = 0\n",
    "    for paper_page in valid_bbs:\n",
    "        paper = paper_page.split('-')[0]\n",
    "        page = f\"page-{paper_page.replace('.png','').split('-')[-1]}\"\n",
    "        if paper in papers:\n",
    "            papers[paper]['pages_count'] +=1\n",
    "\n",
    "        else:\n",
    "            papers[paper]={}\n",
    "            papers[paper]['pages_count']=0\n",
    "            papers[paper]['truth'] = {}\n",
    "            papers[paper]['preds'] = {}\n",
    "\n",
    "        temp_papers = []\n",
    "        for region in valid_bbs[paper_page]['regions']:\n",
    "            temp = valid_bbs[paper_page]['regions'][region]\n",
    "            x2 = temp['shape_attributes']['all_points_x'][2]\n",
    "            x1 = temp['shape_attributes']['all_points_x'][0]\n",
    "            width = x2-x1\n",
    "\n",
    "            y2 = temp['shape_attributes']['all_points_y'][1]\n",
    "            y1 = temp['shape_attributes']['all_points_y'][0]\n",
    "            height = y2-y1\n",
    "\n",
    "            temp_papers.append({'width' : width, 'height' : height, 'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2})\n",
    "\n",
    "        temp_papers = [dict(y) for y in set(tuple(x.items()) for x in temp_papers)]\n",
    "\n",
    "        papers[paper]['truth'][page] = temp_papers\n",
    "\n",
    "    for paper_page in predictions:\n",
    "        paper = paper_page.split('/')[-1].split('-')[0]\n",
    "        page = f\"page-{paper_page.split('/')[-1].replace('.png','').split('-')[-1]}\"\n",
    "    #     img_path= path+'val/'+paper_page.split('/')[-1]\n",
    "    #     print(img_path)\n",
    "    #     img = cv2.imread(img_path)\n",
    "\n",
    "    #     print(f\"{paper}-{page}\")\n",
    "        if paper in papers:\n",
    "            temp_papers = []\n",
    "            for i in range(len(predictions[paper_page]['pred_boxes'])):\n",
    "                temp = predictions[paper_page]['pred_boxes'][i]\n",
    "                score = predictions[paper_page]['scores'][i]\n",
    "                x1,y1,x2,y2 = temp\n",
    "                x1=int(x1)\n",
    "                x2=int(x2)\n",
    "                y1=int(y1)\n",
    "                y2=int(y2)\n",
    "\n",
    "                width = x2-x1\n",
    "                height = y2-y1\n",
    "\n",
    "                temp_papers.append({'width' : width, 'height' : height, 'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2, 'score' : score})\n",
    "\n",
    "\n",
    "                papers[paper]['preds'][page] = temp_papers\n",
    "\n",
    "        else:\n",
    "            print(\"Not found\",paper)\n",
    "            \n",
    "    \n",
    "    \n",
    "    os.makedirs(os.path.dirname(path+'eval_analysis/'), exist_ok=True)\n",
    "    ious = []\n",
    "    for paper in papers:\n",
    "#         print(paper)\n",
    "        for page in papers[paper]['truth']:\n",
    "    #         print(page, len(papers[paper]['truth'][page]))\n",
    "            img_path = path+'val/'+paper+'-'+page+'.png'\n",
    "            img = cv2.imread(img_path)\n",
    "            truths = papers[paper]['truth'][page]\n",
    "            if page in papers[paper]['preds']:\n",
    "                preds = papers[paper]['preds'][page]\n",
    "            else:\n",
    "                papers[paper]['preds'][page] = []\n",
    "                preds = []\n",
    "            cv2.putText(img,'Truth : '+str(len(truths)) + 'Eqns',(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1)\n",
    "            cv2.putText(img,'Preds : '+str(len(preds)) + 'Eqns',(10,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),1)\n",
    "\n",
    "            for t,truth in enumerate(truths):\n",
    "    #             print(truths)\n",
    "                cv2.rectangle(img,(truth[\"x1\"],truth[\"y1\"]),(truth[\"x2\"],truth[\"y2\"]),(0,0,255),1)\n",
    "    #             cv2.putText(img,'Truth : '+str(t),(truth['x2'],truth['y2']),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,255),1)\n",
    "\n",
    "            for p,pred in enumerate(preds):\n",
    "                cv2.rectangle(img,(pred[\"x1\"],pred[\"y1\"]),(pred[\"x2\"],pred[\"y2\"]),(255,0,0),1)\n",
    "                iou, idx = findIOU(pred, truths)\n",
    "                papers[paper]['preds'][page][p]['iou'] = iou\n",
    "                ious.append(iou)\n",
    "                papers[paper]['preds'][page][p]['eqn_idx'] = idx\n",
    "                cv2.putText(img,'S:'+ str(round(pred['score']*100,2))+'%, IOU:'+str(round(iou,2)),(pred['x2']+5,pred['y2']),cv2.FONT_HERSHEY_SIMPLEX,0.35,(255,0,0),1)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imwrite(path+'eval_analysis/'+paper+'-'+page+'.png', img)\n",
    "        \n",
    "    return papers, ious\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_iou_hist(ious):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=ious,bingroup=1,name=\"ious\"))\n",
    "\n",
    "    # Overlay both histograms\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    # Reduce opacity to see both histograms\n",
    "    fig.update_traces(opacity=0.65)\n",
    "    fig.update_layout(\n",
    "        title_x=0.5,\n",
    "        title_text='Histograms of IOUs', # title of plot\n",
    "        xaxis_title_text='IOUs', # xaxis label\n",
    "        yaxis_title_text='Counts', # yaxis label\n",
    "        bargap=0, # gap between bars of adjacent location coordinates\n",
    "        bargroupgap=0.1 # gap between bars of the same location coordinates\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(papers):\n",
    "    ps = []\n",
    "    rs = []\n",
    "    for i in np.arange(0,1,0.05):\n",
    "        p_t = []\n",
    "        r_t = []\n",
    "        for j in np.arange(0,1,0.05):\n",
    "            p,r,p_papers, r_papers, p_pages, r_pages,_ = get_confusion(papers, i,j)\n",
    "            p_t.append(p)\n",
    "            r_t.append(r)\n",
    "        ps.append(p_t)\n",
    "        rs.append(r_t)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2,subplot_titles=('Precision', 'Recall'))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Contour(\n",
    "            z=ps,\n",
    "            x=np.arange(0,1,0.05),\n",
    "            y=np.arange(0,1,0.05),\n",
    "            contours=dict(\n",
    "                start=0,\n",
    "                end=0.8,\n",
    "                size=0.05,\n",
    "                showlabels = True, # show labels on contours\n",
    "                labelfont = dict( # label font properties\n",
    "                    size = 12,\n",
    "                    color = 'white',\n",
    "                )\n",
    "            ),\n",
    "\n",
    "        ),\n",
    "     row=1, col=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Contour(\n",
    "            z=rs,\n",
    "            x=np.arange(0,1,0.05),\n",
    "            y=np.arange(0,1,0.05),\n",
    "            contours=dict(\n",
    "                start=0,\n",
    "                end=0.8,\n",
    "                size=0.05,\n",
    "                showlabels = True, # show labels on contours\n",
    "                labelfont = dict( # label font properties\n",
    "                    size = 12,\n",
    "                    color = 'white',\n",
    "                )\n",
    "            ),\n",
    "\n",
    "        ),\n",
    "     row=1, col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"BB Score\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"BB Score\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"IOU\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"IOU\", row=1, col=2)\n",
    "\n",
    "    fig.update_layout(height=600, width=1000, title_text=\"Precision/Recall vs IOU vs Scores\", title_x=0.5)\n",
    "\n",
    "    fig.show(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_r(papers, iou_thresh, score_thresh):\n",
    "    p,r,p_papers, r_papers, p_pages, r_pages,_ = get_confusion(papers,iou_thresh, score_thresh)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=p_papers,name=\"Precision-Papers\",histnorm='percent',nbinsx=10,autobinx=False))\n",
    "    fig.add_trace(go.Histogram(x=r_papers,name=\"Recall-Papers\",histnorm='percent',nbinsx=10,autobinx=False))\n",
    "\n",
    "    # Overlay both histograms\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    # Reduce opacity to see both histograms\n",
    "    fig.update_traces(opacity=0.5)\n",
    "    fig.update_layout(\n",
    "        title_x=0.5,\n",
    "        title_text='Histograms of Paper-wise recall and precision', # title of plot\n",
    "        xaxis_title_text='P/R', # xaxis label\n",
    "        yaxis_title_text='Percent Papers', # yaxis label\n",
    "        bargap=0, # gap between bars of adjacent location coordinates\n",
    "        bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=p_pages,bingroup=1,name=\"Precision-Pages\",histnorm='percent'))\n",
    "    fig.add_trace(go.Histogram(x=r_pages,bingroup=1,name=\"Recall-Pages\",histnorm='percent'))\n",
    "\n",
    "    # Overlay both histograms\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    # Reduce opacity to see both histograms\n",
    "    fig.update_traces(opacity=0.5)\n",
    "    fig.update_layout(\n",
    "        title_text='Histograms of Page-wise recall and precision', # title of plot\n",
    "        title_x=0.5,\n",
    "        xaxis_title_text='P/R', # xaxis label\n",
    "        yaxis_title_text='Percent Pages', # yaxis label\n",
    "        bargap=0, # gap between bars of adjacent location coordinates\n",
    "        bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "        xaxis = dict(\n",
    "            dtick = 0.1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show(\"notebook\")\n",
    "    \n",
    "    print(f\"Over All Stats - Precision : {p}, Recall : {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr00025_e1000_b128.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr00025_e1000_b256.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr00025_e1000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr0005_e1000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr001_e1000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr002_e1000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr005_e1000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr001_e3000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "plot_iou_hist(ious)\n",
    "plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/CNNTest2/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_lr001_e5000_b512.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "# plot_iou_hist(ious)\n",
    "# plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,r,p_papers, r_papers, p_pages, r_pages,papers_df = get_confusion(papers,0.5, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{(papers_df[papers_df['total_truth']>0].shape[0]/papers_df.shape[0]) * 100} % of all papers have at least one eqn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.sum().tp/(papers_df.sum().tp+papers_df.sum().fp),papers_df.sum().tp/(papers_df.sum().tp+papers_df.sum().fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df[papers_df['total_truth']>0].sum().tp/(papers_df[papers_df['total_truth']>0].sum().tp+papers_df[papers_df['total_truth']>0].sum().fp),papers_df[papers_df['total_truth']>0].sum().tp/(papers_df[papers_df['total_truth']>0].sum().tp+papers_df[papers_df['total_truth']>0].sum().fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df[(papers_df['total_truth']==0)].sort_values('total_pred_thresh',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df[(papers_df['total_truth']>0)].sort_values('fn',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df[(papers_df['total_truth']>0)].sort_values('fp',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '../data/large/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "# plot_iou_hist(ious)\n",
    "# plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/large/'\n",
    "valid_bbs = json.load(open(path+'val/bounding_box_data.json','r'))\n",
    "predictions = json.load(open(path+'pred_results_longer.json','r'))\n",
    "papers, ious = paper_statistics(path, valid_bbs, predictions)\n",
    "# plot_iou_hist(ious)\n",
    "# plot_heatmap(papers)\n",
    "plot_p_r(papers, iou_thresh=0.5, score_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
