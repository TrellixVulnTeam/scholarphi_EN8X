[
  {
    "id": "3",
    "type": "experience",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.806723,
          "top": 0.2,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "experience_id": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "urls": ["Medline"],
      "snippets": ["Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus.Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus.Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus.Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus.Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus.Lupus is an autoimmune disease. This means that your immune system attacks healthy cells and tissues by mistake. This can damage many parts of the body, including the joints, skin, kidneys, heart, lungs, blood vessels, and brain. Anyone can get lupus, but women are most at risk. Lupus is two to three times more common in African American women than in white women. It's also more common in Hispanic, Asian, and Native American women. African American and Hispanic women are more likely to have severe forms of lupus."],
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {}
  },
  {
    "id": "1243",
    "type": "experience",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.272,
          "top": 0.325,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "experience_id": "g2bb938daf8972ac309c25dab900a79070e1917c",
      "urls": ["Medline"],
      "snippets": ["Anti-double stranded DNA (Anti-dsDNA) antibodies are a group of anti-nuclear antibodies (ANA) the target antigen of which is double stranded DNA. Presence of anti-dsDNA antibodies are suggestive of SLE, however an absence of the antibodies does not rule out the disease. The levels of circulating anti-dsDNA antibodies fluctuate with disease activity in SLE. Increases in titres of the antibodies can coincide with, or even precede an increase of disease activity."],
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {}
  },
  {
    "id": "13",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.5,
          "top": 0.5,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test Answer Sentence",
      "text": "This is Test Questions's text answer",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "tex_start": 0,
      "tex_end": 5,
      "source": "tex-pipeline",
      "tags": []
    }
  },
  {
    "id": "14",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.2,
          "top": 0.2,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test Answer 2 Sentence",
      "text": "This is Test Questions's text answer v2",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "tex_start": 0,
      "tex_end": 5,
      "source": "tex-pipeline",
      "tags": []
    }
  },
  {
    "id": "11",
    "type": "question",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.7,
          "top": 0.2,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test Question",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "question_text": "What condition does this paper study?",
      "answer_text": "This paper studies new treaments for Systemic Lupus Erythematosus (SLE).",
      "definitions": ["This is the first answering sentence to the question"],
      "definition_texs": ["This is the answering text that gets rendered in the sidebar"],
      "sources": ["sources"],
      "snippets": ["This is the snippet of the answering sentence", "Second Snippet"],
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {
      "sentence": {"type":"none", "id":"5"},
      "definition_sentences": [{"type":"sentence", "id":"13"}, {"type":"sentence", "id":"14"}],
      "snippet_sentences": [{"type":"sentence", "id":"13"}, {"type":"sentence", "id":"14"}]
    }
  },
  {
    "id": "234",
    "type": "question",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.7,
          "top": 0.2,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test Question 2",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "question_text": "How is the condition usually treated?",
      "answer_text": "This paper studies new treaments for Systemic Lupus Erythematosus (SLE).",
      "definitions": ["This is the first answering sentence to the question"],
      "definition_texs": ["This is the answering text that gets rendered in the sidebar"],
      "sources": ["sources"],
      "snippets": ["This is the snippet of the answering sentence", "Second Snippet"],
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {
      "sentence": {"type":"none", "id":"5"},
      "definition_sentences": [{"type":"sentence", "id":"3096855"}],
      "snippet_sentences": [{"type":"sentence", "id":"3096855"}]
    }
  },

  {
    "id": "1",
    "type": "term",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.5,
          "top": 0.23,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "term_type": "Test",
      "definitions": ["Definitions"],
      "definition_texs": ["This is the definition text that gets rendered in the sidebar"],
      "sources": ["sources"],
      "snippets": ["This is the snipper sentence"],
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {
      "sentence": {"type":"None", "id":"5"},
      "definition_sentences": [{"type":"sentence", "id":"12"}],
      "snippet_sentences": [{"type":"sentence", "id":"12"}]
    }
  },
  {
    "id": "12",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.5,
          "top": 0.5,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "name":"Test Sentence",
      "text": "This is Test's text",
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "tex_start": 0,
      "tex_end": 5,
      "source": "tex-pipeline",
      "tags": []
    }
  },
  {
    "id": "2",
    "type": "symbol",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.5,
          "top": 0.285036,
          "width": 0.0756303,
          "height": 0.00950119
        }
      ],
      "tex": "f2bb938daf8972ac309c25dab900a79070e1917c",
      "type": "identifier",
      "mathml": "mathml",
      "mathml_near_matches": [],
      "is_definition": true,
      "diagram_label": null,
      "nicknames": [],
      "definitions": [],
      "defining_formulas": [],
      "passages": [],
      "snippets": "snippets",
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {
      "sentence": {"type":"None", "id":"None"},
      "parent": {"type":"None", "id":"None"},
      "children": [{"type":"None", "id":"None"}],
      "equation": {"type":"None", "id":"None"},
      "nickname_sentences": [],
      "definition_sentences": [],
      "defining_formula_equations": [],
      "snippet_sentences": []
    }
  },
  {
    "id": "3090838",
    "type": "citation",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.29916,
          "top": 0.619952,
          "width": 0.176471,
          "height": 0.00950119
        }
      ],
      "paper_id": "9405d0388f90ba1432ef13c21309d8363860e22e",
      "source": "tex-pipeline",
      "tags": []
    },
    "relationships": {}
  },
  {
    "id": "3096855",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.280672,
          "top": 0.171021,
          "width": 0.448739,
          "height": 0.0142518
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\{strubell, pat, mccallum\\}@cs.umass.edu",
      "tex_start": 1465,
      "tex_end": 1505,
      "text": "\\{strubell, pat, mccallum\\}@cs.umass.edu"
    },
    "relationships": {}
  },
  {
    "id": "3096856",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.415126,
          "top": 0.186461,
          "width": 0.178151,
          "height": 0.0154394
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "$^2$Google AI Language",
      "tex_start": 1512,
      "tex_end": 1534,
      "text": "EQUATION_DEPTH_0_START ^2 EQUATION_DEPTH_0_END Google AI Language"
    },
    "relationships": {}
  },
  {
    "id": "3096857",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.445378,
          "top": 0.205463,
          "width": 0.117647,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "New York, NY",
      "tex_start": 1540,
      "tex_end": 1552,
      "text": "New York, NY"
    },
    "relationships": {}
  },
  {
    "id": "3096858",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.347899,
          "top": 0.220903,
          "width": 0.315966,
          "height": 0.0142518
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\{andor, djweiss\\}@google.com",
      "tex_start": 1562,
      "tex_end": 1591,
      "text": "\\{andor, djweiss\\}@google.com"
    },
    "relationships": {}
  },
  {
    "id": "3096859",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.319477,
          "width": 0.184874,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.305226,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.290974,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Current state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features.",
      "tex_start": 1649,
      "tex_end": 1767,
      "text": "Current state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features."
    },
    "relationships": {}
  },
  {
    "id": "3096860",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.375297,
          "width": 0.176471,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.361045,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.347981,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.333729,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.352941,
          "top": 0.319477,
          "width": 0.105882,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax.",
      "tex_start": 1769,
      "tex_end": 1943,
      "text": "However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax."
    },
    "relationships": {}
  },
  {
    "id": "3096861",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.446556,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.432304,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.418052,
          "width": 0.305882,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.4038,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.389549,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.342857,
          "top": 0.375297,
          "width": 0.115966,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL.",
      "tex_start": 1944,
      "tex_end": 2183,
      "text": "In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL."
    },
    "relationships": {}
  },
  {
    "id": "3096862",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.546318,
          "width": 0.154622,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.532067,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.517815,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.503563,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.489311,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.475059,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.460808,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates.",
      "tex_start": 2185,
      "tex_end": 2467,
      "text": "Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates."
    },
    "relationships": {}
  },
  {
    "id": "3096863",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.574822,
          "width": 0.25042,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.56057,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.32605,
          "top": 0.546318,
          "width": 0.132773,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Syntax is incorporated by training one attention head to attend to syntactic parents for each token.",
      "tex_start": 2468,
      "tex_end": 2568,
      "text": "Syntax is incorporated by training one attention head to attend to syntactic parents for each token."
    },
    "relationships": {}
  },
  {
    "id": "3096864",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.617577,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.603325,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.589074,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.416807,
          "top": 0.574822,
          "width": 0.0420168,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model.",
      "tex_start": 2569,
      "tex_end": 2714,
      "text": "Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model."
    },
    "relationships": {}
  },
  {
    "id": "3096865",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.732779,
          "width": 0.0201681,
          "height": 0.00593824
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.716152,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.7019,
          "width": 0.309244,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.687648,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.674584,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.660333,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.646081,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.631829,
          "width": 0.307563,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10\\% reduction in error.",
      "tex_start": 2715,
      "tex_end": 3020,
      "text": "In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10\\% reduction in error."
    },
    "relationships": {}
  },
  {
    "id": "3096866",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.744656,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.186555,
          "top": 0.730404,
          "width": 0.272269,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1.",
      "tex_start": 3021,
      "tex_end": 3095,
      "text": "On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1."
    },
    "relationships": {}
  },
  {
    "id": "3096867",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.801663,
          "width": 0.267227,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.787411,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.151261,
          "top": 0.773159,
          "width": 0.307563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.14958,
          "top": 0.758907,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.",
      "tex_start": 3096,
      "tex_end": 3263,
      "text": "LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text."
    },
    "relationships": {}
  },
  {
    "id": "3096868",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.12437,
          "top": 0.839667,
          "width": 0.134454,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\section{Introduction}\n",
      "tex_start": 3278,
      "tex_end": 3303,
      "text": "Introduction."
    },
    "relationships": {}
  },
  {
    "id": "3096869",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.122689,
          "top": 0.882423,
          "width": 0.242017,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.122689,
          "top": 0.849169,
          "width": 0.363025,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Semantic role labeling (SRL) extracts a high-level representation of meaning from a sentence, labeling e.g.\\ \\emph{who} did \\emph{what} to \\emph{whom}.",
      "tex_start": 3303,
      "tex_end": 3454,
      "text": "Semantic role labeling (SRL) extracts a high-level representation of meaning from a sentence, labeling e.g. who did what to whom."
    },
    "relationships": {}
  },
  {
    "id": "3096870",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.122689,
          "top": 0.897862,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.379832,
          "top": 0.882423,
          "width": 0.107563,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.598319,
          "top": 0.334917,
          "width": 0.27563,
          "height": 0.00950119
        },
        {
          "page": 0,
          "left": 0.552941,
          "top": 0.317102,
          "width": 0.304202,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.554622,
          "top": 0.301663,
          "width": 0.278992,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.285036,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.269596,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Explicit representations of such semantic information have been shown to improve results in challenging downstream tasks such as dialog systems \\citep{tur2005semi,chen2013unsupervised}, machine reading \\citep{berant2014modeling, wang2015machine} and translation \\citep{liu2010semantic,bazrafshan2013semantic}.",
      "tex_start": 3455,
      "tex_end": 3764,
      "text": "Explicit representations of such semantic information have been shown to improve results in challenging downstream tasks such as dialog systems Citation (tur2005semi,chen2013unsupervised), machine reading Citation (berant2014modeling, wang2015machine) and translation Citation (liu2010semantic,bazrafshan2013semantic)."
    },
    "relationships": {}
  },
  {
    "id": "3096871",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.463183,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.586555,
          "top": 0.446556,
          "width": 0.295798,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.594958,
          "top": 0.438242,
          "width": 0.285714,
          "height": 0.0023753
        },
        {
          "page": 0,
          "left": 0.640336,
          "top": 0.433492,
          "width": 0.240336,
          "height": 0.00118765
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.414489,
          "width": 0.287395,
          "height": 0.00950119
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.39905,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.626891,
          "top": 0.382423,
          "width": 0.255462,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.365796,
          "width": 0.32437,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.534454,
          "top": 0.350356,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Though syntax was long considered an obvious prerequisite for SRL systems \\citep{levin1993english,punyakanok2008importance}, recently deep neural network architectures have surpassed syntactically-informed models \\citep{zhou2015end, marcheggiani2017simple, he2017deep, tan2018deep, he2018jointly}, achieving state-of-the art SRL performance with no explicit modeling of syntax.",
      "tex_start": 3767,
      "tex_end": 4144,
      "text": "Though syntax was long considered an obvious prerequisite for SRL systems Citation (levin1993english,punyakanok2008importance), recently deep neural network architectures have surpassed syntactically-informed models Citation (zhou2015end, marcheggiani2017simple, he2017deep, tan2018deep, he2018jointly), achieving state-of-the art SRL performance with no explicit modeling of syntax."
    },
    "relationships": {}
  },
  {
    "id": "3096872",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.542755,
          "width": 0.210084,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.527316,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.510689,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.495249,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.478622,
          "width": 0.364706,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "An additional benefit of these end-to-end models is that they require just raw tokens and (usually) detected predicates as input, whereas richer linguistic features typically require extraction by an auxiliary pipeline of models.",
      "tex_start": 4146,
      "tex_end": 4375,
      "text": "An additional benefit of these end-to-end models is that they require just raw tokens and (usually) detected predicates as input, whereas richer linguistic features typically require extraction by an auxiliary pipeline of models."
    },
    "relationships": {}
  },
  {
    "id": "3096873",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.624703,
          "width": 0.240336,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.608076,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.592637,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.554622,
          "top": 0.57601,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.536134,
          "top": 0.56057,
          "width": 0.317647,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Still, recent work \\citep{roth2016neural,he2017deep,marcheggiani2017encoding} indicates that neural network models could see even higher accuracy gains by leveraging syntactic information rather than ignoring it.",
      "tex_start": 4377,
      "tex_end": 4589,
      "text": "Still, recent work Citation (roth2016neural,he2017deep,marcheggiani2017encoding) indicates that neural network models could see even higher accuracy gains by leveraging syntactic information rather than ignoring it."
    },
    "relationships": {}
  },
  {
    "id": "3096874",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.752969,
          "width": 0.12437,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.73753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.720903,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.704276,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.688836,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.672209,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.65677,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.640143,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.835294,
          "top": 0.624703,
          "width": 0.0470588,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2017deep} indicate that many of the errors made by a syntax-free neural network on SRL are tied to certain syntactic confusions such as prepositional phrase attachment, and show that while constrained inference using a relatively low-accuracy predicted parse can provide small improvements in SRL accuracy, providing a gold-quality parse leads to substantial gains.",
      "tex_start": 4590,
      "tex_end": 4964,
      "text": "Citation (he2017deep) indicate that many of the errors made by a syntax-free neural network on SRL are tied to certain syntactic confusions such as prepositional phrase attachment, and show that while constrained inference using a relatively low-accuracy predicted parse can provide small improvements in SRL accuracy, providing a gold-quality parse leads to substantial gains."
    },
    "relationships": {}
  },
  {
    "id": "3096875",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.865796,
          "width": 0.223529,
          "height": 0.00831354
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.849169,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.833729,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.552941,
          "top": 0.817102,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.801663,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.785036,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.517647,
          "top": 0.769596,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.835294,
          "top": 0.752969,
          "width": 0.0470588,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{marcheggiani2017encoding} incorporate syntax from a high-quality parser \\citep{kiperwasser2016simple} using graph convolutional neural networks \\citep{kipf2017semi}, but like \\citet{he2017deep} they attain only small increases over a model with no syntactic parse, and even perform worse than a syntax-free model on out-of-domain data.",
      "tex_start": 4965,
      "tex_end": 5307,
      "text": "Citation (marcheggiani2017encoding) incorporate syntax from a high-quality parser Citation (kiperwasser2016simple) using graph convolutional neural networks Citation (kipf2017semi), but like Citation (he2017deep) they attain only small increases over a model with no syntactic parse, and even perform worse than a syntax-free model on out-of-domain data."
    },
    "relationships": {}
  },
  {
    "id": "3096876",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.897862,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.515966,
          "top": 0.882423,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 0,
          "left": 0.751261,
          "top": 0.865796,
          "width": 0.131092,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.0950119,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "These works suggest that though syntax has the potential to improve neural network SRL models, we have not yet designed an architecture which maximizes the benefits of auxiliary syntactic information.",
      "tex_start": 5308,
      "tex_end": 5508,
      "text": "These works suggest that though syntax has the potential to improve neural network SRL models, we have not yet designed an architecture which maximizes the benefits of auxiliary syntactic information."
    },
    "relationships": {}
  },
  {
    "id": "3096877",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.226841,
          "width": 0.294118,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.211401,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.194774,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.157983,
          "top": 0.179335,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.162708,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.147268,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.130641,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.141176,
          "top": 0.115202,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In response, we propose \\emph{linguistically-informed self-attention} (LISA): a model that combines multi-task learning \\citep{caruana1993multitask} with stacked layers of multi-head self-attention \\citep{vaswani2017attention}; the model is trained to: (1) jointly predict parts of speech and predicates; (2) perform parsing; and (3) attend to syntactic parse parents, while (4) assigning semantic role labels.",
      "tex_start": 5511,
      "tex_end": 5921,
      "text": "In response, we propose linguistically-informed self-attention (LISA): a model that combines multi-task learning Citation (caruana1993multitask) with stacked layers of multi-head self-attention Citation (vaswani2017attention); the model is trained to: (1) jointly predict parts of speech and predicates; (2) perform parsing; and (3) attend to syntactic parse parents, while (4) assigning semantic role labels."
    },
    "relationships": {}
  },
  {
    "id": "3096878",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.339667,
          "width": 0.295798,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.324228,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.307601,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.292162,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.275534,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.260095,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.243468,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.42521,
          "top": 0.226841,
          "width": 0.0621849,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Whereas prior work typically requires separate models to provide linguistic analysis, including most syntax-free neural models which still rely on external predicate detection, our model is truly end-to-end: earlier layers are trained to predict prerequisite parts-of-speech and predicates, the latter of which are supplied to later layers for scoring.",
      "tex_start": 5922,
      "tex_end": 6274,
      "text": "Whereas prior work typically requires separate models to provide linguistic analysis, including most syntax-free neural models which still rely on external predicate detection, our model is truly end-to-end: earlier layers are trained to predict prerequisite parts-of-speech and predicates, the latter of which are supplied to later layers for scoring."
    },
    "relationships": {}
  },
  {
    "id": "3096879",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.452494,
          "width": 0.248739,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.437055,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.420428,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.4038,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.388361,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.371734,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.356295,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.430252,
          "top": 0.339667,
          "width": 0.0571429,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Though prior work re-encodes each sentence to predict each desired task and again with respect to each predicate to perform SRL,\n%in our model predicates are not known \\emph{a priori} so \nwe more efficiently encode each sentence only once, predict its predicates, part-of-speech tags and labeled syntactic parse, then predict the semantic roles for all predicates in the sentence in parallel.",
      "tex_start": 6275,
      "tex_end": 6667,
      "text": "Though prior work re-encodes each sentence to predict each desired task and again with respect to each predicate to perform SRL, we more efficiently encode each sentence only once, predict its predicates, part-of-speech tags and labeled syntactic parse, then predict the semantic roles for all predicates in the sentence in parallel."
    },
    "relationships": {}
  },
  {
    "id": "3096880",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.533254,
          "width": 0.137815,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.516627,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.501188,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.484561,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.469121,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.386555,
          "top": 0.452494,
          "width": 0.10084,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The model is trained such that, as syntactic parsing models improve, providing high-quality parses at test time will improve its performance, allowing the model to leverage updated parsing models without requiring re-training.",
      "tex_start": 6668,
      "tex_end": 6894,
      "text": "The model is trained such that, as syntactic parsing models improve, providing high-quality parses at test time will improve its performance, allowing the model to leverage updated parsing models without requiring re-training."
    },
    "relationships": {}
  },
  {
    "id": "3096881",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.60095,
          "width": 0.226891,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.584323,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.568884,
          "width": 0.368067,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.141176,
          "top": 0.552257,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In experiments on the CoNLL-2005 and CoNLL-2012 datasets we show that our linguistically-informed models out-perform the syntax-free state-of-the-art.",
      "tex_start": 7089,
      "tex_end": 7239,
      "text": "In experiments on the CoNLL-2005 and CoNLL-2012 datasets we show that our linguistically-informed models out-perform the syntax-free state-of-the-art."
    },
    "relationships": {}
  },
  {
    "id": "3096882",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.665083,
          "width": 0.215126,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.648456,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.633017,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.61639,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.359664,
          "top": 0.60095,
          "width": 0.127731,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On CoNLL-2005 with predicted predicates and standard word embeddings, our single model out-performs the previous state-of-the-art model on the WSJ test set by 2.5 F1 points absolute.",
      "tex_start": 7240,
      "tex_end": 7422,
      "text": "On CoNLL-2005 with predicted predicates and standard word embeddings, our single model out-performs the previous state-of-the-art model on the WSJ test set by 2.5 F1 points absolute."
    },
    "relationships": {}
  },
  {
    "id": "3096883",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.712589,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.69715,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.680523,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.346218,
          "top": 0.665083,
          "width": 0.141176,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On the challenging out-of-domain Brown test set, our model improves substantially over the previous state-of-the-art by more than 3.5 F1, a nearly 10\\% reduction in error.",
      "tex_start": 7423,
      "tex_end": 7594,
      "text": "On the challenging out-of-domain Brown test set, our model improves substantially over the previous state-of-the-art by more than 3.5 F1, a nearly 10\\% reduction in error."
    },
    "relationships": {}
  },
  {
    "id": "3096884",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.122689,
          "top": 0.745843,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.729216,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On CoNLL-2012, our model gains more than 2.5 F1 absolute over the previous state-of-the-art.",
      "tex_start": 7595,
      "tex_end": 7687,
      "text": "On CoNLL-2012, our model gains more than 2.5 F1 absolute over the previous state-of-the-art."
    },
    "relationships": {}
  },
  {
    "id": "3096885",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.144538,
          "top": 0.889549,
          "width": 0.342857,
          "height": 0.0178147
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.862233,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.845606,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.830166,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.814727,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.7981,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.78266,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.766033,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.749406,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.733967,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.71734,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.699525,
          "width": 0.763025,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.669834,
          "width": 0.588235,
          "height": 0.0261283
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.653207,
          "width": 0.70084,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.637767,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.62114,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.141176,
          "top": 0.605701,
          "width": 0.739496,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.589074,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.573634,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.557007,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.54038,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.524941,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.508314,
          "width": 0.763025,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.476247,
          "width": 0.763025,
          "height": 0.0249406
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.45962,
          "width": 0.712605,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.440618,
          "width": 0.759664,
          "height": 0.0154394
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.427553,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.410926,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.395487,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.37886,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.36342,
          "width": 0.645378,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.139496,
          "top": 0.346793,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.273159,
          "width": 0.763025,
          "height": 0.0700713
        },
        {
          "page": 3,
          "left": 0.242017,
          "top": 0.238717,
          "width": 0.640336,
          "height": 0.0273159
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.224466,
          "width": 0.297479,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.206651,
          "width": 0.761345,
          "height": 0.0166271
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.173397,
          "width": 0.763025,
          "height": 0.0308789
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.160333,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.179832,
          "top": 0.128266,
          "width": 0.702521,
          "height": 0.0273159
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.665546,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.763025,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.847981,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.78266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.767221,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.744656,
          "width": 0.331092,
          "height": 0.0118765
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.719715,
          "width": 0.282353,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.704276,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.687648,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.672209,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.655582,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.638955,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.623515,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.897862,
          "width": 0.468908,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.884798,
          "width": 0.742857,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.871734,
          "width": 0.742857,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.85867,
          "width": 0.741176,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.845606,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.821853,
          "width": 0.640336,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.808789,
          "width": 0.744538,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.795724,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.78266,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.709026,
          "width": 0.763025,
          "height": 0.0629454
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.673397,
          "width": 0.761345,
          "height": 0.0308789
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.631829,
          "width": 0.763025,
          "height": 0.0391924
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.581948,
          "width": 0.761345,
          "height": 0.04038
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.505938,
          "width": 0.763025,
          "height": 0.067696
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.442993,
          "width": 0.761345,
          "height": 0.0534442
        },
        {
          "page": 9,
          "left": 0.536134,
          "top": 0.427553,
          "width": 0.0302521,
          "height": 0.00831354
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.375297,
          "width": 0.761345,
          "height": 0.0510689
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.355107,
          "width": 0.742857,
          "height": 0.0154394
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.339667,
          "width": 0.72605,
          "height": 0.0130641
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.326603,
          "width": 0.763025,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.279097,
          "width": 0.742857,
          "height": 0.0451306
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.264846,
          "width": 0.484034,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.251781,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.515966,
          "top": 0.238717,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.229216,
          "width": 0.0420168,
          "height": 0.00831354
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.216152,
          "width": 0.668908,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.139496,
          "top": 0.203088,
          "width": 0.742857,
          "height": 0.0106888
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.180523,
          "width": 0.586555,
          "height": 0.0178147
        },
        {
          "page": 9,
          "left": 0.137815,
          "top": 0.166271,
          "width": 0.744538,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.141176,
          "top": 0.153207,
          "width": 0.741176,
          "height": 0.0118765
        },
        {
          "page": 9,
          "left": 0.121008,
          "top": 0.0926366,
          "width": 0.761345,
          "height": 0.0581948
        },
        {
          "page": 9,
          "left": 0.122689,
          "top": 0.0783848,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.897862,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.882423,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.849169,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.833729,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.817102,
          "width": 0.761345,
          "height": 0.0154394
        },
        {
          "page": 1,
          "left": 0.536134,
          "top": 0.605701,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.587886,
          "width": 0.243697,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.572447,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.555819,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.539192,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.523753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.507126,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.491686,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.461995,
          "width": 0.0840336,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.897862,
          "width": 0.302521,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.589916,
          "top": 0.882423,
          "width": 0.292437,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.846793,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.72437,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.769596,
          "width": 0.761345,
          "height": 0.0261283
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.751781,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.735154,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.719715,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.703088,
          "width": 0.741176,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.685273,
          "width": 0.761345,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.669834,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.684034,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.638955,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.622328,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.226891,
          "top": 0.590261,
          "width": 0.655462,
          "height": 0.0285036
        },
        {
          "page": 4,
          "left": 0.554622,
          "top": 0.57601,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.497625,
          "width": 0.763025,
          "height": 0.0771971
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.47981,
          "width": 0.757983,
          "height": 0.0154394
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.448931,
          "width": 0.539496,
          "height": 0.0296912
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.361045,
          "width": 0.761345,
          "height": 0.0819477
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.344418,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.271971,
          "width": 0.761345,
          "height": 0.067696
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.239905,
          "width": 0.759664,
          "height": 0.0273159
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.219715,
          "width": 0.665546,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.155582,
          "width": 0.715966,
          "height": 0.0617577
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.143705,
          "width": 0.368067,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.128266,
          "width": 0.569748,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.157983,
          "top": 0.0795724,
          "width": 0.72437,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.157983,
          "top": 0.897862,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.882423,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.847981,
          "width": 0.763025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.815915,
          "width": 0.761345,
          "height": 0.0261283
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.795724,
          "width": 0.757983,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.139496,
          "top": 0.775534,
          "width": 0.741176,
          "height": 0.0190024
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.669834,
          "width": 0.761345,
          "height": 0.104513
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.622328,
          "width": 0.761345,
          "height": 0.0308789
        },
        {
          "page": 2,
          "left": 0.139496,
          "top": 0.605701,
          "width": 0.742857,
          "height": 0.0142518
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.589074,
          "width": 0.759664,
          "height": 0.0154394
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.524941,
          "width": 0.761345,
          "height": 0.0629454
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.491686,
          "width": 0.761345,
          "height": 0.0273159
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.465558,
          "width": 0.352941,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.447743,
          "width": 0.366387,
          "height": 0.0154394
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.431116,
          "width": 0.368067,
          "height": 0.0142518
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.416865,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.401425,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.384798,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.369359,
          "width": 0.226891,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.352732,
          "width": 0.364706,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.337292,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.320665,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.305226,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.288599,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.271971,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.256532,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.552941,
          "top": 0.239905,
          "width": 0.331092,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.224466,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.207838,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.175772,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.160333,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.143705,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.128266,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.534454,
          "top": 0.111639,
          "width": 0.34958,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.0950119,
          "width": 0.352941,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.0783848,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.897862,
          "width": 0.613445,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.2,
          "top": 0.882423,
          "width": 0.682353,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.864608,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.203361,
          "top": 0.849169,
          "width": 0.678992,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.17479,
          "top": 0.833729,
          "width": 0.707563,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.157983,
          "top": 0.801663,
          "width": 0.72437,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.164706,
          "top": 0.785036,
          "width": 0.717647,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.768409,
          "width": 0.542857,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.751781,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.139496,
          "top": 0.736342,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.716152,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.700713,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.684085,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.667458,
          "width": 0.761345,
          "height": 0.0154394
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.652019,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.635392,
          "width": 0.584874,
          "height": 0.0142518
        },
        {
          "page": 5,
          "left": 0.242017,
          "top": 0.62114,
          "width": 0.640336,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.603325,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.587886,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.571259,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 5,
          "left": 0.159664,
          "top": 0.557007,
          "width": 0.722689,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.159664,
          "top": 0.541568,
          "width": 0.722689,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.523753,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.507126,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 5,
          "left": 0.141176,
          "top": 0.490499,
          "width": 0.741176,
          "height": 0.0142518
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.406176,
          "width": 0.763025,
          "height": 0.0819477
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.251781,
          "width": 0.763025,
          "height": 0.153207
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.128266,
          "width": 0.763025,
          "height": 0.122328
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.110451,
          "width": 0.601681,
          "height": 0.0118765
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.0795724,
          "width": 0.482353,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.897862,
          "width": 0.0352941,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.882423,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.849169,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.833729,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.801663,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.785036,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.769596,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.752969,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.141176,
          "top": 0.73753,
          "width": 0.346218,
          "height": 0.00831354
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.71734,
          "width": 0.183193,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.700713,
          "width": 0.761345,
          "height": 0.0154394
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.685273,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.668646,
          "width": 0.67563,
          "height": 0.0142518
        },
        {
          "page": 12,
          "left": 0.129412,
          "top": 0.653207,
          "width": 0.752941,
          "height": 0.0142518
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.63658,
          "width": 0.759664,
          "height": 0.0142518
        },
        {
          "page": 12,
          "left": 0.141176,
          "top": 0.611639,
          "width": 0.667227,
          "height": 0.0190024
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.603325,
          "width": 0.0504202,
          "height": 0.00593824
        },
        {
          "page": 12,
          "left": 0.14958,
          "top": 0.60095,
          "width": 0.00168067,
          "height": 0.00118765
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.542755,
          "width": 0.763025,
          "height": 0.0522565
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.522565,
          "width": 0.761345,
          "height": 0.0154394
        },
        {
          "page": 12,
          "left": 0.517647,
          "top": 0.510689,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.483373,
          "width": 0.603361,
          "height": 0.0166271
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.157983,
          "top": 0.783848,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.764846,
          "width": 0.705882,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.747031,
          "width": 0.763025,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.652019,
          "width": 0.763025,
          "height": 0.087886
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.619952,
          "width": 0.761345,
          "height": 0.0308789
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.522565,
          "width": 0.761345,
          "height": 0.0961995
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.475059,
          "width": 0.761345,
          "height": 0.0463183
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.442993,
          "width": 0.763025,
          "height": 0.0285036
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.431116,
          "width": 0.29916,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.410926,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.384798,
          "width": 0.69916,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.368171,
          "width": 0.692437,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.350356,
          "width": 0.761345,
          "height": 0.0142518
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.334917,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.319477,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.304038,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.287411,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.271971,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.241093,
          "width": 0.715966,
          "height": 0.0261283
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.224466,
          "width": 0.539496,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.207838,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.192399,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.141176,
          "top": 0.175772,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.160333,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.143705,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.128266,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.891924,
          "width": 0.315966,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.87886,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.865796,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.852732,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.830166,
          "width": 0.255462,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.817102,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.804038,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.790974,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.779097,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.766033,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.743468,
          "width": 0.203361,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.730404,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.71734,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.704276,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.691211,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.678147,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.665083,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.137815,
          "top": 0.653207,
          "width": 0.34958,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.640143,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.617577,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.604513,
          "width": 0.344538,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.591449,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.570071,
          "width": 0.260504,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.557007,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.543943,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.522565,
          "width": 0.183193,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.509501,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.496437,
          "width": 0.346218,
          "height": 0.00950119
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.483373,
          "width": 0.347899,
          "height": 0.00950119
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.470309,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.448931,
          "width": 0.112605,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.435867,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.422803,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.409739,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.387173,
          "width": 0.132773,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.374109,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.362233,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.349169,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.336105,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.32304,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.309976,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.296912,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.274347,
          "width": 0.102521,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.261283,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.248219,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.236342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.213777,
          "width": 0.213445,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.200713,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.187648,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.166271,
          "width": 0.310924,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.153207,
          "width": 0.347899,
          "height": 0.00831354
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.140143,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.118765,
          "width": 0.179832,
          "height": 0.00831354
        },
        {
          "page": 11,
          "left": 0.141176,
          "top": 0.105701,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.139496,
          "top": 0.0926366,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 11,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.897862,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.882423,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.849169,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.833729,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.801663,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.785036,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.769596,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.752969,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.73753,
          "width": 0.759664,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.720903,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.704276,
          "width": 0.761345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.686461,
          "width": 0.694118,
          "height": 0.0130641
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.761345,
          "height": 0.0273159
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.638955,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.606888,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.590261,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.573634,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.534454,
          "top": 0.558195,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.54038,
          "width": 0.255462,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.523753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.508314,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.491686,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.475059,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.45962,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.442993,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.426366,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.410926,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.395487,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.37886,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.882423,
          "width": 0.2,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.86342,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.846793,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.757983,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.78266,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.141176,
          "top": 0.767221,
          "width": 0.741176,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.750594,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.733967,
          "width": 0.759664,
          "height": 0.0142518
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.718527,
          "width": 0.763025,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.7019,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.686461,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.141176,
          "top": 0.669834,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.654394,
          "width": 0.54958,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.637767,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.619952,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.603325,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.587886,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.571259,
          "width": 0.761345,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.555819,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.539192,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.523753,
          "width": 0.759664,
          "height": 0.0118765
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.507126,
          "width": 0.759664,
          "height": 0.0130641
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.492874,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.121008,
          "top": 0.751781,
          "width": 0.761345,
          "height": 0.064133
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.735154,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.534454,
          "top": 0.719715,
          "width": 0.347899,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.700713,
          "width": 0.156303,
          "height": 0.0118765
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.686461,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.669834,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.654394,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.637767,
          "width": 0.236975,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.62114,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.475059,
          "width": 0.12605,
          "height": 0.00950119
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.438242,
          "width": 0.310924,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.422803,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.406176,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.389549,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.374109,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.357482,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.342043,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.325416,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.309976,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.293349,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.897862,
          "width": 0.704202,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.884798,
          "width": 0.742857,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.871734,
          "width": 0.344538,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.857482,
          "width": 0.610084,
          "height": 0.0118765
        },
        {
          "page": 10,
          "left": 0.536134,
          "top": 0.844418,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.831354,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.81829,
          "width": 0.742857,
          "height": 0.0118765
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.806413,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.752969,
          "width": 0.761345,
          "height": 0.0498812
        },
        {
          "page": 10,
          "left": 0.137815,
          "top": 0.729216,
          "width": 0.744538,
          "height": 0.0213777
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.686461,
          "width": 0.763025,
          "height": 0.04038
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.650831,
          "width": 0.744538,
          "height": 0.0332542
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.606888,
          "width": 0.763025,
          "height": 0.0415677
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.573634,
          "width": 0.742857,
          "height": 0.0308789
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.528504,
          "width": 0.763025,
          "height": 0.0427553
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.495249,
          "width": 0.744538,
          "height": 0.0308789
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.461995,
          "width": 0.761345,
          "height": 0.0308789
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.429929,
          "width": 0.741176,
          "height": 0.0296912
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.408551,
          "width": 0.628571,
          "height": 0.0190024
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.357482,
          "width": 0.761345,
          "height": 0.0486936
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.339667,
          "width": 0.196639,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.290974,
          "width": 0.761345,
          "height": 0.0475059
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.248219,
          "width": 0.761345,
          "height": 0.04038
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.185273,
          "width": 0.763025,
          "height": 0.0475059
        },
        {
          "page": 10,
          "left": 0.139496,
          "top": 0.157957,
          "width": 0.615126,
          "height": 0.02019
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.144893,
          "width": 0.761345,
          "height": 0.0118765
        },
        {
          "page": 10,
          "left": 0.515966,
          "top": 0.133017,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.119952,
          "width": 0.109244,
          "height": 0.00950119
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.105701,
          "width": 0.504202,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.141176,
          "top": 0.0926366,
          "width": 0.741176,
          "height": 0.0106888
        },
        {
          "page": 10,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.761345,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our models also show improvements when using contextually-encoded word representations \\citep{peters2018deep}, obtaining nearly 1.0 F1 higher than the state-of-the-art on CoNLL-2005 news and more than 2.0 F1 improvement on out-of-domain text.\\footnote{Our implementation in TensorFlow \\citep{abadi2015tensorflow} is available at : \\protect\\url{http://github.com/strubell/LISA",
      "tex_start": 7688,
      "tex_end": 8063,
      "text": "Our models also show improvements when using contextually-encoded word representations Citation (peters2018deep), obtaining nearly 1.0 F1 higher than the state-of-the-art on CoNLL-2005 news and more than 2.0 F1 improvement on out-of-domain text.Our implementation in TensorFlow Citation (abadi2015tensorflow) is available at : http://github.com/strubell/LISA"
    },
    "relationships": {}
  },
  {
    "id": "3096886",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\section{Model}\n\n\\begin{figure}[",
      "tex_start": 8065,
      "tex_end": 8099,
      "text": "Model."
    },
    "relationships": {}
  },
  {
    "id": "3096887",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "t]\n\\begin{center}\n\\includegraphics[scale=.8]{no_words_simpler_compact-srl-model.pdf",
      "tex_start": 8099,
      "tex_end": 8182,
      "text": "t  scale=.8no_words_simpler_compact-srl-model.pdf"
    },
    "relationships": {}
  },
  {
    "id": "3096888",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.306413,
          "width": 0.184874,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.584874,
          "top": 0.289786,
          "width": 0.29916,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Word embeddings are input to $J$ layers of multi-head self-attention.",
      "tex_start": 8193,
      "tex_end": 8262,
      "text": "Word embeddings are input to EQUATION_DEPTH_0_START J EQUATION_DEPTH_0_END layers of multi-head self-attention."
    },
    "relationships": {}
  },
  {
    "id": "3096889",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.52605,
          "top": 0.339667,
          "width": 0.00840336,
          "height": 0.00950119
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.321853,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.712605,
          "top": 0.306413,
          "width": 0.169748,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In layer $p$ one attention head is trained to attend to parse parents (Figure \\ref{attention-fig}).",
      "tex_start": 8263,
      "tex_end": 8362,
      "text": "In layer EQUATION_DEPTH_0_START p EQUATION_DEPTH_0_END one attention head is trained to attend to parse parents (Figure (Ref attention-fig))."
    },
    "relationships": {}
  },
  {
    "id": "3096890",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.355107,
          "width": 0.0369748,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.542857,
          "top": 0.33848,
          "width": 0.339496,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Layer $r$ is input for a joint predicate/POS classifier.",
      "tex_start": 8363,
      "tex_end": 8419,
      "text": "Layer EQUATION_DEPTH_0_START r EQUATION_DEPTH_0_END is input for a joint predicate/POS classifier."
    },
    "relationships": {}
  },
  {
    "id": "3096891",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.41924,
          "width": 0.292437,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.402613,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.387173,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.370546,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.571429,
          "top": 0.355107,
          "width": 0.310924,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Representations from layer $r$ corresponding to predicted predicates are passed to  a bilinear operation scoring distinct predicate and role representations to produce per-token SRL predictions with respect to each predicted predicate.",
      "tex_start": 8420,
      "tex_end": 8655,
      "text": "Representations from layer EQUATION_DEPTH_0_START r EQUATION_DEPTH_0_END corresponding to predicted predicates are passed to  a bilinear operation scoring distinct predicate and role representations to produce per-token SRL predictions with respect to each predicted predicate."
    },
    "relationships": {}
  },
  {
    "id": "3096892",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{architecture-fig}}",
      "tex_start": 8655,
      "tex_end": 8680,
      "text": "(Label architecture-fig)"
    },
    "relationships": {}
  },
  {
    "id": "3096893",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "t]\n\\begin{center}\n\\includegraphics[scale=.24]{attention-keynote",
      "tex_start": 8723,
      "tex_end": 8786,
      "text": "t  scale=.24attention-keynote"
    },
    "relationships": {}
  },
  {
    "id": "3096894",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.337292,
          "width": 0.161345,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.191597,
          "top": 0.320665,
          "width": 0.297479,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Syntactically-informed self-attention for the query word \\emph{sloth}.",
      "tex_start": 8797,
      "tex_end": 8867,
      "text": "Syntactically-informed self-attention for the query word sloth."
    },
    "relationships": {}
  },
  {
    "id": "3096895",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.385986,
          "width": 0.0823529,
          "height": 0.0118765
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.369359,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.353919,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.29916,
          "top": 0.337292,
          "width": 0.186555,
          "height": 0.0130641
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Attention weights $A_{parse}$ heavily weight the token's syntactic governor, \\emph{saw}, in a weighted average over the token values $V_{parse}$.",
      "tex_start": 8868,
      "tex_end": 9013,
      "text": "Attention weights EQUATION_DEPTH_0_START A_{parse} EQUATION_DEPTH_0_END heavily weight the token's syntactic governor, saw, in a weighted average over the token values EQUATION_DEPTH_0_START V_{parse} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096896",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.450119,
          "width": 0.243697,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.433492,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.418052,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.401425,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.228571,
          "top": 0.385986,
          "width": 0.258824,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The other attention heads act as usual, and the attended representations from all heads are concatenated and projected through a feed-forward layer to produce the syntactically-informed representation for \\emph{sloth}.",
      "tex_start": 9014,
      "tex_end": 9232,
      "text": "The other attention heads act as usual, and the attended representations from all heads are concatenated and projected through a feed-forward layer to produce the syntactically-informed representation for sloth."
    },
    "relationships": {}
  },
  {
    "id": "3096897",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{attention-fig}}",
      "tex_start": 9233,
      "tex_end": 9255,
      "text": "(Label attention-fig)"
    },
    "relationships": {}
  },
  {
    "id": "3096898",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.539192,
          "width": 0.0857143,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.523753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.507126,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.491686,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our goal is to design an efficient neural network model which makes use of linguistic information as effectively as possible in order to perform end-to-end SRL.",
      "tex_start": 9283,
      "tex_end": 9443,
      "text": "Our goal is to design an efficient neural network model which makes use of linguistic information as effectively as possible in order to perform end-to-end SRL."
    },
    "relationships": {}
  },
  {
    "id": "3096899",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.587886,
          "width": 0.243697,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.572447,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.555819,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.611765,
          "top": 0.539192,
          "width": 0.270588,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA achieves this by combining: (1) A new technique of supervising neural attention to predict syntactic dependencies with (2) multi-task learning across four related tasks.",
      "tex_start": 9444,
      "tex_end": 9618,
      "text": "LISA achieves this by combining: (1) A new technique of supervising neural attention to predict syntactic dependencies with (2) multi-task learning across four related tasks."
    },
    "relationships": {}
  },
  {
    "id": "3096900",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.62114,
          "width": 0.0504202,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.536134,
          "top": 0.605701,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Figure~\\ref{architecture-fig} depicts the overall architecture of our model.",
      "tex_start": 9820,
      "tex_end": 9896,
      "text": "Figure (Ref architecture-fig) depicts the overall architecture of our model."
    },
    "relationships": {}
  },
  {
    "id": "3096901",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.700713,
          "width": 0.156303,
          "height": 0.0118765
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.686461,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.669834,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.654394,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.637767,
          "width": 0.236975,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.584874,
          "top": 0.62114,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The basis for our model is the Transformer encoder introduced by \\citet{vaswani2017attention}: we transform word embeddings into contextually-encoded token representations using stacked multi-head self-attention and feed-forward layers (\\S\\ref{sec:self-attn}).",
      "tex_start": 9897,
      "tex_end": 10157,
      "text": "The basis for our model is the Transformer encoder introduced by Citation (vaswani2017attention): we transform word embeddings into contextually-encoded token representations using stacked multi-head self-attention and feed-forward layers ((Ref sec:self-attn))."
    },
    "relationships": {}
  },
  {
    "id": "3096902",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.768409,
          "width": 0.30084,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.751781,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.735154,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.534454,
          "top": 0.719715,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "To incorporate syntax, one self-attention head is trained to attend to each token's syntactic parent, allowing the model to use this attention head as an oracle for syntactic dependencies.",
      "tex_start": 10267,
      "tex_end": 10455,
      "text": "To incorporate syntax, one self-attention head is trained to attend to each token's syntactic parent, allowing the model to use this attention head as an oracle for syntactic dependencies."
    },
    "relationships": {}
  },
  {
    "id": "3096903",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.799287,
          "width": 0.236975,
          "height": 0.0118765
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.783848,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.833613,
          "top": 0.768409,
          "width": 0.0487395,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We introduce this \\emph{syntactically-informed self-attention} (Figure \\ref{attention-fig}) in more detail in \\S\\ref{sec:syntax-attn}.",
      "tex_start": 10456,
      "tex_end": 10590,
      "text": "We introduce this syntactically-informed self-attention (Figure (Ref attention-fig)) in more detail in (Ref sec:syntax-attn)."
    },
    "relationships": {}
  },
  {
    "id": "3096904",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.849169,
          "width": 0.0655462,
          "height": 0.00831354
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.833729,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.534454,
          "top": 0.817102,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our model is designed for the more realistic setting in which gold predicates are not provided at test-time.",
      "tex_start": 11420,
      "tex_end": 11528,
      "text": "Our model is designed for the more realistic setting in which gold predicates are not provided at test-time."
    },
    "relationships": {}
  },
  {
    "id": "3096905",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.897862,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.517647,
          "top": 0.882423,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.515966,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 1,
          "left": 0.591597,
          "top": 0.849169,
          "width": 0.290756,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.491686,
          "width": 0.257143,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our model predicts predicates and integrates part-of-speech (POS) information into earlier layers by re-purposing representations closer to the input to predict predicate and POS tags using hard parameter sharing (\\S\\ref{sec:MTL}).",
      "tex_start": 11529,
      "tex_end": 11760,
      "text": "Our model predicts predicates and integrates part-of-speech (POS) information into earlier layers by re-purposing representations closer to the input to predict predicate and POS tags using hard parameter sharing ((Ref sec:MTL))."
    },
    "relationships": {}
  },
  {
    "id": "3096906",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.589074,
          "width": 0.184874,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.572447,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.557007,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.54038,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.524941,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.508314,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.396639,
          "top": 0.492874,
          "width": 0.0907563,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We simplify optimization and benefit from shared statistical strength derived from highly correlated POS and predicates by treating tagging and predicate detection as a single task, performing multi-class classification into the joint Cartesian product space of POS and predicate labels.",
      "tex_start": 11761,
      "tex_end": 12048,
      "text": "We simplify optimization and benefit from shared statistical strength derived from highly correlated POS and predicates by treating tagging and predicate detection as a single task, performing multi-class classification into the joint Cartesian product space of POS and predicate labels."
    },
    "relationships": {}
  },
  {
    "id": "3096907",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.669834,
          "width": 0.131092,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.637767,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.139496,
          "top": 0.605701,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Though typical models, which re-encode the sentence for each predicate, can simplify SRL to token-wise tagging, our joint model requires a different approach to classify roles with respect to each predicate.",
      "tex_start": 12051,
      "tex_end": 12258,
      "text": "Though typical models, which re-encode the sentence for each predicate, can simplify SRL to token-wise tagging, our joint model requires a different approach to classify roles with respect to each predicate."
    },
    "relationships": {}
  },
  {
    "id": "3096908",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.733967,
          "width": 0.189916,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.718527,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.700713,
          "width": 0.364706,
          "height": 0.0118765
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.686461,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.268908,
          "top": 0.669834,
          "width": 0.218487,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Contextually encoded tokens are projected to distinct \\emph{predicate} and \\emph{role} embeddings (\\S\\ref{sec:srl}), and each predicted predicate is scored with the sequence's role representations using a bilinear model (Eqn.",
      "tex_start": 12259,
      "tex_end": 12484,
      "text": "Contextually encoded tokens are projected to distinct predicate and role embeddings ((Ref sec:srl)), and each predicted predicate is scored with the sequence's role representations using a bilinear model (Eqn."
    },
    "relationships": {}
  },
  {
    "id": "3096909",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.766033,
          "width": 0.268908,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.750594,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.327731,
          "top": 0.733967,
          "width": 0.157983,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\ref{eqn:bilinear}), producing per-label scores for BIO-encoded semantic role labels for each token and each semantic frame.",
      "tex_start": 12485,
      "tex_end": 12609,
      "text": "(Ref eqn:bilinear)), producing per-label scores for BIO-encoded semantic role labels for each token and each semantic frame."
    },
    "relationships": {}
  },
  {
    "id": "3096910",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.7981,
          "width": 0.364706,
          "height": 0.0118765
        },
        {
          "page": 2,
          "left": 0.139496,
          "top": 0.783848,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The model is trained end-to-end by maximum likelihood using stochastic gradient descent (\\S\\ref{sec:train-opt}).",
      "tex_start": 12612,
      "tex_end": 12724,
      "text": "The model is trained end-to-end by maximum likelihood using stochastic gradient descent ((Ref sec:train-opt))."
    },
    "relationships": {}
  },
  {
    "id": "3096911",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.826603,
          "width": 0.262185,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": " \n\n\\subsection{Self-attention token encoder \\label{sec:self-attn}}",
      "tex_start": 12724,
      "tex_end": 12790,
      "text": "Self-attention token encoder \\label{sec:self-attn."
    },
    "relationships": {}
  },
  {
    "id": "3096912",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.157983,
          "top": 0.897862,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.122689,
          "top": 0.882423,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.121008,
          "top": 0.849169,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.0783848,
          "width": 0.331092,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The basis for our model is a multi-head self-attention token encoder, recently shown to achieve state-of-the-art performance on SRL \\citep{tan2018deep}, and which provides a natural mechanism for incorporating syntax, as described in \\S\\ref{sec:syntax-attn}.",
      "tex_start": 12791,
      "tex_end": 13049,
      "text": "The basis for our model is a multi-head self-attention token encoder, recently shown to achieve state-of-the-art performance on SRL Citation (tan2018deep), and which provides a natural mechanism for incorporating syntax, as described in (Ref sec:syntax-attn)."
    },
    "relationships": {}
  },
  {
    "id": "3096913",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.0950119,
          "width": 0.352941,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.855462,
          "top": 0.0795724,
          "width": 0.0285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our implementation replicates \\citet{vaswani2017attention}.",
      "tex_start": 13050,
      "tex_end": 13109,
      "text": "Our implementation replicates Citation (vaswani2017attention)."
    },
    "relationships": {}
  },
  {
    "id": "3096914",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.128266,
          "width": 0.183193,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.534454,
          "top": 0.111639,
          "width": 0.34958,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The input to the network is a sequence $\\mathcal{X}$ of $T$ token representations $x_t$.",
      "tex_start": 13112,
      "tex_end": 13200,
      "text": "The input to the network is a sequence EQUATION_DEPTH_0_START \\mathcal{X} EQUATION_DEPTH_0_END of EQUATION_DEPTH_0_START T EQUATION_DEPTH_0_END token representations EQUATION_DEPTH_0_START x_t EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096915",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.552941,
          "top": 0.241093,
          "width": 0.010084,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.224466,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.207838,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.175772,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.160333,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.143705,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.715966,
          "top": 0.128266,
          "width": 0.166387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In the standard setting these token representations are initialized to pre-trained word embeddings, but we also experiment with supplying pre-trained ELMo representations combined with task-specific learned parameters, which have been shown to substantially improve performance of other SRL models \\citep{peters2018deep}.",
      "tex_start": 13201,
      "tex_end": 13522,
      "text": "In the standard setting these token representations are initialized to pre-trained word embeddings, but we also experiment with supplying pre-trained ELMo representations combined with task-specific learned parameters, which have been shown to substantially improve performance of other SRL models Citation (peters2018deep)."
    },
    "relationships": {}
  },
  {
    "id": "3096916",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.271971,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.256532,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.57479,
          "top": 0.239905,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "For experiments with gold predicates, we concatenate a predicate indicator embedding $p_t$ following previous work \\citep{he2017deep}.",
      "tex_start": 13523,
      "tex_end": 13657,
      "text": "For experiments with gold predicates, we concatenate a predicate indicator embedding EQUATION_DEPTH_0_START p_t EQUATION_DEPTH_0_END following previous work Citation (he2017deep)."
    },
    "relationships": {}
  },
  {
    "id": "3096917",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.86342,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.847981,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.831354,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.815915,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.795724,
          "width": 0.363025,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.775534,
          "width": 0.364706,
          "height": 0.0178147
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.756532,
          "width": 0.366387,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.73753,
          "width": 0.363025,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.723278,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.707838,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.688836,
          "width": 0.346218,
          "height": 0.0130641
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.675772,
          "width": 0.314286,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.659145,
          "width": 0.363025,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.643705,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.627078,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.611639,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.595012,
          "width": 0.364706,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.534454,
          "top": 0.579572,
          "width": 0.347899,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.288599,
          "width": 0.0806723,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We project\\footnote{All linear projections include bias terms, which we omit in this exposition for the sake of clarity.",
      "tex_start": 14889,
      "tex_end": 15009,
      "text": "We projectAll linear projections include bias terms, which we omit in this exposition for the sake of clarity."
    },
    "relationships": {}
  },
  {
    "id": "3096918",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.320665,
          "width": 0.17479,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.305226,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.633613,
          "top": 0.288599,
          "width": 0.248739,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "these input embeddings to a representation that is the same size as the output of the self-attention layers.",
      "tex_start": 15011,
      "tex_end": 15119,
      "text": "these input embeddings to a representation that is the same size as the output of the self-attention layers."
    },
    "relationships": {}
  },
  {
    "id": "3096919",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.369359,
          "width": 0.226891,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.352732,
          "width": 0.364706,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.337292,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.702521,
          "top": 0.320665,
          "width": 0.178151,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We then add a positional encoding vector computed as a deterministic sinusoidal function of $t$, since the self-attention has no innate notion of token position.",
      "tex_start": 15120,
      "tex_end": 15281,
      "text": "We then add a positional encoding vector computed as a deterministic sinusoidal function of EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END , since the self-attention has no innate notion of token position."
    },
    "relationships": {}
  },
  {
    "id": "3096920",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.416865,
          "width": 0.258824,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.401425,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.384798,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We feed this token representation as input to a series of $J$ residual multi-head self-attention layers with feed-forward connections.",
      "tex_start": 17953,
      "tex_end": 18087,
      "text": "We feed this token representation as input to a series of EQUATION_DEPTH_0_START J EQUATION_DEPTH_0_END residual multi-head self-attention layers with feed-forward connections."
    },
    "relationships": {}
  },
  {
    "id": "3096921",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.526128,
          "width": 0.314286,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.57479,
          "top": 0.495249,
          "width": 0.307563,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.465558,
          "width": 0.352941,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.447743,
          "width": 0.366387,
          "height": 0.0154394
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.431116,
          "width": 0.368067,
          "height": 0.0142518
        },
        {
          "page": 2,
          "left": 0.788235,
          "top": 0.416865,
          "width": 0.0957983,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Denoting the $j$th self-attention layer as $T^{(j)}(\\cdot)$, the output of that layer $s_t^{(j)}$, and $LN(\\cdot)$ layer normalization, the following recurrence applied to initial input $c_t^{(p)}$:\n\\begin{align}\n\\label{eqn:overall}\n% s_t^{(1)} = LN(c_t^{(p)} + T^{(1)}(c_t^{(p)})) \\\\\n% \\vdots \\nonumber \\\\\ns_t^{(j)} = LN(s_t^{(j-1)} + T^{(j)}(s_t^{(j-1)}))\n\\end{align}\ngives our final token representations $s_t^{(j)}$.",
      "tex_start": 18088,
      "tex_end": 18508,
      "text": "Denoting the EQUATION_DEPTH_0_START j EQUATION_DEPTH_0_END th self-attention layer as EQUATION_DEPTH_0_START T^{(j)}(\\cdot) EQUATION_DEPTH_0_END , the output of that layer EQUATION_DEPTH_0_START s_t^{(j)} EQUATION_DEPTH_0_END , and EQUATION_DEPTH_0_START LN(\\cdot) EQUATION_DEPTH_0_END layer normalization, the following recurrence applied to initial input EQUATION_DEPTH_0_START c_t^{(p)} EQUATION_DEPTH_0_END : EQUATION_DEPTH_0_START \\label{eqn:overall}\n% s_t^{(1)} = LN(c_t^{(p)} + T^{(1)}(c_t^{(p)})) \\\\\n% \\vdots \\nonumber \\\\\ns_t^{(j)} = LN(s_t^{(j-1)} + T^{(j)}(s_t^{(j-1)}))\nEQUATION_DEPTH_0_END gives our final token representations EQUATION_DEPTH_0_START s_t^{(j)} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096922",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.543943,
          "width": 0.142857,
          "height": 0.0142518
        },
        {
          "page": 2,
          "left": 0.84874,
          "top": 0.530879,
          "width": 0.0336134,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Each $T^{(j)}(\\cdot)$ consists of:",
      "tex_start": 18509,
      "tex_end": 18543,
      "text": "Each EQUATION_DEPTH_0_START T^{(j)}(\\cdot) EQUATION_DEPTH_0_END consists of:"
    },
    "relationships": {}
  },
  {
    "id": "3096923",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.562945,
          "width": 0.0268908,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.67395,
          "top": 0.546318,
          "width": 0.208403,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "(a) multi-head self-attention and",
      "tex_start": 18544,
      "tex_end": 18577,
      "text": "(a) multi-head self-attention and"
    },
    "relationships": {}
  },
  {
    "id": "3096924",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.54958,
          "top": 0.562945,
          "width": 0.213445,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "(b) a feed-forward projection.",
      "tex_start": 18578,
      "tex_end": 18608,
      "text": "(b) a feed-forward projection."
    },
    "relationships": {}
  },
  {
    "id": "3096925",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.627078,
          "width": 0.097479,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.611639,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.595012,
          "width": 0.364706,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.534454,
          "top": 0.579572,
          "width": 0.347899,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The multi-head self attention consists of $H$ attention heads, each of which learns a distinct attention function to attend to all of the tokens in the sequence.",
      "tex_start": 18610,
      "tex_end": 18771,
      "text": "The multi-head self attention consists of EQUATION_DEPTH_0_START H EQUATION_DEPTH_0_END attention heads, each of which learns a distinct attention function to attend to all of the tokens in the sequence."
    },
    "relationships": {}
  },
  {
    "id": "3096926",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.675772,
          "width": 0.314286,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.659145,
          "width": 0.363025,
          "height": 0.00831354
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.643705,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 2,
          "left": 0.623529,
          "top": 0.627078,
          "width": 0.260504,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This self-attention is performed for each token for each head, and the results of the $H$ self-attentions are concatenated to form the final self-attended representation for each token.",
      "tex_start": 18772,
      "tex_end": 18957,
      "text": "This self-attention is performed for each token for each head, and the results of the EQUATION_DEPTH_0_START H EQUATION_DEPTH_0_END self-attentions are concatenated to form the final self-attended representation for each token."
    },
    "relationships": {}
  },
  {
    "id": "3096927",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.707838,
          "width": 0.248739,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.536134,
          "top": 0.688836,
          "width": 0.346218,
          "height": 0.0130641
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Specifically, consider the matrix $S^{(j-1)}$ of $T$ token representations at layer $j-1$.",
      "tex_start": 18960,
      "tex_end": 19050,
      "text": "Specifically, consider the matrix EQUATION_DEPTH_0_START S^{(j-1)} EQUATION_DEPTH_0_END of EQUATION_DEPTH_0_START T EQUATION_DEPTH_0_END token representations at layer EQUATION_DEPTH_0_START j-1 EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096928",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.780285,
          "width": 0.0907563,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.756532,
          "width": 0.366387,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.73753,
          "width": 0.363025,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.723278,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.77479,
          "top": 0.707838,
          "width": 0.107563,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "For each attention head $h$, we project this matrix into distinct key, value and query representations $K_h^{(j)}$, $V_h^{(j)}$ and $Q_h^{(j)}$ of dimensions $T\\times d_k$, $T\\times d_q$, and $T\\times d_v$, respectively.",
      "tex_start": 19051,
      "tex_end": 19271,
      "text": "For each attention head EQUATION_DEPTH_0_START h EQUATION_DEPTH_0_END , we project this matrix into distinct key, value and query representations EQUATION_DEPTH_0_START K_h^{(j)} EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START V_h^{(j)} EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START Q_h^{(j)} EQUATION_DEPTH_0_END of dimensions EQUATION_DEPTH_0_START T\\times d_k EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START T\\times d_q EQUATION_DEPTH_0_END , and EQUATION_DEPTH_0_START T\\times d_v EQUATION_DEPTH_0_END , respectively."
    },
    "relationships": {}
  },
  {
    "id": "3096929",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.815915,
          "width": 0.32605,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.795724,
          "width": 0.363025,
          "height": 0.0166271
        },
        {
          "page": 2,
          "left": 0.618487,
          "top": 0.775534,
          "width": 0.262185,
          "height": 0.0178147
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We can then multiply $Q_h^{(j)}$ by $K_h^{(j)}$ to obtain a $T\\times T$ matrix of attention weights $A_h^{(j)}$ between each pair of tokens in the sentence.",
      "tex_start": 19272,
      "tex_end": 19428,
      "text": "We can then multiply EQUATION_DEPTH_0_START Q_h^{(j)} EQUATION_DEPTH_0_END by EQUATION_DEPTH_0_START K_h^{(j)} EQUATION_DEPTH_0_END to obtain a EQUATION_DEPTH_0_START T\\times T EQUATION_DEPTH_0_END matrix of attention weights EQUATION_DEPTH_0_START A_h^{(j)} EQUATION_DEPTH_0_END between each pair of tokens in the sentence."
    },
    "relationships": {}
  },
  {
    "id": "3096930",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.326603,
          "width": 0.215126,
          "height": 0.0166271
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.307601,
          "width": 0.366387,
          "height": 0.0166271
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.293349,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.273159,
          "width": 0.366387,
          "height": 0.0166271
        },
        {
          "page": 3,
          "left": 0.242017,
          "top": 0.238717,
          "width": 0.245378,
          "height": 0.0178147
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.206651,
          "width": 0.186555,
          "height": 0.0166271
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.186461,
          "width": 0.364706,
          "height": 0.0178147
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.173397,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.179832,
          "top": 0.135392,
          "width": 0.307563,
          "height": 0.02019
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.189916,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.86342,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.515966,
          "top": 0.847981,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.517647,
          "top": 0.831354,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 2,
          "left": 0.853782,
          "top": 0.815915,
          "width": 0.0285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Following \\citet{vaswani2017attention} we perform scaled dot-product attention: We scale the weights by the inverse square root of their embedding dimension and normalize with the softmax function to produce a distinct distribution for each token over all the tokens in the sentence:\n\\begin{align}\nA_h^{(j)} = \\mathrm{softmax}(d_{k}^{-0.5}Q_h^{(j)}{K_h^{(j)}}^T)\n\\end{align}\n% \\begin{align}\n% M_h^{(j)} = Q_h^{(j)}{K_h^{(j)}}^T\n% \\end{align}\nThese attention weights are then multiplied by $V_h^{(j)}$ for each token to obtain the self-attended token representations $M_h^{(j)}$:\n\\begin{align}\nM_h^{(j)} = A_h^{(j)}V_h^{(j)}\n\\end{align}\nRow $t$ of $M_h^{(j)}$, the self-attended representation for token $t$ at layer $j$, is thus the weighted sum with respect to $t$ (with weights given by $A_h^{(j)}$) over the token representations in $V_h^{(j)}$.",
      "tex_start": 19429,
      "tex_end": 20277,
      "text": "Following Citation (vaswani2017attention) we perform scaled dot-product attention: We scale the weights by the inverse square root of their embedding dimension and normalize with the softmax function to produce a distinct distribution for each token over all the tokens in the sentence: EQUATION_DEPTH_0_START A_h^{(j)} = \\mathrm{softmax}(d_{k}^{-0.5}Q_h^{(j)}{K_h^{(j)}}^T)\nEQUATION_DEPTH_0_END These attention weights are then multiplied by EQUATION_DEPTH_0_START V_h^{(j)} EQUATION_DEPTH_0_END for each token to obtain the self-attended token representations EQUATION_DEPTH_0_START M_h^{(j)} EQUATION_DEPTH_0_END : EQUATION_DEPTH_0_START M_h^{(j)} = A_h^{(j)}V_h^{(j)}\nEQUATION_DEPTH_0_END Row EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END of EQUATION_DEPTH_0_START M_h^{(j)} EQUATION_DEPTH_0_END , the self-attended representation for token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END at layer EQUATION_DEPTH_0_START j EQUATION_DEPTH_0_END , is thus the weighted sum with respect to EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END (with weights given by EQUATION_DEPTH_0_START A_h^{(j)} EQUATION_DEPTH_0_END ) over the token representations in EQUATION_DEPTH_0_START V_h^{(j)} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096931",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.412114,
          "width": 0.231933,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.395487,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.37886,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.36342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.139496,
          "top": 0.346793,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The outputs of all attention heads for each token are concatenated, and this representation is passed to the feed-forward layer, which consists of two linear projections each followed by leaky ReLU activations \\citep{maas2012rectifier}.",
      "tex_start": 20280,
      "tex_end": 20516,
      "text": "The outputs of all attention heads for each token are concatenated, and this representation is passed to the feed-forward layer, which consists of two linear projections each followed by leaky ReLU activations Citation (maas2012rectifier)."
    },
    "relationships": {}
  },
  {
    "id": "3096932",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.45962,
          "width": 0.302521,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.444181,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.427553,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.368067,
          "top": 0.412114,
          "width": 0.119328,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We add the output of the feed-forward to the initial representation and apply layer normalization to give the final output of self-attention layer $j$, as in Eqn.",
      "tex_start": 20517,
      "tex_end": 20679,
      "text": "We add the output of the feed-forward to the initial representation and apply layer normalization to give the final output of self-attention layer EQUATION_DEPTH_0_START j EQUATION_DEPTH_0_END , as in Eqn."
    },
    "relationships": {}
  },
  {
    "id": "3096933",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.442017,
          "top": 0.466746,
          "width": 0.00168067,
          "height": 0.00118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\ref{eqn:overall}.",
      "tex_start": 20680,
      "tex_end": 20698,
      "text": "(Ref eqn:overall)."
    },
    "relationships": {}
  },
  {
    "id": "3096934",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.485748,
          "width": 0.32605,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Syntactically-informed self-attention \\label{sec:syntax-attn}}",
      "tex_start": 20698,
      "tex_end": 20774,
      "text": "Syntactically-informed self-attention \\label{sec:syntax-attn."
    },
    "relationships": {}
  },
  {
    "id": "3096935",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.524941,
          "width": 0.334454,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.508314,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Typically, neural attention mechanisms are left on their own to learn to attend to relevant inputs.",
      "tex_start": 20775,
      "tex_end": 20874,
      "text": "Typically, neural attention mechanisms are left on their own to learn to attend to relevant inputs."
    },
    "relationships": {}
  },
  {
    "id": "3096936",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.589074,
          "width": 0.319328,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.573634,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.557007,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.54038,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.467227,
          "top": 0.524941,
          "width": 0.0201681,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Instead, we propose training the self-attention to attend to specific tokens corresponding to the syntactic structure of the sentence as a mechanism for passing linguistic knowledge to later layers.",
      "tex_start": 20875,
      "tex_end": 21073,
      "text": "Instead, we propose training the self-attention to attend to specific tokens corresponding to the syntactic structure of the sentence as a mechanism for passing linguistic knowledge to later layers."
    },
    "relationships": {}
  },
  {
    "id": "3096937",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.637767,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.62114,
          "width": 0.206723,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.141176,
          "top": 0.605701,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Specifically, we replace one attention head with the deep bi-affine model of \\citet{dozat2017deep}, trained to predict syntactic dependencies.",
      "tex_start": 21076,
      "tex_end": 21218,
      "text": "Specifically, we replace one attention head with the deep bi-affine model of Citation (dozat2017deep), trained to predict syntactic dependencies."
    },
    "relationships": {}
  },
  {
    "id": "3096938",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.672209,
          "width": 0.010084,
          "height": 0.00593824
        },
        {
          "page": 3,
          "left": 0.12437,
          "top": 0.669834,
          "width": 0.00168067,
          "height": 0.00118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.653207,
          "width": 0.366387,
          "height": 0.0130641
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Let $A_{parse}$ be the parse attention weights, at layer $i$.",
      "tex_start": 21219,
      "tex_end": 21280,
      "text": "Let EQUATION_DEPTH_0_START A_{parse} EQUATION_DEPTH_0_END be the parse attention weights, at layer EQUATION_DEPTH_0_START i EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096939",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.684085,
          "width": 0.0487395,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.142857,
          "top": 0.669834,
          "width": 0.344538,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Its input is the matrix of token representations $S^{(i-1)}$.",
      "tex_start": 21281,
      "tex_end": 21342,
      "text": "Its input is the matrix of token representations EQUATION_DEPTH_0_START S^{(i-1)} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096940",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.71734,
          "width": 0.292437,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.699525,
          "width": 0.366387,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.191597,
          "top": 0.686461,
          "width": 0.295798,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "As with the other attention heads, we project $S^{(i-1)}$ into key, value and query representations, denoted $K_{parse}$, $Q_{parse}$, $V_{parse}$.",
      "tex_start": 21343,
      "tex_end": 21490,
      "text": "As with the other attention heads, we project EQUATION_DEPTH_0_START S^{(i-1)} EQUATION_DEPTH_0_END into key, value and query representations, denoted EQUATION_DEPTH_0_START K_{parse} EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START Q_{parse} EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START V_{parse} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096941",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.7981,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.78266,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.766033,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.749406,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.733967,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.426891,
          "top": 0.718527,
          "width": 0.0605042,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Here the key and query projections correspond to $parent$ and $dependent$ representations of the tokens, and we allow their dimensions to differ from the rest of the attention heads to more closely follow the implementation of \\citet{dozat2017deep}.",
      "tex_start": 21491,
      "tex_end": 21740,
      "text": "Here the key and query projections correspond to EQUATION_DEPTH_0_START parent EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START dependent EQUATION_DEPTH_0_END representations of the tokens, and we allow their dimensions to differ from the rest of the attention heads to more closely follow the implementation of Citation (dozat2017deep)."
    },
    "relationships": {}
  },
  {
    "id": "3096942",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.144538,
          "top": 0.889549,
          "width": 0.342857,
          "height": 0.0178147
        },
        {
          "page": 3,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.317647,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.845606,
          "width": 0.364706,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.831354,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.122689,
          "top": 0.814727,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.460504,
          "top": 0.7981,
          "width": 0.0268908,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.111639,
          "width": 0.270588,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.0950119,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.0795724,
          "width": 0.368067,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Unlike the other attention heads which use a dot product to score key-query pairs, we score the compatibility between $K_{parse}$ and $Q_{parse}$ using a bi-affine operator $U_{heads}$ to obtain attention weights:\n\\begin{align}\nA_{parse} = \\mathrm{softmax}(Q_{parse} U_{heads} K_{parse}^T)\n\\end{align}\nThese attention weights are used to compose a weighted average of the value representations $V_{parse}$ as in the other attention heads.",
      "tex_start": 21741,
      "tex_end": 22179,
      "text": "Unlike the other attention heads which use a dot product to score key-query pairs, we score the compatibility between EQUATION_DEPTH_0_START K_{parse} EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START Q_{parse} EQUATION_DEPTH_0_END using a bi-affine operator EQUATION_DEPTH_0_START U_{heads} EQUATION_DEPTH_0_END to obtain attention weights: EQUATION_DEPTH_0_START A_{parse} = \\mathrm{softmax}(Q_{parse} U_{heads} K_{parse}^T)\nEQUATION_DEPTH_0_END These attention weights are used to compose a weighted average of the value representations EQUATION_DEPTH_0_START V_{parse} EQUATION_DEPTH_0_END as in the other attention heads."
    },
    "relationships": {}
  },
  {
    "id": "3096943",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.175772,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.160333,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.143705,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.536134,
          "top": 0.128266,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We apply auxiliary supervision at this attention head to encourage it to attend to each token's parent in a syntactic dependency tree, and to encode information about the token's dependency label.",
      "tex_start": 22181,
      "tex_end": 22377,
      "text": "We apply auxiliary supervision at this attention head to encourage it to attend to each token's parent in a syntactic dependency tree, and to encode information about the token's dependency label."
    },
    "relationships": {}
  },
  {
    "id": "3096944",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.299287,
          "width": 0.282353,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.28266,
          "width": 0.364706,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.571429,
          "top": 0.252969,
          "width": 0.310924,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.224466,
          "width": 0.297479,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.206651,
          "width": 0.368067,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Denoting the attention weight from token $t$ to a candidate head $q$ as $A_{parse}[t,q]$, we model the probability of token $t$ having parent $q$ as:\n\\begin{align}\nP(q=\\mathrm{head}(t) \\mid \\mathcal{X}) = A_{parse}[t, q]\n\\end{align}\nusing the attention weights $A_{parse}[t]$ as the distribution over possible heads for token $t$.",
      "tex_start": 22378,
      "tex_end": 22708,
      "text": "Denoting the attention weight from token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END to a candidate head EQUATION_DEPTH_0_START q EQUATION_DEPTH_0_END as EQUATION_DEPTH_0_START A_{parse}[t,q] EQUATION_DEPTH_0_END , we model the probability of token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END having parent EQUATION_DEPTH_0_START q EQUATION_DEPTH_0_END as: EQUATION_DEPTH_0_START P(q=\\mathrm{head}(t) \\mid \\mathcal{X}) = A_{parse}[t, q]\nEQUATION_DEPTH_0_END using the attention weights EQUATION_DEPTH_0_START A_{parse}[t] EQUATION_DEPTH_0_END as the distribution over possible heads for token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096945",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.315914,
          "width": 0.272269,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.810084,
          "top": 0.299287,
          "width": 0.0739496,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We define the root token as having a self-loop.",
      "tex_start": 22709,
      "tex_end": 22756,
      "text": "We define the root token as having a self-loop."
    },
    "relationships": {}
  },
  {
    "id": "3096946",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.862233,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.846793,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.830166,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.814727,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.7981,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.78266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.766033,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.750594,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.733967,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.718527,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.7019,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.679335,
          "width": 0.193277,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.653207,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.637767,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.62114,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.605701,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.589074,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.573634,
          "width": 0.364706,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.557007,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.541568,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.524941,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.509501,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.534454,
          "top": 0.492874,
          "width": 0.34958,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.620168,
          "top": 0.476247,
          "width": 0.171429,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.460808,
          "width": 0.315966,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.440618,
          "width": 0.366387,
          "height": 0.0154394
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.428741,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.410926,
          "width": 0.366387,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.396675,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.536134,
          "top": 0.380048,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.331354,
          "width": 0.268908,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.801681,
          "top": 0.315914,
          "width": 0.0806723,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This attention head thus emits a directed graph\\footnote{Usually the head emits a tree, but we do not enforce it here.",
      "tex_start": 22757,
      "tex_end": 22875,
      "text": "This attention head thus emits a directed graphUsually the head emits a tree, but we do not enforce it here."
    },
    "relationships": {}
  },
  {
    "id": "3096947",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.36342,
          "width": 0.248739,
          "height": 0.0130641
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.347981,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.801681,
          "top": 0.331354,
          "width": 0.0806723,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "where each token's parent is the token to which the attention $A_{parse}$ assigns the highest weight.",
      "tex_start": 22877,
      "tex_end": 22978,
      "text": "where each token's parent is the token to which the attention EQUATION_DEPTH_0_START A_{parse} EQUATION_DEPTH_0_END assigns the highest weight."
    },
    "relationships": {}
  },
  {
    "id": "3096948",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.460808,
          "width": 0.152941,
          "height": 0.00831354
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.440618,
          "width": 0.366387,
          "height": 0.0154394
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.428741,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.410926,
          "width": 0.366387,
          "height": 0.0142518
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.396675,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.536134,
          "top": 0.380048,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also predict dependency labels using per-class bi-affine operations between parent and dependent representations $Q_{parse}$ and $K_{parse}$ to produce per-label scores, with locally normalized probabilities over dependency labels $y_t^{dep}$ given by the softmax function.",
      "tex_start": 22981,
      "tex_end": 23257,
      "text": "We also predict dependency labels using per-class bi-affine operations between parent and dependent representations EQUATION_DEPTH_0_START Q_{parse} EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START K_{parse} EQUATION_DEPTH_0_END to produce per-label scores, with locally normalized probabilities over dependency labels EQUATION_DEPTH_0_START y_t^{dep} EQUATION_DEPTH_0_END given by the softmax function."
    },
    "relationships": {}
  },
  {
    "id": "3096949",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.620168,
          "top": 0.476247,
          "width": 0.171429,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.678992,
          "top": 0.460808,
          "width": 0.154622,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We refer the reader to \\citet{dozat2017deep} for more details.",
      "tex_start": 23258,
      "tex_end": 23320,
      "text": "We refer the reader to Citation (dozat2017deep) for more details."
    },
    "relationships": {}
  },
  {
    "id": "3096950",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.524941,
          "width": 0.163025,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.509501,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.534454,
          "top": 0.492874,
          "width": 0.34958,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This attention head now becomes an oracle for syntax, denoted $\\mathcal{P}$, providing a dependency parse to downstream layers.",
      "tex_start": 23322,
      "tex_end": 23449,
      "text": "This attention head now becomes an oracle for syntax, denoted EQUATION_DEPTH_0_START \\mathcal{P} EQUATION_DEPTH_0_END , providing a dependency parse to downstream layers."
    },
    "relationships": {}
  },
  {
    "id": "3096951",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.589074,
          "width": 0.27563,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.573634,
          "width": 0.364706,
          "height": 0.0118765
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.557007,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.541568,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.692437,
          "top": 0.524941,
          "width": 0.189916,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This model not only predicts its own dependency arcs, but allows for the injection of auxiliary parse information at test time by simply setting $A_{parse}$ to the parse parents produced by e.g.\\ a state-of-the-art parser.",
      "tex_start": 23450,
      "tex_end": 23672,
      "text": "This model not only predicts its own dependency arcs, but allows for the injection of auxiliary parse information at test time by simply setting EQUATION_DEPTH_0_START A_{parse} EQUATION_DEPTH_0_END to the parse parents produced by e.g. a state-of-the-art parser."
    },
    "relationships": {}
  },
  {
    "id": "3096952",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.62114,
          "width": 0.263866,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.605701,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.8,
          "top": 0.589074,
          "width": 0.0823529,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In this way, our model can benefit from improved, external parsing models without re-training.",
      "tex_start": 23673,
      "tex_end": 23767,
      "text": "In this way, our model can benefit from improved, external parsing models without re-training."
    },
    "relationships": {}
  },
  {
    "id": "3096953",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.653207,
          "width": 0.305882,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.637767,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.793277,
          "top": 0.62114,
          "width": 0.0890756,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Unlike typical multi-task models, ours maintains the ability to leverage external syntactic information.",
      "tex_start": 23973,
      "tex_end": 24077,
      "text": "Unlike typical multi-task models, ours maintains the ability to leverage external syntactic information."
    },
    "relationships": {}
  },
  {
    "id": "3096954",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.679335,
          "width": 0.193277,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\subsection{Multi-task learning \\label{sec:MTL}}",
      "tex_start": 25724,
      "tex_end": 25773,
      "text": "Multi-task learning \\label{sec:MTL."
    },
    "relationships": {}
  },
  {
    "id": "3096955",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.718527,
          "width": 0.322689,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.7019,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also share the parameters of lower layers in our model to predict POS tags and predicates.",
      "tex_start": 25774,
      "tex_end": 25867,
      "text": "We also share the parameters of lower layers in our model to predict POS tags and predicates."
    },
    "relationships": {}
  },
  {
    "id": "3096956",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.766033,
          "width": 0.0756303,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.750594,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.733967,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.853782,
          "top": 0.718527,
          "width": 0.0285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Following \\citet{he2017deep}, we focus on the end-to-end setting, %which most closely resembles SRL ``in the wild,'' \nwhere predicates must be predicted on-the-fly.",
      "tex_start": 25868,
      "tex_end": 26032,
      "text": "Following Citation (he2017deep), we focus on the end-to-end setting, where predicates must be predicted on-the-fly."
    },
    "relationships": {}
  },
  {
    "id": "3096957",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.7981,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.78266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.615126,
          "top": 0.766033,
          "width": 0.267227,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Since we also train our model to predict syntactic dependencies, it is beneficial to give the model knowledge of POS information.",
      "tex_start": 26033,
      "tex_end": 26162,
      "text": "Since we also train our model to predict syntactic dependencies, it is beneficial to give the model knowledge of POS information."
    },
    "relationships": {}
  },
  {
    "id": "3096958",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.862233,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.846793,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.515966,
          "top": 0.830166,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 3,
          "left": 0.517647,
          "top": 0.814727,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.12437,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.157983,
          "top": 0.0795724,
          "width": 0.329412,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "While much previous work employs a pipelined approach to both POS tagging for dependency parsing and predicate detection for SRL, we take a multi-task learning (MTL) approach \\citep{caruana1993multitask}, sharing the parameters of earlier layers in our SRL model with a joint POS and predicate detection objective.",
      "tex_start": 26163,
      "tex_end": 26477,
      "text": "While much previous work employs a pipelined approach to both POS tagging for dependency parsing and predicate detection for SRL, we take a multi-task learning (MTL) approach Citation (caruana1993multitask), sharing the parameters of earlier layers in our SRL model with a joint POS and predicate detection objective."
    },
    "relationships": {}
  },
  {
    "id": "3096959",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.846793,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.776722,
          "width": 0.107563,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.751781,
          "width": 0.317647,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.735154,
          "width": 0.366387,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.719715,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.703088,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.685273,
          "width": 0.228571,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.669834,
          "width": 0.363025,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.638955,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.226891,
          "top": 0.590261,
          "width": 0.260504,
          "height": 0.0178147
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.562945,
          "width": 0.342857,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.548694,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.532067,
          "width": 0.364706,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.516627,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.497625,
          "width": 0.366387,
          "height": 0.0142518
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.47981,
          "width": 0.364706,
          "height": 0.0154394
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.461995,
          "width": 0.342857,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.448931,
          "width": 0.231933,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.432304,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.416865,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.400238,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.384798,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.368171,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.346793,
          "width": 0.236975,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.320665,
          "width": 0.166387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.30285,
          "width": 0.364706,
          "height": 0.0142518
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.288599,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.271971,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.256532,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.239905,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.219715,
          "width": 0.342857,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.128266,
          "width": 0.121008,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.262185,
          "top": 0.111639,
          "width": 0.22521,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Since POS is a strong predictor of predicates\\footnote{All predicates in CoNLL-2005 are verbs; CoNLL-2012 includes some nominal predicates.",
      "tex_start": 26478,
      "tex_end": 26617,
      "text": "Since POS is a strong predictor of predicatesAll predicates in CoNLL-2005 are verbs; CoNLL-2012 includes some nominal predicates."
    },
    "relationships": {}
  },
  {
    "id": "3096960",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.207838,
          "width": 0.363025,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.175772,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.160333,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.143705,
          "width": 0.368067,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.258824,
          "top": 0.128266,
          "width": 0.228571,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "and the complexity of training a multi-task model increases with the number of tasks, we combine POS tagging and predicate detection into a joint label space: For each POS tag {\\sc tag} which is observed co-occurring with a predicate, we add a label of the form {\\sc tag:predicate}.",
      "tex_start": 26620,
      "tex_end": 26902,
      "text": "and the complexity of training a multi-task model increases with the number of tasks, we combine POS tagging and predicate detection into a joint label space: For each POS tag tag which is observed co-occurring with a predicate, we add a label of the form tag:predicate."
    },
    "relationships": {}
  },
  {
    "id": "3096961",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.271971,
          "width": 0.263866,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.256532,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.239905,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.219715,
          "width": 0.342857,
          "height": 0.0166271
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Specifically, we feed the representation $s_t^{(r)}$ from a layer $r$ preceding the syntactically-informed layer $p$ to a linear classifier to produce per-class scores $r_t$ for token $t$.",
      "tex_start": 27024,
      "tex_end": 27212,
      "text": "Specifically, we feed the representation EQUATION_DEPTH_0_START s_t^{(r)} EQUATION_DEPTH_0_END from a layer EQUATION_DEPTH_0_START r EQUATION_DEPTH_0_END preceding the syntactically-informed layer EQUATION_DEPTH_0_START p EQUATION_DEPTH_0_END to a linear classifier to produce per-class scores EQUATION_DEPTH_0_START r_t EQUATION_DEPTH_0_END for token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096962",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.320665,
          "width": 0.166387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.30285,
          "width": 0.364706,
          "height": 0.0142518
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.288599,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.396639,
          "top": 0.271971,
          "width": 0.0907563,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We compute locally-normalized probabilities using the softmax function: $P(y_t^{prp} \\mid \\mathcal{X}) \\propto \\exp(r_t)$, where $y_t^{prp}$ is a label in the joint space.",
      "tex_start": 27213,
      "tex_end": 27384,
      "text": "We compute locally-normalized probabilities using the softmax function: EQUATION_DEPTH_0_START P(y_t^{prp} \\mid \\mathcal{X}) \\propto \\exp(r_t) EQUATION_DEPTH_0_END , where EQUATION_DEPTH_0_START y_t^{prp} EQUATION_DEPTH_0_END is a label in the joint space."
    },
    "relationships": {}
  },
  {
    "id": "3096963",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.346793,
          "width": 0.236975,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\subsection{Predicting semantic roles \\label{sec:srl}}",
      "tex_start": 27543,
      "tex_end": 27598,
      "text": "Predicting semantic roles \\label{sec:srl."
    },
    "relationships": {}
  },
  {
    "id": "3096964",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.384798,
          "width": 0.184874,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.368171,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our final goal is to predict semantic roles for each predicate in the sequence.",
      "tex_start": 27599,
      "tex_end": 27678,
      "text": "Our final goal is to predict semantic roles for each predicate in the sequence."
    },
    "relationships": {}
  },
  {
    "id": "3096965",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.448931,
          "width": 0.231933,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.432304,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.416865,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.400238,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.314286,
          "top": 0.384798,
          "width": 0.173109,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We score each predicate\n%\\footnote{CoNLL-2012 contains only single-word predicates. In CoNLL-2005, some predicates are multi-word verbs, such as ``sign up.'' In this case, we drop the particle.} \nagainst each token in the sequence using a bilinear operation, producing per-label scores for each token for each predicate, with predicates and syntax determined by oracles $\\mathcal{V}$ and $\\mathcal{P}$.",
      "tex_start": 27679,
      "tex_end": 28081,
      "text": "We score each predicate against each token in the sequence using a bilinear operation, producing per-label scores for each token for each predicate, with predicates and syntax determined by oracles EQUATION_DEPTH_0_START \\mathcal{V} EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START \\mathcal{P} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096966",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.497625,
          "width": 0.240336,
          "height": 0.0142518
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.47981,
          "width": 0.364706,
          "height": 0.0154394
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.461995,
          "width": 0.342857,
          "height": 0.0166271
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "First, we project each token representation $s_t^{(J)}$ to a predicate-specific representation $s_t^{pred}$ and a role-specific representation $s_t^{role}$.",
      "tex_start": 28084,
      "tex_end": 28240,
      "text": "First, we project each token representation EQUATION_DEPTH_0_START s_t^{(J)} EQUATION_DEPTH_0_END to a predicate-specific representation EQUATION_DEPTH_0_START s_t^{pred} EQUATION_DEPTH_0_END and a role-specific representation EQUATION_DEPTH_0_START s_t^{role} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096967",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.532067,
          "width": 0.10084,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.516627,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.369748,
          "top": 0.5,
          "width": 0.117647,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We then provide these representations to a bilinear transformation $U$ for scoring.",
      "tex_start": 28396,
      "tex_end": 28479,
      "text": "We then provide these representations to a bilinear transformation EQUATION_DEPTH_0_START U EQUATION_DEPTH_0_END for scoring."
    },
    "relationships": {}
  },
  {
    "id": "3096968",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.638955,
          "width": 0.267227,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.226891,
          "top": 0.590261,
          "width": 0.260504,
          "height": 0.0178147
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.562945,
          "width": 0.342857,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.548694,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.233613,
          "top": 0.532067,
          "width": 0.253782,
          "height": 0.0130641
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "So, the role label scores $s_{ft}$ for the token at index $t$ with respect to the predicate at index $f$ (i.e. token $t$ and frame $f$) are given by:\n\\begin{align}\n\\label{eqn:bilinear}\ns_{ft} = (s_f^{pred})^T U s_t^{role}\n\\end{align}\nwhich can be computed in parallel across all semantic frames in an entire minibatch.",
      "tex_start": 28480,
      "tex_end": 28798,
      "text": "So, the role label scores EQUATION_DEPTH_0_START s_{ft} EQUATION_DEPTH_0_END for the token at index EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END with respect to the predicate at index EQUATION_DEPTH_0_START f EQUATION_DEPTH_0_END (i.e. token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END and frame EQUATION_DEPTH_0_START f EQUATION_DEPTH_0_END ) are given by: EQUATION_DEPTH_0_START \\label{eqn:bilinear}\ns_{ft} = (s_f^{pred})^T U s_t^{role}\nEQUATION_DEPTH_0_END which can be computed in parallel across all semantic frames in an entire minibatch."
    },
    "relationships": {}
  },
  {
    "id": "3096969",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.685273,
          "width": 0.228571,
          "height": 0.0166271
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.669834,
          "width": 0.363025,
          "height": 0.0118765
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.654394,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.396639,
          "top": 0.638955,
          "width": 0.0907563,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We calculate a locally normalized distribution over role labels for token $t$ in frame $f$ using the softmax function: $P(y_{ft}^{role}\\mid \\mathcal{P},\\mathcal{V}, \\mathcal{X}) \\propto \\exp(s_{ft})$.",
      "tex_start": 28799,
      "tex_end": 28999,
      "text": "We calculate a locally normalized distribution over role labels for token EQUATION_DEPTH_0_START t EQUATION_DEPTH_0_END in frame EQUATION_DEPTH_0_START f EQUATION_DEPTH_0_END using the softmax function: EQUATION_DEPTH_0_START P(y_{ft}^{role}\\mid \\mathcal{P},\\mathcal{V}, \\mathcal{X}) \\propto \\exp(s_{ft}) EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096970",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.751781,
          "width": 0.317647,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.735154,
          "width": 0.366387,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.719715,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.141176,
          "top": 0.703088,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "At test time, we perform constrained decoding using the Viterbi algorithm to emit valid sequences of BIO tags, using unary scores $s_{ft}$ and the transition probabilities given by the training data.",
      "tex_start": 29001,
      "tex_end": 29200,
      "text": "At test time, we perform constrained decoding using the Viterbi algorithm to emit valid sequences of BIO tags, using unary scores EQUATION_DEPTH_0_START s_{ft} EQUATION_DEPTH_0_END and the transition probabilities given by the training data."
    },
    "relationships": {}
  },
  {
    "id": "3096971",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.776722,
          "width": 0.107563,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\subsection{Training \\label{sec:train-opt}}",
      "tex_start": 29265,
      "tex_end": 29308,
      "text": "Training \\label{sec:train-opt."
    },
    "relationships": {}
  },
  {
    "id": "3096972",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.105882,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We maximize the sum of the likelihoods of the individual tasks.",
      "tex_start": 29309,
      "tex_end": 29372,
      "text": "We maximize the sum of the likelihoods of the individual tasks."
    },
    "relationships": {}
  },
  {
    "id": "3096973",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.86342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.846793,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.238655,
          "top": 0.814727,
          "width": 0.248739,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.111639,
          "width": 0.332773,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.0950119,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.0795724,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In order to maximize our model's ability to leverage syntax, during training we clamp $\\mathcal{P}$ to the gold parse ($\\mathcal{P}_G$) and $\\mathcal{V}$ to gold predicates $\\mathcal{V}_G$ when passing parse and predicate representations to later layers, whereas syntactic head prediction and joint predicate/POS prediction are conditioned only on the input sequence $\\mathcal{X}$.",
      "tex_start": 29532,
      "tex_end": 29913,
      "text": "In order to maximize our model's ability to leverage syntax, during training we clamp EQUATION_DEPTH_0_START \\mathcal{P} EQUATION_DEPTH_0_END to the gold parse ( EQUATION_DEPTH_0_START \\mathcal{P}_G EQUATION_DEPTH_0_END ) and EQUATION_DEPTH_0_START \\mathcal{V} EQUATION_DEPTH_0_END to gold predicates EQUATION_DEPTH_0_START \\mathcal{V}_G EQUATION_DEPTH_0_END when passing parse and predicate representations to later layers, whereas syntactic head prediction and joint predicate/POS prediction are conditioned only on the input sequence EQUATION_DEPTH_0_START \\mathcal{X} EQUATION_DEPTH_0_END."
    },
    "relationships": {}
  },
  {
    "id": "3096974",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.296912,
          "width": 0.0857143,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.280285,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.62521,
          "top": 0.24228,
          "width": 0.257143,
          "height": 0.0225653
        },
        {
          "page": 4,
          "left": 0.62521,
          "top": 0.22209,
          "width": 0.181513,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.62521,
          "top": 0.203088,
          "width": 0.132773,
          "height": 0.0130641
        },
        {
          "page": 4,
          "left": 0.563025,
          "top": 0.155582,
          "width": 0.27395,
          "height": 0.04038
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.128266,
          "width": 0.176471,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.855462,
          "top": 0.111639,
          "width": 0.0285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The overall objective is thus:\n%while still training $A_{parse}$ to predict syntactic heads. Similarly, we condition on gold predicates $\\mathcal{V}_G$ during training. \n\\begin{align}\n\\frac{1}{T}\\sum_{t=1}^T\\Big[&\\sum_{f=1}^F \\log P(y_{ft}^{role}\\mid \\mathcal{P}_G, \\mathcal{V}_G, \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:srl-term} \\\\ \n&+ \\log P(y_t^{prp}\\mid \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:predpos-term}\\\\ \n% &+ \\lambda\\sum_{q=1}^T \\log P(q=\\mathrm{head}(t)\\mid \\mathcal{X}) \\Big]\n&+ \\lambda_1 \\log P(\\mathrm{head}(t)\\mid \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:head-term}\\\\\n&+ \\lambda_2 \\log P(y_t^{dep} \\mid \\mathcal{P}_G, \\mathcal{X}) \\label{eqn:rel-term} \\Big]\n\\end{align}\nwhere $\\lambda_1$ and $\\lambda_2$ are penalties on the syntactic attention loss.",
      "tex_start": 29914,
      "tex_end": 30674,
      "text": "The overall objective is thus: EQUATION_DEPTH_0_START \\frac{1}{T}\\sum_{t=1}^T\\Big[&\\sum_{f=1}^F \\log P(y_{ft}^{role}\\mid \\mathcal{P}_G, \\mathcal{V}_G, \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:srl-term} \\\\ \n&+ \\log P(y_t^{prp}\\mid \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:predpos-term}\\\\ \n% &+ \\lambda\\sum_{q=1}^T \\log P(q=\\mathrm{head}(t)\\mid \\mathcal{X}) \\Big]\n&+ \\lambda_1 \\log P(\\mathrm{head}(t)\\mid \\mathcal{X}) \\nonumber \\\\ %\\label{eqn:head-term}\\\\\n&+ \\lambda_2 \\log P(y_t^{dep} \\mid \\mathcal{P}_G, \\mathcal{X}) \\label{eqn:rel-term} \\Big]\nEQUATION_DEPTH_0_END where EQUATION_DEPTH_0_START \\lambda_1 EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START \\lambda_2 EQUATION_DEPTH_0_END are penalties on the syntactic attention loss."
    },
    "relationships": {}
  },
  {
    "id": "3096975",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.623529,
          "top": 0.344418,
          "width": 0.0504202,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.328979,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.536134,
          "top": 0.312352,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We train the model using Nadam \\citep{dozat2016incorporating} SGD combined with the learning rate schedule in \\citet{vaswani2017attention}.",
      "tex_start": 31024,
      "tex_end": 31163,
      "text": "We train the model using Nadam Citation (dozat2016incorporating) SGD combined with the learning rate schedule in Citation (vaswani2017attention)."
    },
    "relationships": {}
  },
  {
    "id": "3096976",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.552941,
          "top": 0.377672,
          "width": 0.010084,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.361045,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.682353,
          "top": 0.344418,
          "width": 0.2,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In addition to MTL, we regularize our model using dropout \\citep{srivastava2014dropout}.",
      "tex_start": 31164,
      "tex_end": 31252,
      "text": "In addition to MTL, we regularize our model using dropout Citation (srivastava2014dropout)."
    },
    "relationships": {}
  },
  {
    "id": "3096977",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.552941,
          "top": 0.410926,
          "width": 0.010084,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.393112,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.573109,
          "top": 0.376485,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We use gradient clipping to avoid exploding gradients \\citep{bengio1994learning, pascanu2013on}.",
      "tex_start": 31253,
      "tex_end": 31349,
      "text": "We use gradient clipping to avoid exploding gradients Citation (bengio1994learning, pascanu2013on)."
    },
    "relationships": {}
  },
  {
    "id": "3096978",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.425178,
          "width": 0.315966,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.571429,
          "top": 0.409739,
          "width": 0.310924,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Additional details on optimization and hyperparameters are included in Appendix \\ref{sec:supplemental}.",
      "tex_start": 31350,
      "tex_end": 31453,
      "text": "Additional details on optimization and hyperparameters are included in Appendix (Ref sec:supplemental)."
    },
    "relationships": {}
  },
  {
    "id": "3096979",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.452494,
          "width": 0.144538,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\section{Related work}\n\n% Semantic role labeling\n%The CoNLL-2005 shared task \\citep{carreras2005introduction} spearheaded machine learning approaches to SRL by providing a relatively large corpus annotated with predicate-argument structure in the style of PropBank \\citep{palmer2005proposition}. \n",
      "tex_start": 33273,
      "tex_end": 33571,
      "text": "Related work."
    },
    "relationships": {}
  },
  {
    "id": "3096980",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.554622,
          "top": 0.577197,
          "width": 0.0537815,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.559382,
          "width": 0.27395,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.543943,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.527316,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.554622,
          "top": 0.511876,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.636975,
          "top": 0.502375,
          "width": 0.245378,
          "height": 0.0023753
        },
        {
          "page": 4,
          "left": 0.689076,
          "top": 0.497625,
          "width": 0.00168067,
          "height": 0.00118765
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.47981,
          "width": 0.363025,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Early approaches to SRL \\citep{pradhan2005semantic,surdeanu2007combination,johansson2008dependency,toutanova2008global} focused on developing rich sets of linguistic features as input to a linear model, often combined with complex constrained inference e.g. with an ILP \\citep{punyakanok2008importance}.",
      "tex_start": 33571,
      "tex_end": 33874,
      "text": "Early approaches to SRL Citation (pradhan2005semantic,surdeanu2007combination,johansson2008dependency,toutanova2008global) focused on developing rich sets of linguistic features as input to a linear model, often combined with complex constrained inference e.g. with an ILP Citation (punyakanok2008importance)."
    },
    "relationships": {}
  },
  {
    "id": "3096981",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.608076,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.591449,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.742857,
          "top": 0.57601,
          "width": 0.139496,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{tackstrom2015efficient} showed that constraints could be enforced more efficiently using a clever dynamic program for exact inference.",
      "tex_start": 33875,
      "tex_end": 34016,
      "text": "Citation (tackstrom2015efficient) showed that constraints could be enforced more efficiently using a clever dynamic program for exact inference."
    },
    "relationships": {}
  },
  {
    "id": "3096982",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.514286,
          "top": 0.65677,
          "width": 0.290756,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.640143,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.692437,
          "top": 0.623515,
          "width": 0.189916,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{sutton2005joint} modeled syntactic parsing and SRL jointly, and \\citet{lewis2015joint} jointly modeled SRL and CCG parsing.",
      "tex_start": 34087,
      "tex_end": 34217,
      "text": "Citation (sutton2005joint) modeled syntactic parsing and SRL jointly, and Citation (lewis2015joint) jointly modeled SRL and CCG parsing."
    },
    "relationships": {}
  },
  {
    "id": "3096983",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.720903,
          "width": 0.142857,
          "height": 0.00831354
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.704276,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.688836,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 4,
          "left": 0.655462,
          "top": 0.672209,
          "width": 0.226891,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{collobert2011natural} were among the first to use a neural network model for SRL, a CNN over word embeddings which failed to out-perform non-neural models.",
      "tex_start": 34937,
      "tex_end": 35099,
      "text": "Citation (collobert2011natural) were among the first to use a neural network model for SRL, a CNN over word embeddings which failed to out-perform non-neural models."
    },
    "relationships": {}
  },
  {
    "id": "3096984",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.769596,
          "width": 0.344538,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.752969,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.736342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.8,
          "top": 0.720903,
          "width": 0.0823529,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{fitzgerald2015semantic} successfully employed neural networks by embedding lexicalized features and providing them as factors in the model of \\citet{tackstrom2015efficient}.",
      "tex_start": 35242,
      "tex_end": 35422,
      "text": "Citation (fitzgerald2015semantic) successfully employed neural networks by embedding lexicalized features and providing them as factors in the model of Citation (tackstrom2015efficient)."
    },
    "relationships": {}
  },
  {
    "id": "3096985",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.536134,
          "top": 0.785036,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "More recent neural models are syntax-free.",
      "tex_start": 35572,
      "tex_end": 35614,
      "text": "More recent neural models are syntax-free."
    },
    "relationships": {}
  },
  {
    "id": "3096986",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.865796,
          "width": 0.243697,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.557983,
          "top": 0.849169,
          "width": 0.32437,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.517647,
          "top": 0.833729,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.817102,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.62521,
          "top": 0.801663,
          "width": 0.257143,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{zhou2015end}, \\citet{marcheggiani2017simple} and \\citet{he2017deep} all use variants of deep LSTMs with constrained decoding, while \\citet{tan2018deep} apply self-attention to obtain state-of-the-art SRL with gold predicates.",
      "tex_start": 35615,
      "tex_end": 35847,
      "text": "Citation (zhou2015end), Citation (marcheggiani2017simple) and Citation (he2017deep) all use variants of deep LSTMs with constrained decoding, while Citation (tan2018deep) apply self-attention to obtain state-of-the-art SRL with gold predicates."
    },
    "relationships": {}
  },
  {
    "id": "3096987",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 4,
          "left": 0.515966,
          "top": 0.897862,
          "width": 0.302521,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.589916,
          "top": 0.882423,
          "width": 0.292437,
          "height": 0.0106888
        },
        {
          "page": 4,
          "left": 0.773109,
          "top": 0.865796,
          "width": 0.109244,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.111639,
          "width": 0.322689,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.0795724,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Like this work, \\citet{he2017deep} present end-to-end experiments, predicting predicates using an LSTM, and \\citet{he2018jointly} jointly predict SRL spans and predicates in a model based on that of \\citet{lee2017end}, obtaining state-of-the-art predicted predicate SRL.",
      "tex_start": 35848,
      "tex_end": 36118,
      "text": "Like this work, Citation (he2017deep) present end-to-end experiments, predicting predicates using an LSTM, and Citation (he2018jointly) jointly predict SRL spans and predicates in a model based on that of Citation (lee2017end), obtaining state-of-the-art predicted predicate SRL."
    },
    "relationships": {}
  },
  {
    "id": "3096988",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.224466,
          "width": 0.092437,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.207838,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.175772,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.160333,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.164706,
          "top": 0.143705,
          "width": 0.322689,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.128266,
          "width": 0.337815,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.45042,
          "top": 0.111639,
          "width": 0.0369748,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Concurrent to this work, \\citet{peters2018deep} and \\citet{he2018jointly} report significant gains on PropBank SRL by training a wide LSTM language model and using a task-specific transformation of its hidden representations (ELMo) as a deep, and computationally expensive, alternative to typical word embeddings.",
      "tex_start": 36119,
      "tex_end": 36432,
      "text": "Concurrent to this work, Citation (peters2018deep) and Citation (he2018jointly) report significant gains on PropBank SRL by training a wide LSTM language model and using a task-specific transformation of its hidden representations (ELMo) as a deep, and computationally expensive, alternative to typical word embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3096989",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.256532,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.239905,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.221849,
          "top": 0.224466,
          "width": 0.265546,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We find that LISA obtains further accuracy increases when provided with ELMo word representations, especially on out-of-domain data.",
      "tex_start": 36433,
      "tex_end": 36565,
      "text": "We find that LISA obtains further accuracy increases when provided with ELMo word representations, especially on out-of-domain data."
    },
    "relationships": {}
  },
  {
    "id": "3096990",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.293349,
          "width": 0.151261,
          "height": 0.00831354
        },
        {
          "page": 5,
          "left": 0.141176,
          "top": 0.276722,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Some work has incorporated syntax into neural models for SRL.",
      "tex_start": 36764,
      "tex_end": 36825,
      "text": "Some work has incorporated syntax into neural models for SRL."
    },
    "relationships": {}
  },
  {
    "id": "3096991",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.374109,
          "width": 0.218487,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.357482,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.342043,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.325416,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.308789,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.413445,
          "top": 0.293349,
          "width": 0.0739496,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{roth2016neural} incorporate syntax by embedding dependency paths, and similarly \\citet{marcheggiani2017encoding} encode syntax using a graph CNN over a predicted syntax tree, out-performing models without syntax on CoNLL-2009.",
      "tex_start": 36826,
      "tex_end": 37059,
      "text": "Citation (roth2016neural) incorporate syntax by embedding dependency paths, and similarly Citation (marcheggiani2017encoding) encode syntax using a graph CNN over a predicted syntax tree, out-performing models without syntax on CoNLL-2009."
    },
    "relationships": {}
  },
  {
    "id": "3096992",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.421615,
          "width": 0.156303,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.406176,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.389549,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.359664,
          "top": 0.374109,
          "width": 0.127731,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "These works are limited to incorporating partial dependency paths between tokens whereas our technique incorporates the entire parse.",
      "tex_start": 37060,
      "tex_end": 37193,
      "text": "These works are limited to incorporating partial dependency paths between tokens whereas our technique incorporates the entire parse."
    },
    "relationships": {}
  },
  {
    "id": "3096993",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.470309,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.453682,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.2,
          "top": 0.438242,
          "width": 0.287395,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.287395,
          "top": 0.421615,
          "width": 0.092437,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Additionally, \\citet{marcheggiani2017encoding} report that their model does not out-perform syntax-free models on out-of-domain data, a setting in which our technique excels.",
      "tex_start": 37194,
      "tex_end": 37368,
      "text": "Additionally, Citation (marcheggiani2017encoding) report that their model does not out-perform syntax-free models on out-of-domain data, a setting in which our technique excels."
    },
    "relationships": {}
  },
  {
    "id": "3096994",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.242017,
          "top": 0.62114,
          "width": 0.243697,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.603325,
          "width": 0.322689,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.587886,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.571259,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.159664,
          "top": 0.557007,
          "width": 0.32605,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.159664,
          "top": 0.546318,
          "width": 0.32605,
          "height": 0.0023753
        },
        {
          "page": 5,
          "left": 0.159664,
          "top": 0.541568,
          "width": 0.189916,
          "height": 0.00118765
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.523753,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.507126,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.141176,
          "top": 0.490499,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "MTL \\citep{caruana1993multitask} is popular in NLP, and others have proposed MTL models which incorporate subsets of the tasks we do \\citep{collobert2011natural, zhang2016stack, hashimoto2017joint, peng2017deep, swayamdipta2017}, and we build off work that investigates where and when to combine different tasks to achieve the best results \\citep{sogaard2016deep, bingel2017identifying, alonso2017when}.",
      "tex_start": 37970,
      "tex_end": 38373,
      "text": "MTL Citation (caruana1993multitask) is popular in NLP, and others have proposed MTL models which incorporate subsets of the tasks we do Citation (collobert2011natural, zhang2016stack, hashimoto2017joint, peng2017deep, swayamdipta2017), and we build off work that investigates where and when to combine different tasks to achieve the best results Citation (sogaard2016deep, bingel2017identifying, alonso2017when)."
    },
    "relationships": {}
  },
  {
    "id": "3096995",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.716152,
          "width": 0.228571,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.700713,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.684085,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.667458,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.652019,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.635392,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our specific method of incorporating supervision into self-attention is most similar to the concurrent work of \\citet{liu2018learning}, who use edge marginals produced by the matrix-tree algorithm as attention weights for document classification and natural language inference.",
      "tex_start": 38374,
      "tex_end": 38651,
      "text": "Our specific method of incorporating supervision into self-attention is most similar to the concurrent work of Citation (liu2018learning), who use edge marginals produced by the matrix-tree algorithm as attention weights for document classification and natural language inference."
    },
    "relationships": {}
  },
  {
    "id": "3096996",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.203361,
          "top": 0.850356,
          "width": 0.0571429,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.17479,
          "top": 0.840855,
          "width": 0.253782,
          "height": 0.0023753
        },
        {
          "page": 5,
          "left": 0.221849,
          "top": 0.836105,
          "width": 0.206723,
          "height": 0.00118765
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.294118,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.157983,
          "top": 0.801663,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.164706,
          "top": 0.785036,
          "width": 0.268908,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.122689,
          "top": 0.769596,
          "width": 0.309244,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.752969,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.139496,
          "top": 0.73753,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The question of training on gold versus predicted labels is closely related to learning to search \\citep{daume2009search,ross2011reduction,chang2015learning} and scheduled sampling \\citep{bengio2015scheduled}, with applications in NLP to sequence labeling and transition-based parsing \\citep{choi2011getting, goldberg2012dynamic,ballesteros2016training}.",
      "tex_start": 39758,
      "tex_end": 40112,
      "text": "The question of training on gold versus predicted labels is closely related to learning to search Citation (daume2009search,ross2011reduction,chang2015learning) and scheduled sampling Citation (bengio2015scheduled), with applications in NLP to sequence labeling and transition-based parsing Citation (choi2011getting, goldberg2012dynamic,ballesteros2016training)."
    },
    "relationships": {}
  },
  {
    "id": "3096997",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.2,
          "top": 0.882423,
          "width": 0.112605,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.29916,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.27563,
          "top": 0.849169,
          "width": 0.211765,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our approach may be interpreted as an extension of teacher forcing \\citep{williams1989learning} to MTL.",
      "tex_start": 40113,
      "tex_end": 40216,
      "text": "Our approach may be interpreted as an extension of teacher forcing Citation (williams1989learning) to MTL."
    },
    "relationships": {}
  },
  {
    "id": "3096998",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.121008,
          "top": 0.897862,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.317647,
          "top": 0.882423,
          "width": 0.171429,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.0795724,
          "width": 0.087395,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We leave exploration of more advanced scheduled sampling techniques to future work.",
      "tex_start": 40217,
      "tex_end": 40300,
      "text": "We leave exploration of more advanced scheduled sampling techniques to future work."
    },
    "relationships": {}
  },
  {
    "id": "3096999",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\section{Experimental results}\n\n\\begin{table*}[",
      "tex_start": 40738,
      "tex_end": 40786,
      "text": "Experimental results."
    },
    "relationships": {}
  },
  {
    "id": "3097000",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "t!]\n% \\begin{tabular}{llll}\n% WSJ Dev & P & R & F1 \\\\ \\hline \\hline\n% % \\citet{he2017deep} single & 80.3 & 80.4 & 80.3 \\\\\n% \\citet{he2017deep} PoE & 81.8 &  81.2 & 81.5  \\\\ \n% \\citet{he2018jointly} & 81.3 & 81.9 & 81.6 \\\\ \\hline\n% % \\citet{he2018jointly}+ELMo & -- & -- & 85.3 \\\\ \\hline\n% SA &  83.52 & 81.28 & 82.39 \\\\ %79.70 &  78.59 &  79.14 \\\\\n% LISA &  83.06\t& 81.42\t& 82.23 \\\\\n% \\ \\ \\ \\ +D\\&M & {\\bf 84.25} & {\\bf 82.53} &\t{\\bf 83.38} \\\\\n% \\ \\ \\ \\ \\emph{+Gold} & \\emph{87.44} & \\emph{85.41} & \\emph{86.41} \\\\\n% & & & \\\\ \n% WSJ Test & P & R & F1 \\\\ \\hline \\hline\n% % \\citet{he2017deep} single & 80.2 & 82.3 & 81.2 \\\\\n% \\citet{he2017deep} PoE & 82.0 & 83.4 & 82.7 \\\\\n% \\citet{he2018jointly} & 81.2 & 83.9 & 82.5 \\\\ \\hline\n% % \\citet{he2018jointly}+ELMo & 84.8 & 87.2 & 86.0 \\\\ \\hline\n% SA &  84.17 &\t83.28 &\t83.72  \\\\\n% LISA & 83.81 & 83.03 &\t83.42 \\\\ \n% \\ \\ \\ \\ +D\\&M & {\\bf 85.38} & {\\bf 84.46} &\t{\\bf 84.92} \\\\ %{\\bf 83.71} &  {\\bf 83.69} &  {\\bf 83.70} \\\\\n% % & \\multicolumn{3}{c}{Brown Test} \\\\ \\cline{2-4} \n% & & & \\\\ \n% Brown Test &  P & R & F1 \\\\ \\hline \\hline\n% % \\citet{he2017deep} single & 67.6&  69.6 & 68.5\\\\\n% \\citet{he2017deep} PoE & 69.7&  70.5 & 70.1\\\\\n% \\citet{he2018jointly} & 69.7 & 71.9 & 70.8 \\\\ \\hline\n% % \\citet{he2018jointly}+ELMo & 73.9 & 78.4 & 76.1 \\\\ \\hline\n% SA &  72.98 & 70.1 & 71.51 \\\\ %70.10  & 66.01  & 67.99  \\\\\n% LISA & 72.93 &\t70.79 &\t71.84 \\\\ % 71.93  & 69.45 &  70.67 \\\\\n% \\ \\ \\ \\ +D\\&M & {\\bf 75.05} & {\\bf 72.81} & {\\bf 73.91} \\\\ % {\\bf 72.60} &  69.73 &  {\\bf 71.13} \\\\ \n% \\end{tabular}\n\\begin{tabular}{llllllllllll}\n& \\multicolumn{3}{c}{Dev} && \\multicolumn{3}{c}{WSJ Test} && \\multicolumn{3}{c}{Brown Test",
      "tex_start": 40786,
      "tex_end": 42440,
      "text": "t! llllllllllll & 3cDev && 3cWSJ Test && 3cBrown Test"
    },
    "relationships": {}
  },
  {
    "id": "3097001",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "2-4} \\cline{6-8} \\cline{10-12}\nGloVe & P & R & F1 && P & R & F1 && P & R & F1",
      "tex_start": 42452,
      "tex_end": 42529,
      "text": "2-4 6-8 10-12 GloVe & P & R & F1 && P & R & F1 && P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097002",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.198319,
          "top": 0.112827,
          "width": 0.662185,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2017deep} PoE & 81.8 &  81.2 & 81.5 & & 82.0 & 83.4 & 82.7 && 69.7 &  70.5 & 70.1",
      "tex_start": 42546,
      "tex_end": 42636,
      "text": "Citation (he2017deep) PoE & 81.8 &  81.2 & 81.5 & & 82.0 & 83.4 & 82.7 && 69.7 &  70.5 & 70.1"
    },
    "relationships": {}
  },
  {
    "id": "3097003",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.198319,
          "top": 0.128266,
          "width": 0.665546,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 81.3 & 81.9 & 81.6 & & 81.2 & 83.9 & 82.5 && 69.7 & 71.9 & 70.8",
      "tex_start": 42641,
      "tex_end": 42728,
      "text": "Citation (he2018jointly) & 81.3 & 81.9 & 81.6 & & 81.2 & 83.9 & 82.5 && 69.7 & 71.9 & 70.8"
    },
    "relationships": {}
  },
  {
    "id": "3097004",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.132773,
          "top": 0.144893,
          "width": 0.737815,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA &  83.52 & 81.28 & 82.39 &&  84.17 &\t83.28 &\t83.72 && 72.98 & 70.1 & 71.51",
      "tex_start": 42738,
      "tex_end": 42815,
      "text": "SA &  83.52 & 81.28 & 82.39 &&  84.17 &\t83.28 &\t83.72 && 72.98 & 70.1 & 71.51"
    },
    "relationships": {}
  },
  {
    "id": "3097005",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.132773,
          "top": 0.16152,
          "width": 0.737815,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA &  83.1 & 81.39 &  82.24 && 84.07 & 83.16 & 83.61 && 73.32 & 70.56 & 71.91",
      "tex_start": 42820,
      "tex_end": 42899,
      "text": "LISA &  83.1 & 81.39 &  82.24 && 84.07 & 83.16 & 83.61 && 73.32 & 70.56 & 71.91"
    },
    "relationships": {}
  },
  {
    "id": "3097006",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.14958,
          "top": 0.17696,
          "width": 0.72437,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 84.59} & {\\bf 82.59} &\t{\\bf 83.58} && {\\bf 85.53} & {\\bf 84.45} & {\\bf 84.99} && {\\bf 75.8} & {\\bf 73.54} & {\\bf 74.66",
      "tex_start": 42914,
      "tex_end": 43045,
      "text": "+D&M & 84.59 & 82.59 &\t83.58 && 85.53 & 84.45 & 84.99 && 75.8 & 73.54 & 74.66"
    },
    "relationships": {}
  },
  {
    "id": "3097007",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.151261,
          "top": 0.193587,
          "width": 0.70084,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{87.91} & \\emph{85.73} & \\emph{86.81} && --- & --- & --- && --- & --- & ---",
      "tex_start": 43065,
      "tex_end": 43154,
      "text": "+Gold & 87.91 & 85.73 & 86.81 && --- & --- & --- && --- & --- & ---"
    },
    "relationships": {}
  },
  {
    "id": "3097008",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & & && & & && & &",
      "tex_start": 43158,
      "tex_end": 43177,
      "text": "& & & && & & && & &"
    },
    "relationships": {}
  },
  {
    "id": "3097009",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.132773,
          "top": 0.225653,
          "width": 0.0453782,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "ELMo & & & && & & && & &",
      "tex_start": 43181,
      "tex_end": 43205,
      "text": "ELMo & & & && & & && & &"
    },
    "relationships": {}
  },
  {
    "id": "3097010",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.198319,
          "top": 0.244656,
          "width": 0.662185,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 84.9 & {\\bf 85.7} & 85.3 & & 84.8 & {\\bf 87.2} & 86.0 && 73.9 & {\\bf 78.4} & 76.1",
      "tex_start": 43223,
      "tex_end": 43328,
      "text": "Citation (he2018jointly) & 84.9 & 85.7 & 85.3 & & 84.8 & 87.2 & 86.0 && 73.9 & 78.4 & 76.1"
    },
    "relationships": {}
  },
  {
    "id": "3097011",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.132773,
          "top": 0.261283,
          "width": 0.741176,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA &  85.78\t& 84.74\t& 85.26 &&  86.21 &\t85.98 &\t86.09 && 77.1 &\t75.61 &\t76.35",
      "tex_start": 43338,
      "tex_end": 43415,
      "text": "SA &  85.78\t& 84.74\t& 85.26 &&  86.21 &\t85.98 &\t86.09 && 77.1 &\t75.61 &\t76.35"
    },
    "relationships": {}
  },
  {
    "id": "3097012",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.132773,
          "top": 0.27791,
          "width": 0.741176,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA &  {\\bf 86.07} & 84.64 & {\\bf 85.35} && 86.69 & 86.42 & 86.55 && 78.95 & 77.17 &\t78.05",
      "tex_start": 43420,
      "tex_end": 43511,
      "text": "LISA &  86.07 & 84.64 & 85.35 && 86.69 & 86.42 & 86.55 && 78.95 & 77.17 &\t78.05"
    },
    "relationships": {}
  },
  {
    "id": "3097013",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.14958,
          "top": 0.293349,
          "width": 0.72437,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M &85.83 &\t84.51 &\t85.17 && {\\bf 87.13} & 86.67 & {\\bf 86.90} && {\\bf 79.02} & 77.49 & {\\bf 78.25",
      "tex_start": 43526,
      "tex_end": 43627,
      "text": "+D&M &85.83 &\t84.51 &\t85.17 && 87.13 & 86.67 & 86.90 && 79.02 & 77.49 & 78.25"
    },
    "relationships": {}
  },
  {
    "id": "3097014",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.151261,
          "top": 0.309976,
          "width": 0.70084,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{88.51} & \\emph{86.77} & \\emph{87.63} && --- & --- & --- && --- & --- & ---\n\\end{tabular}\n% \\caption{Precision, recall and F1 on the CoNLL-2005 development and test sets. Our model out-performs the baseline both in- and out-of-domain. \\label{tab:conll05-results}}\n\\caption{Precision, recall and F1 on the CoNLL-2005 development and test sets.",
      "tex_start": 43647,
      "tex_end": 44003,
      "text": "+Gold & 88.51 & 86.77 & 87.63 && --- & --- & --- && --- & --- & ---  Precision, recall and F1 on the CoNLL-2005 development and test sets."
    },
    "relationships": {}
  },
  {
    "id": "3097015",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:conll05-results}}",
      "tex_start": 44004,
      "tex_end": 44032,
      "text": "(Label tab:conll05-results)"
    },
    "relationships": {}
  },
  {
    "id": "3097016",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.218527,
          "width": 0.122689,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.203088,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.186461,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.171021,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.154394,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.138955,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We present results on the CoNLL-2005 shared task \\citep{carreras2005introduction} and the CoNLL-2012 English subset of OntoNotes 5.0 \\citep{pradhan2013towards}, achieving state-of-the-art results for a single model with predicted predicates on both corpora.",
      "tex_start": 44047,
      "tex_end": 44304,
      "text": "We present results on the CoNLL-2005 shared task Citation (carreras2005introduction) and the CoNLL-2012 English subset of OntoNotes 5.0 Citation (pradhan2013towards), achieving state-of-the-art results for a single model with predicted predicates on both corpora."
    },
    "relationships": {}
  },
  {
    "id": "3097017",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.299287,
          "width": 0.104202,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.283848,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.267221,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.618487,
          "top": 0.251781,
          "width": 0.263866,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.235154,
          "width": 0.332773,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.652101,
          "top": 0.218527,
          "width": 0.230252,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We experiment with both standard pre-trained GloVe word embeddings \\citep{pennington2014glove} and pre-trained ELMo representations with fine-tuned task-specific parameters \\citep{peters2018deep} in order to best compare to prior work.",
      "tex_start": 44305,
      "tex_end": 44540,
      "text": "We experiment with both standard pre-trained GloVe word embeddings Citation (pennington2014glove) and pre-trained ELMo representations with fine-tuned task-specific parameters Citation (peters2018deep) in order to best compare to prior work."
    },
    "relationships": {}
  },
  {
    "id": "3097018",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.36342,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.347981,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.331354,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.315914,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.636975,
          "top": 0.299287,
          "width": 0.245378,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Hyperparameters that resulted in the best performance on the validation set were selected via a small grid search, and models were trained for a maximum of 4 days on one TitanX GPU using early stopping on the validation set.",
      "tex_start": 44541,
      "tex_end": 44765,
      "text": "Hyperparameters that resulted in the best performance on the validation set were selected via a small grid search, and models were trained for a maximum of 4 days on one TitanX GPU using early stopping on the validation set."
    },
    "relationships": {}
  },
  {
    "id": "3097019",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.584874,
          "top": 0.413302,
          "width": 0.0537815,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.395487,
          "width": 0.235294,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.380048,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We convert constituencies to dependencies using the Stanford head rules v3.5 \\citep{deMarneffe2008}.",
      "tex_start": 45129,
      "tex_end": 45229,
      "text": "We convert constituencies to dependencies using the Stanford head rules v3.5 Citation (deMarneffe2008)."
    },
    "relationships": {}
  },
  {
    "id": "3097020",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.444181,
          "width": 0.157983,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.428741,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.64874,
          "top": 0.412114,
          "width": 0.233613,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "A detailed description of hyperparameter settings and data pre-processing can be found in Appendix~\\ref{sec:supplemental}.",
      "tex_start": 45230,
      "tex_end": 45352,
      "text": "A detailed description of hyperparameter settings and data pre-processing can be found in Appendix (Ref sec:supplemental)."
    },
    "relationships": {}
  },
  {
    "id": "3097021",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.541568,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.526128,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.509501,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.494062,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.477435,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.536134,
          "top": 0.461995,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We compare our {\\bf LISA} models to four strong baselines: For experiments using predicted predicates, we compare to \\citet{he2018jointly} and the ensemble model ({\\bf PoE}) from \\citet{he2017deep}, as well as a version of our own self-attention model which does not incorporate syntactic information ({\\bf SA}).",
      "tex_start": 45492,
      "tex_end": 45804,
      "text": "We compare our LISA models to four strong baselines: For experiments using predicted predicates, we compare to Citation (he2018jointly) and the ensemble model (PoE) from Citation (he2017deep), as well as a version of our own self-attention model which does not incorporate syntactic information (SA)."
    },
    "relationships": {}
  },
  {
    "id": "3097022",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.590261,
          "width": 0.203361,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.573634,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.558195,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "To compare to more prior work, we present additional results on CoNLL-2005 with models given gold predicates at test time.",
      "tex_start": 45805,
      "tex_end": 45927,
      "text": "To compare to more prior work, we present additional results on CoNLL-2005 with models given gold predicates at test time."
    },
    "relationships": {}
  },
  {
    "id": "3097023",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.638955,
          "width": 0.189916,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.605701,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.731092,
          "top": 0.590261,
          "width": 0.151261,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In these experiments we also compare to \\citet{tan2018deep}, the previous state-of-the art SRL model using gold predicates and standard embeddings.",
      "tex_start": 45928,
      "tex_end": 46075,
      "text": "In these experiments we also compare to Citation (tan2018deep), the previous state-of-the art SRL model using gold predicates and standard embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3097024",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.552941,
          "top": 0.736342,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.719715,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.704276,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.687648,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.672209,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.536134,
          "top": 0.655582,
          "width": 0.346218,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We demonstrate that our models benefit from injecting state-of-the-art predicted parses at test time ({\\bf +D\\&M}) by fixing the attention to parses predicted by \\citet{dozat2017deep}, the winner of the 2017 CoNLL shared task \\citep{zeman2017conll} which we re-train using ELMo embeddings.",
      "tex_start": 46077,
      "tex_end": 46366,
      "text": "We demonstrate that our models benefit from injecting state-of-the-art predicted parses at test time (+D&M) by fixing the attention to parses predicted by Citation (dozat2017deep), the winner of the 2017 CoNLL shared task Citation (zeman2017conll) which we re-train using ELMo embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3097025",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.768409,
          "width": 0.14958,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.751781,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In all cases, using these parses at test time improves performance.",
      "tex_start": 46367,
      "tex_end": 46434,
      "text": "In all cases, using these parses at test time improves performance."
    },
    "relationships": {}
  },
  {
    "id": "3097026",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.833729,
          "width": 0.14958,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.817102,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.801663,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.536134,
          "top": 0.785036,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also evaluate our model using the gold syntactic parse at test time ({\\bf +Gold}), to provide an upper bound for the benefit that syntax could have for SRL using LISA.",
      "tex_start": 46437,
      "tex_end": 46607,
      "text": "We also evaluate our model using the gold syntactic parse at test time (+Gold), to provide an upper bound for the benefit that syntax could have for SRL using LISA."
    },
    "relationships": {}
  },
  {
    "id": "3097027",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.865796,
          "width": 0.25042,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.515966,
          "top": 0.849169,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.672269,
          "top": 0.833729,
          "width": 0.210084,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "These experiments show that despite LISA's strong performance, there remains substantial room for improvement.",
      "tex_start": 46608,
      "tex_end": 46718,
      "text": "These experiments show that despite LISA's strong performance, there remains substantial room for improvement."
    },
    "relationships": {}
  },
  {
    "id": "3097028",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.897862,
          "width": 0.216807,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.517647,
          "top": 0.882423,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 5,
          "left": 0.776471,
          "top": 0.864608,
          "width": 0.105882,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In \\S\\ref{sec:analysis} we perform further analysis comparing SRL models using gold and predicted parses.",
      "tex_start": 46719,
      "tex_end": 46824,
      "text": "In (Ref sec:analysis) we perform further analysis comparing SRL models using gold and predicted parses."
    },
    "relationships": {}
  },
  {
    "id": "3097029",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "llll}\nWSJ Test & P & R & F1",
      "tex_start": 46958,
      "tex_end": 46985,
      "text": "llll WSJ Test & P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097030",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.220168,
          "top": 0.396675,
          "width": 0.226891,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 84.2 & 83.7 & 83.9",
      "tex_start": 47049,
      "tex_end": 47091,
      "text": "Citation (he2018jointly) & 84.2 & 83.7 & 83.9"
    },
    "relationships": {}
  },
  {
    "id": "3097031",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.22521,
          "top": 0.412114,
          "width": 0.221849,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{tan2018deep} & 84.5 & 85.2 & 84.8",
      "tex_start": 47145,
      "tex_end": 47185,
      "text": "Citation (tan2018deep) & 84.5 & 85.2 & 84.8"
    },
    "relationships": {}
  },
  {
    "id": "3097032",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.152941,
          "top": 0.428741,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 84.7 & 84.24 & 84.47",
      "tex_start": 47259,
      "tex_end": 47284,
      "text": "SA & 84.7 & 84.24 & 84.47"
    },
    "relationships": {}
  },
  {
    "id": "3097033",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.152941,
          "top": 0.445368,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 84.72 &\t84.57\t& 84.64",
      "tex_start": 47288,
      "tex_end": 47316,
      "text": "LISA & 84.72 &\t84.57\t& 84.64"
    },
    "relationships": {}
  },
  {
    "id": "3097034",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.169748,
          "top": 0.460808,
          "width": 0.285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 86.02} &\t{\\bf 86.05} &\t{\\bf 86.04",
      "tex_start": 47354,
      "tex_end": 47400,
      "text": "+D&M & 86.02 &\t86.05 &\t86.04"
    },
    "relationships": {}
  },
  {
    "id": "3097035",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & &",
      "tex_start": 47406,
      "tex_end": 47411,
      "text": "& & &"
    },
    "relationships": {}
  },
  {
    "id": "3097036",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.152941,
          "top": 0.492874,
          "width": 0.277311,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Brown Test &  P & R & F1",
      "tex_start": 47415,
      "tex_end": 47439,
      "text": "Brown Test &  P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097037",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.220168,
          "top": 0.511876,
          "width": 0.226891,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 74.2 & 73.1 & 73.7",
      "tex_start": 47549,
      "tex_end": 47591,
      "text": "Citation (he2018jointly) & 74.2 & 73.1 & 73.7"
    },
    "relationships": {}
  },
  {
    "id": "3097038",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.22521,
          "top": 0.528504,
          "width": 0.218487,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{tan2018deep} & 73.5 & 74.6 & 74.1",
      "tex_start": 47595,
      "tex_end": 47635,
      "text": "Citation (tan2018deep) & 73.5 & 74.6 & 74.1"
    },
    "relationships": {}
  },
  {
    "id": "3097039",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.152941,
          "top": 0.545131,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 73.89 & 72.39 & 73.13",
      "tex_start": 47703,
      "tex_end": 47729,
      "text": "SA & 73.89 & 72.39 & 73.13"
    },
    "relationships": {}
  },
  {
    "id": "3097040",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.152941,
          "top": 0.56057,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 74.77 & 74.32 &\t74.55",
      "tex_start": 47733,
      "tex_end": 47761,
      "text": "LISA & 74.77 & 74.32 &\t74.55"
    },
    "relationships": {}
  },
  {
    "id": "3097041",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.169748,
          "top": 0.577197,
          "width": 0.285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 76.65} & {\\bf 76.44} & {\\bf 76.54",
      "tex_start": 47800,
      "tex_end": 47846,
      "text": "+D&M & 76.65 & 76.44 & 76.54"
    },
    "relationships": {}
  },
  {
    "id": "3097042",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.62114,
          "width": 0.14958,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.184874,
          "top": 0.604513,
          "width": 0.302521,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Precision, recall and F1 on CoNLL-2005 with gold predicates.",
      "tex_start": 47900,
      "tex_end": 47960,
      "text": "Precision, recall and F1 on CoNLL-2005 with gold predicates."
    },
    "relationships": {}
  },
  {
    "id": "3097043",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:conll05-gold-pred}}",
      "tex_start": 47961,
      "tex_end": 47991,
      "text": "(Label tab:conll05-gold-pred)"
    },
    "relationships": {}
  },
  {
    "id": "3097044",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.663895,
          "width": 0.213445,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Semantic role labeling \\label{sec:conll05}}",
      "tex_start": 48003,
      "tex_end": 48060,
      "text": "Semantic role labeling \\label{sec:conll05."
    },
    "relationships": {}
  },
  {
    "id": "3097045",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.720903,
          "width": 0.12605,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.704276,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.688836,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Table~\\ref{tab:conll05-results} lists precision, recall and F1 on the CoNLL-2005 development and test sets using predicted predicates.",
      "tex_start": 48062,
      "tex_end": 48196,
      "text": "Table (Ref tab:conll05-results) lists precision, recall and F1 on the CoNLL-2005 development and test sets using predicted predicates."
    },
    "relationships": {}
  },
  {
    "id": "3097046",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.769596,
          "width": 0.163025,
          "height": 0.00950119
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.752969,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.73753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.255462,
          "top": 0.720903,
          "width": 0.231933,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "For models using GloVe embeddings, our syntax-free SA model already achieves a new state-of-the-art by jointly predicting predicates, POS and SRL.",
      "tex_start": 48197,
      "tex_end": 48343,
      "text": "For models using GloVe embeddings, our syntax-free SA model already achieves a new state-of-the-art by jointly predicting predicates, POS and SRL."
    },
    "relationships": {}
  },
  {
    "id": "3097047",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.242017,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.801663,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.785036,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.294118,
          "top": 0.769596,
          "width": 0.193277,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA with its own parses performs comparably to SA, but when supplied with D\\&M parses LISA out-performs the previous state-of-the-art by 2.5 F1 points.",
      "tex_start": 48344,
      "tex_end": 48496,
      "text": "LISA with its own parses performs comparably to SA, but when supplied with D&M parses LISA out-performs the previous state-of-the-art by 2.5 F1 points."
    },
    "relationships": {}
  },
  {
    "id": "3097048",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.122689,
          "top": 0.897862,
          "width": 0.161345,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.882423,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.849169,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.121008,
          "top": 0.833729,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.378151,
          "top": 0.817102,
          "width": 0.109244,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On the out-of-domain Brown test set, LISA also performs comparably to its syntax-free counterpart with its own parses, but with D\\&M parses LISA performs exceptionally well, more than 3.5 F1 points higher than \\citet{he2018jointly}.",
      "tex_start": 48497,
      "tex_end": 48729,
      "text": "On the out-of-domain Brown test set, LISA also performs comparably to its syntax-free counterpart with its own parses, but with D&M parses LISA performs exceptionally well, more than 3.5 F1 points higher than Citation (he2018jointly)."
    },
    "relationships": {}
  },
  {
    "id": "3097049",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.29916,
          "top": 0.897862,
          "width": 0.188235,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.37886,
          "width": 0.223529,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Incorporating ELMo embeddings improves all scores.",
      "tex_start": 48730,
      "tex_end": 48780,
      "text": "Incorporating ELMo embeddings improves all scores."
    },
    "relationships": {}
  },
  {
    "id": "3097050",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.475059,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.45962,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.442993,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.426366,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.410926,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.395487,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.757983,
          "top": 0.37886,
          "width": 0.12437,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The gap in SRL F1 between models using LISA and D\\&M parses is smaller due to LISA's improved parsing accuracy (see \\S\\ref{sec:parse-pos-results}), but LISA with D\\&M parses still achieves the highest F1: nearly 1.0 absolute F1 higher than the previous state-of-the art on WSJ, and more than 2.0 F1 higher on Brown.",
      "tex_start": 48781,
      "tex_end": 49096,
      "text": "The gap in SRL F1 between models using LISA and D&M parses is smaller due to LISA's improved parsing accuracy (see (Ref sec:parse-pos-results)), but LISA with D&M parses still achieves the highest F1: nearly 1.0 absolute F1 higher than the previous state-of-the art on WSJ, and more than 2.0 F1 higher on Brown."
    },
    "relationships": {}
  },
  {
    "id": "3097051",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.54038,
          "width": 0.255462,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.523753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.508314,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.491686,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In both settings LISA leverages domain-agnostic syntactic information rather than over-fitting to the newswire training data which leads to high performance even on out-of-domain text.",
      "tex_start": 49097,
      "tex_end": 49281,
      "text": "In both settings LISA leverages domain-agnostic syntactic information rather than over-fitting to the newswire training data which leads to high performance even on out-of-domain text."
    },
    "relationships": {}
  },
  {
    "id": "3097052",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.590261,
          "width": 0.260504,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.573634,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.534454,
          "top": 0.558195,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "To compare to more prior work we also evaluate our models in the artificial setting where gold predicates are provided at test time.",
      "tex_start": 49283,
      "tex_end": 49415,
      "text": "To compare to more prior work we also evaluate our models in the artificial setting where gold predicates are provided at test time."
    },
    "relationships": {}
  },
  {
    "id": "3097053",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.655582,
          "width": 0.0336134,
          "height": 0.00712589
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.638955,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.622328,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.606888,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.786555,
          "top": 0.590261,
          "width": 0.0957983,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "For fair comparison we use GloVe embeddings, provide predicate indicator embeddings on the input and re-encode the sequence relative to each gold predicate.",
      "tex_start": 49416,
      "tex_end": 49572,
      "text": "For fair comparison we use GloVe embeddings, provide predicate indicator embeddings on the input and re-encode the sequence relative to each gold predicate."
    },
    "relationships": {}
  },
  {
    "id": "3097054",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.686461,
          "width": 0.29916,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.671021,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.563025,
          "top": 0.654394,
          "width": 0.319328,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Here LISA still excels: with D\\&M parses, LISA out-performs the previous state-of-the-art by more than 2 F1 on both WSJ and Brown.",
      "tex_start": 49573,
      "tex_end": 49703,
      "text": "Here LISA still excels: with D&M parses, LISA out-performs the previous state-of-the-art by more than 2 F1 on both WSJ and Brown."
    },
    "relationships": {}
  },
  {
    "id": "3097055",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.720903,
          "width": 0.196639,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.534454,
          "top": 0.704276,
          "width": 0.347899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Table~\\ref{tab:conll12-results} reports precision, recall and F1 on the CoNLL-2012 test set.",
      "tex_start": 49706,
      "tex_end": 49798,
      "text": "Table (Ref tab:conll12-results) reports precision, recall and F1 on the CoNLL-2012 test set."
    },
    "relationships": {}
  },
  {
    "id": "3097056",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.519328,
          "top": 0.785036,
          "width": 0.0537815,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.769596,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.752969,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.73753,
          "width": 0.364706,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.736134,
          "top": 0.720903,
          "width": 0.146218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We observe performance similar to that observed on ConLL-2005: Using GloVe embeddings our SA baseline already out-performs \\citet{he2018jointly} by nearly 1.5 F1.",
      "tex_start": 49799,
      "tex_end": 49961,
      "text": "We observe performance similar to that observed on ConLL-2005: Using GloVe embeddings our SA baseline already out-performs Citation (he2018jointly) by nearly 1.5 F1."
    },
    "relationships": {}
  },
  {
    "id": "3097057",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.849169,
          "width": 0.0218487,
          "height": 0.00831354
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.833729,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.817102,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.801663,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.6,
          "top": 0.785036,
          "width": 0.282353,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "With its own parses, LISA slightly under-performs our syntax-free model, but when provided with stronger D\\&M parses LISA out-performs the state-of-the-art by more than 2.5 F1.",
      "tex_start": 49962,
      "tex_end": 50138,
      "text": "With its own parses, LISA slightly under-performs our syntax-free model, but when provided with stronger D&M parses LISA out-performs the state-of-the-art by more than 2.5 F1."
    },
    "relationships": {}
  },
  {
    "id": "3097058",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.882423,
          "width": 0.337815,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.515966,
          "top": 0.865796,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.547899,
          "top": 0.849169,
          "width": 0.334454,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Like CoNLL-2005, ELMo representations improve all models and close the F1 gap between models supplied with LISA and D\\&M parses.",
      "tex_start": 50139,
      "tex_end": 50267,
      "text": "Like CoNLL-2005, ELMo representations improve all models and close the F1 gap between models supplied with LISA and D&M parses."
    },
    "relationships": {}
  },
  {
    "id": "3097059",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.638955,
          "width": 0.131092,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.623515,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.517647,
          "top": 0.897862,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 6,
          "left": 0.860504,
          "top": 0.882423,
          "width": 0.0218487,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "On this dataset ELMo also substantially narrows the difference between models with- and without syntactic information.",
      "tex_start": 50268,
      "tex_end": 50386,
      "text": "On this dataset ELMo also substantially narrows the difference between models with- and without syntactic information."
    },
    "relationships": {}
  },
  {
    "id": "3097060",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.672209,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.655582,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.260504,
          "top": 0.638955,
          "width": 0.226891,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This suggests that for this challenging dataset, ELMo already encodes much of the information available in the D\\&M parses.",
      "tex_start": 50387,
      "tex_end": 50510,
      "text": "This suggests that for this challenging dataset, ELMo already encodes much of the information available in the D&M parses."
    },
    "relationships": {}
  },
  {
    "id": "3097061",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.719715,
          "width": 0.282353,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.704276,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.687648,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.460504,
          "top": 0.672209,
          "width": 0.0252101,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Yet, higher accuracy parses could still yield improvements since providing gold parses increases F1 by 4 points even with ELMo embeddings.",
      "tex_start": 50511,
      "tex_end": 50649,
      "text": "Yet, higher accuracy parses could still yield improvements since providing gold parses increases F1 by 4 points even with ELMo embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3097062",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "llll}\nDev & P & R & F1",
      "tex_start": 50681,
      "tex_end": 50703,
      "text": "llll Dev & P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097063",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "4}{c}{GloVe",
      "tex_start": 50734,
      "tex_end": 50745,
      "text": "4cGloVe"
    },
    "relationships": {}
  },
  {
    "id": "3097064",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.221849,
          "top": 0.112827,
          "width": 0.221849,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 79.2 & 79.7 & 79.4",
      "tex_start": 50858,
      "tex_end": 50900,
      "text": "Citation (he2018jointly) & 79.2 & 79.7 & 79.4"
    },
    "relationships": {}
  },
  {
    "id": "3097065",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.129454,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 82.32 & 79.76 & 81.02",
      "tex_start": 50961,
      "tex_end": 50987,
      "text": "SA & 82.32 & 79.76 & 81.02"
    },
    "relationships": {}
  },
  {
    "id": "3097066",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.146081,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 81.77 & 79.65 & 80.70",
      "tex_start": 51022,
      "tex_end": 51050,
      "text": "LISA & 81.77 & 79.65 & 80.70"
    },
    "relationships": {}
  },
  {
    "id": "3097067",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.173109,
          "top": 0.16152,
          "width": 0.280672,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 82.97} & {\\bf 81.14} &\t{\\bf 82.05",
      "tex_start": 51062,
      "tex_end": 51108,
      "text": "+D&M & 82.97 & 81.14 &\t82.05"
    },
    "relationships": {}
  },
  {
    "id": "3097068",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.17479,
          "top": 0.178147,
          "width": 0.278992,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{87.57} & \\emph{85.32} & \\emph{86.43",
      "tex_start": 51127,
      "tex_end": 51177,
      "text": "+Gold & 87.57 & 85.32 & 86.43"
    },
    "relationships": {}
  },
  {
    "id": "3097069",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & &",
      "tex_start": 51191,
      "tex_end": 51196,
      "text": "& & &"
    },
    "relationships": {}
  },
  {
    "id": "3097070",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "4}{c}{ELMo",
      "tex_start": 51213,
      "tex_end": 51223,
      "text": "4cELMo"
    },
    "relationships": {}
  },
  {
    "id": "3097071",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.221849,
          "top": 0.226841,
          "width": 0.221849,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 82.1 & {\\bf 84.0} & 83.0",
      "tex_start": 51235,
      "tex_end": 51283,
      "text": "Citation (he2018jointly) & 82.1 & 84.0 & 83.0"
    },
    "relationships": {}
  },
  {
    "id": "3097072",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.243468,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 84.35 & 82.14 & 83.23",
      "tex_start": 51294,
      "tex_end": 51320,
      "text": "SA & 84.35 & 82.14 & 83.23"
    },
    "relationships": {}
  },
  {
    "id": "3097073",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.260095,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & {\\bf 84.19} & 82.56 & {\\bf 83.37",
      "tex_start": 51355,
      "tex_end": 51394,
      "text": "LISA & 84.19 & 82.56 & 83.37"
    },
    "relationships": {}
  },
  {
    "id": "3097074",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.173109,
          "top": 0.275534,
          "width": 0.280672,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 84.09 & 82.65 & 83.36",
      "tex_start": 51407,
      "tex_end": 51436,
      "text": "+D&M & 84.09 & 82.65 & 83.36"
    },
    "relationships": {}
  },
  {
    "id": "3097075",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{88.22} & \\emph{86.53} & \\emph{87.36",
      "tex_start": 51454,
      "tex_end": 51504,
      "text": "+Gold & 88.22 & 86.53 & 87.36"
    },
    "relationships": {}
  },
  {
    "id": "3097076",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & &",
      "tex_start": 51511,
      "tex_end": 51516,
      "text": "& & &"
    },
    "relationships": {}
  },
  {
    "id": "3097077",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.154622,
          "top": 0.324228,
          "width": 0.27395,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Test &  P & R & F1",
      "tex_start": 51520,
      "tex_end": 51538,
      "text": "Test &  P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097078",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "4}{c}{GloVe",
      "tex_start": 51569,
      "tex_end": 51580,
      "text": "4cGloVe"
    },
    "relationships": {}
  },
  {
    "id": "3097079",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.221849,
          "top": 0.359857,
          "width": 0.221849,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 79.4 & 80.1 & 79.8",
      "tex_start": 51691,
      "tex_end": 51733,
      "text": "Citation (he2018jointly) & 79.4 & 80.1 & 79.8"
    },
    "relationships": {}
  },
  {
    "id": "3097080",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.376485,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 82.55 & 80.02 & 81.26",
      "tex_start": 51804,
      "tex_end": 51830,
      "text": "SA & 82.55 & 80.02 & 81.26"
    },
    "relationships": {}
  },
  {
    "id": "3097081",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.391924,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA &  81.86 &\t79.56 &\t80.70",
      "tex_start": 51864,
      "tex_end": 51893,
      "text": "LISA &  81.86 &\t79.56 &\t80.70"
    },
    "relationships": {}
  },
  {
    "id": "3097082",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.173109,
          "top": 0.408551,
          "width": 0.280672,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 83.3} & {\\bf 81.38} &\t{\\bf 82.33",
      "tex_start": 51934,
      "tex_end": 51979,
      "text": "+D&M & 83.3 & 81.38 &\t82.33"
    },
    "relationships": {}
  },
  {
    "id": "3097083",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & &",
      "tex_start": 52037,
      "tex_end": 52042,
      "text": "& & &"
    },
    "relationships": {}
  },
  {
    "id": "3097084",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "4}{c}{ELMo",
      "tex_start": 52059,
      "tex_end": 52069,
      "text": "4cELMo"
    },
    "relationships": {}
  },
  {
    "id": "3097085",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.221849,
          "top": 0.457245,
          "width": 0.221849,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 81.9 & {\\bf 84.0} & 82.9",
      "tex_start": 52081,
      "tex_end": 52129,
      "text": "Citation (he2018jointly) & 81.9 & 84.0 & 82.9"
    },
    "relationships": {}
  },
  {
    "id": "3097086",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.473872,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & {\\bf 84.39} & 82.21 & 83.28",
      "tex_start": 52140,
      "tex_end": 52172,
      "text": "SA & 84.39 & 82.21 & 83.28"
    },
    "relationships": {}
  },
  {
    "id": "3097087",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.156303,
          "top": 0.490499,
          "width": 0.297479,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 83.97 & 82.29 & 83.12",
      "tex_start": 52207,
      "tex_end": 52235,
      "text": "LISA & 83.97 & 82.29 & 83.12"
    },
    "relationships": {}
  },
  {
    "id": "3097088",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.173109,
          "top": 0.505938,
          "width": 0.280672,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 84.14 & 82.64 & {\\bf 83.38",
      "tex_start": 52247,
      "tex_end": 52281,
      "text": "+D&M & 84.14 & 82.64 & 83.38"
    },
    "relationships": {}
  },
  {
    "id": "3097089",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.551069,
          "width": 0.242017,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.188235,
          "top": 0.534442,
          "width": 0.29916,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Precision, recall and F1 on the CoNLL-2012 development and test sets.",
      "tex_start": 52311,
      "tex_end": 52380,
      "text": "Precision, recall and F1 on the CoNLL-2012 development and test sets."
    },
    "relationships": {}
  },
  {
    "id": "3097090",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.583135,
          "width": 0.164706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.566508,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.379832,
          "top": 0.551069,
          "width": 0.107563,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Italics indicate a synthetic upper bound obtained by providing a gold parse at test time.",
      "tex_start": 52381,
      "tex_end": 52470,
      "text": "Italics indicate a synthetic upper bound obtained by providing a gold parse at test time."
    },
    "relationships": {}
  },
  {
    "id": "3097091",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:conll12-results}}",
      "tex_start": 52470,
      "tex_end": 52498,
      "text": "(Label tab:conll12-results)"
    },
    "relationships": {}
  },
  {
    "id": "3097092",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.744656,
          "width": 0.331092,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\subsection{Parsing, POS and predicate detection \\label{sec:parse-pos-results}}",
      "tex_start": 52607,
      "tex_end": 52687,
      "text": "Parsing, POS and predicate detection \\label{sec:parse-pos-results."
    },
    "relationships": {}
  },
  {
    "id": "3097093",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "llrrr} \t\t\nData & Model & POS & UAS & LAS",
      "tex_start": 52719,
      "tex_end": 52759,
      "text": "llrrr \t\t Data & Model & POS & UAS & LAS"
    },
    "relationships": {}
  },
  {
    "id": "3097094",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "3}{*}{WSJ} & D\\&M$_{E}$ & --- & 96.48 & 94.40",
      "tex_start": 52787,
      "tex_end": 52832,
      "text": "3*WSJ & D&M EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & --- & 96.48 & 94.40"
    },
    "relationships": {}
  },
  {
    "id": "3097095",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.112827,
          "width": 0.238655,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{G}$ & 96.92 & 94.92 & 91.87",
      "tex_start": 52836,
      "tex_end": 52872,
      "text": "& LISA EQUATION_DEPTH_0_START _{G} EQUATION_DEPTH_0_END & 96.92 & 94.92 & 91.87"
    },
    "relationships": {}
  },
  {
    "id": "3097096",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.128266,
          "width": 0.238655,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{E}$ & 97.80 & 96.28 & 93.65",
      "tex_start": 52877,
      "tex_end": 52913,
      "text": "& LISA EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & 97.80 & 96.28 & 93.65"
    },
    "relationships": {}
  },
  {
    "id": "3097097",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "3}{*}{Brown} & D\\&M$_{E}$ & --- & 92.56 & 88.52",
      "tex_start": 52948,
      "tex_end": 52995,
      "text": "3*Brown & D&M EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & --- & 92.56 & 88.52"
    },
    "relationships": {}
  },
  {
    "id": "3097098",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.16152,
          "width": 0.238655,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{G}$ & 94.26 & 90.31 & 85.82",
      "tex_start": 52999,
      "tex_end": 53035,
      "text": "& LISA EQUATION_DEPTH_0_START _{G} EQUATION_DEPTH_0_END & 94.26 & 90.31 & 85.82"
    },
    "relationships": {}
  },
  {
    "id": "3097099",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.17696,
          "width": 0.238655,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{E}$ & 95.77 & 93.36 & 88.75",
      "tex_start": 53040,
      "tex_end": 53076,
      "text": "& LISA EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & 95.77 & 93.36 & 88.75"
    },
    "relationships": {}
  },
  {
    "id": "3097100",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "3}{*}{CoNLL-12} & D\\&M$_{E}$ & --- & 94.99 & 92.59",
      "tex_start": 53110,
      "tex_end": 53160,
      "text": "3*CoNLL-12 & D&M EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & --- & 94.99 & 92.59"
    },
    "relationships": {}
  },
  {
    "id": "3097101",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.210214,
          "width": 0.238655,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{G}$ & 96.81 & 93.35 & 90.42",
      "tex_start": 53164,
      "tex_end": 53200,
      "text": "& LISA EQUATION_DEPTH_0_START _{G} EQUATION_DEPTH_0_END & 96.81 & 93.35 & 90.42"
    },
    "relationships": {}
  },
  {
    "id": "3097102",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.631933,
          "top": 0.226841,
          "width": 0.238655,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA$_{E}$ & 98.11 & 94.84 & 92.23",
      "tex_start": 53204,
      "tex_end": 53240,
      "text": "& LISA EQUATION_DEPTH_0_START _{E} EQUATION_DEPTH_0_END & 98.11 & 94.84 & 92.23"
    },
    "relationships": {}
  },
  {
    "id": "3097103",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.286223,
          "width": 0.315966,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.270784,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.593277,
          "top": 0.254157,
          "width": 0.289076,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{parsing-numbers} Parsing (labeled and unlabeled attachment) and POS accuracies attained by the models used in SRL experiments on test datasets.",
      "tex_start": 53267,
      "tex_end": 53417,
      "text": "(Label parsing-numbers) Parsing (labeled and unlabeled attachment) and POS accuracies attained by the models used in SRL experiments on test datasets."
    },
    "relationships": {}
  },
  {
    "id": "3097104",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.301663,
          "width": 0.364706,
          "height": 0.0118765
        },
        {
          "page": 7,
          "left": 0.85042,
          "top": 0.286223,
          "width": 0.0319328,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Subscript $G$ denotes GloVe and $E$ ELMo embeddings.",
      "tex_start": 53418,
      "tex_end": 53470,
      "text": "Subscript EQUATION_DEPTH_0_START G EQUATION_DEPTH_0_END denotes GloVe and EQUATION_DEPTH_0_START E EQUATION_DEPTH_0_END ELMo embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3097105",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.305882,
          "height": 0.0118765
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.78266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.122689,
          "top": 0.767221,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We first report the labeled and unlabeled attachment scores (LAS, UAS) of our parsing models on the CoNLL-2005 and 2012 test sets (Table~\\ref{parsing-numbers}) with GloVe ($G$) and ELMo ($E$) embeddings.",
      "tex_start": 53485,
      "tex_end": 53688,
      "text": "We first report the labeled and unlabeled attachment scores (LAS, UAS) of our parsing models on the CoNLL-2005 and 2012 test sets (Table (Ref parsing-numbers)) with GloVe ( EQUATION_DEPTH_0_START G EQUATION_DEPTH_0_END ) and ELMo ( EQUATION_DEPTH_0_START E EQUATION_DEPTH_0_END ) embeddings."
    },
    "relationships": {}
  },
  {
    "id": "3097106",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.191597,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.445378,
          "top": 0.815915,
          "width": 0.0420168,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "D\\&M achieves the best scores.",
      "tex_start": 53689,
      "tex_end": 53719,
      "text": "D&M achieves the best scores."
    },
    "relationships": {}
  },
  {
    "id": "3097107",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.875297,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.121008,
          "top": 0.84323,
          "width": 0.761345,
          "height": 0.0308789
        },
        {
          "page": 7,
          "left": 0.336134,
          "top": 0.826603,
          "width": 0.542857,
          "height": 0.0142518
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.811164,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.788599,
          "width": 0.107563,
          "height": 0.0118765
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.761283,
          "width": 0.354622,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.745843,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.729216,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.713777,
          "width": 0.285714,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.69715,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.68171,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.665083,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.649644,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.633017,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.61639,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.60095,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 7,
          "left": 0.536134,
          "top": 0.584323,
          "width": 0.346218,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.567696,
          "width": 0.238655,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.552257,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.535629,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.573109,
          "top": 0.52019,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Still, LISA's GloVe UAS is comparable to popular off-the-shelf dependency parsers such as spaCy,\\footnote{spaCy reports 94.48 UAS on WSJ using Stanford dependencies v3.3: \\protect\\url{https://spacy.io/usage/facts-figures}} and with ELMo embeddings comparable to the standalone D\\&M parser.",
      "tex_start": 53720,
      "tex_end": 54009,
      "text": "Still, LISA's GloVe UAS is comparable to popular off-the-shelf dependency parsers such as spaCy,spaCy reports 94.48 UAS on WSJ using Stanford dependencies v3.3: https://spacy.io/usage/facts-figures and with ELMo embeddings comparable to the standalone D&M parser."
    },
    "relationships": {}
  },
  {
    "id": "3097108",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.567696,
          "width": 0.238655,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.552257,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.535629,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.573109,
          "top": 0.52019,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The difference in parse accuracy between LISA$_G$ and D\\&M likely explains the large increase in SRL performance we see from decoding with D\\&M parses in that setting.",
      "tex_start": 54010,
      "tex_end": 54177,
      "text": "The difference in parse accuracy between LISA EQUATION_DEPTH_0_START _G EQUATION_DEPTH_0_END and D&M likely explains the large increase in SRL performance we see from decoding with D&M parses in that setting."
    },
    "relationships": {}
  },
  {
    "id": "3097109",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "5pt}\n\\begin{tabular}{lllllll}\n% &\\multicolumn{3}{c}{WSJ Test} & \\multicolumn{3}{c}{Brown Test} \\\\  \\cline{2-4} \\cline{5-7}\n%  & P & R & F1 & P & R & F1\\\\ \\hline \\hline\n% \\citet{he2017deep} & 94.5 & {\\bf 98.5} & 96.4 & 89.3 & {\\bf 95.7} & 92.4 \\\\ %\\hline\n% % SA &  98.3 &  98.1 &  {\\bf 98.2} & & {\\bf 94.7}  & 92.9 &  {\\bf 93.8}\\\\\n% % LISA$_{D}$ &  {\\bf 98.3} & 98.1 & 98.2 & & 94.5 & 92.5 & 93.5  \\\\\n% LISA & {\\bf 98.91} &  97.82 &  {\\bf 98.36} &  {\\bf 96.34} &  91.79 &  {\\bf 94.01} \\\\\n% &\\multicolumn{3}{c}{WSJ Test} & \\multicolumn{3}{c}{Brown Test} \\\\  \\cline{2-4} \\cline{5-7}\n% & Model & P & R & F1 \\\\ \\hline \\hline\n% \\multirow{2}{*}{WSJ} & \\citet{he2017deep} & 94.5 & 98.5 & 96.4  \\\\\n% & LISA & 98.87 &  97.85 & 98.36 \\\\ \\hline\n\n% \\multirow{2}{*}{Brown} & \\citet{he2017deep} & 89.3 & 95.7 & 92.4 \\\\ \n% & LISA & 95.48 &  91.92 &  93.66 \\\\ \\hline\n\n% CoNLL-12 & LISA & 99.83 & 95.23 & 97.48 \\\\ \n& Model & P & R & F1",
      "tex_start": 54216,
      "tex_end": 55133,
      "text": "5pt lllllll   & Model & P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097110",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "2}{*}{WSJ} & \\citet{he2017deep} & 94.5 & 98.5 & 96.4",
      "tex_start": 55161,
      "tex_end": 55213,
      "text": "2*WSJ & Citation (he2017deep) & 94.5 & 98.5 & 96.4"
    },
    "relationships": {}
  },
  {
    "id": "3097111",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.62521,
          "top": 0.368171,
          "width": 0.258824,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA & 98.9 &  97.9 & 98.4",
      "tex_start": 55218,
      "tex_end": 55246,
      "text": "& LISA & 98.9 &  97.9 & 98.4"
    },
    "relationships": {}
  },
  {
    "id": "3097112",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "2}{*}{Brown} & \\citet{he2017deep} & 89.3 & 95.7 & 92.4",
      "tex_start": 55268,
      "tex_end": 55322,
      "text": "2*Brown & Citation (he2017deep) & 89.3 & 95.7 & 92.4"
    },
    "relationships": {}
  },
  {
    "id": "3097113",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.62521,
          "top": 0.401425,
          "width": 0.258824,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& LISA & 95.5 &  91.9 &  93.7",
      "tex_start": 55327,
      "tex_end": 55356,
      "text": "& LISA & 95.5 &  91.9 &  93.7"
    },
    "relationships": {}
  },
  {
    "id": "3097114",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.52437,
          "top": 0.418052,
          "width": 0.359664,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "CoNLL-12 & LISA & 99.8 & 94.7 &\t97.2",
      "tex_start": 55368,
      "tex_end": 55404,
      "text": "CoNLL-12 & LISA & 99.8 & 94.7 &\t97.2"
    },
    "relationships": {}
  },
  {
    "id": "3097115",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.461995,
          "width": 0.346218,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.583193,
          "top": 0.445368,
          "width": 0.29916,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Predicate detection precision, recall and F1 on CoNLL-2005 and CoNLL-2012 test sets.",
      "tex_start": 55432,
      "tex_end": 55516,
      "text": "Predicate detection precision, recall and F1 on CoNLL-2005 and CoNLL-2012 test sets."
    },
    "relationships": {}
  },
  {
    "id": "3097116",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:preds}}",
      "tex_start": 55517,
      "tex_end": 55535,
      "text": "(Label tab:preds)"
    },
    "relationships": {}
  },
  {
    "id": "3097117",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.61639,
          "width": 0.109244,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.60095,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 7,
          "left": 0.536134,
          "top": 0.584323,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In Table~\\ref{tab:preds} we present predicate detection precision, recall and F1 on the CoNLL-2005 and 2012 test sets.",
      "tex_start": 55549,
      "tex_end": 55667,
      "text": "In Table (Ref tab:preds) we present predicate detection precision, recall and F1 on the CoNLL-2005 and 2012 test sets."
    },
    "relationships": {}
  },
  {
    "id": "3097118",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.649644,
          "width": 0.10084,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.633017,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.642017,
          "top": 0.61639,
          "width": 0.240336,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA and LISA with and without ELMo attain comparable scores so we report only LISA+GloVe.",
      "tex_start": 55668,
      "tex_end": 55756,
      "text": "SA and LISA with and without ELMo attain comparable scores so we report only LISA+GloVe."
    },
    "relationships": {}
  },
  {
    "id": "3097119",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.68171,
          "width": 0.226891,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.665083,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.628571,
          "top": 0.649644,
          "width": 0.253782,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We compare to \\citet{he2017deep} on CoNLL-2005, the only cited work reporting comparable predicate detection F1.",
      "tex_start": 55757,
      "tex_end": 55869,
      "text": "We compare to Citation (he2017deep) on CoNLL-2005, the only cited work reporting comparable predicate detection F1."
    },
    "relationships": {}
  },
  {
    "id": "3097120",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA attains high predicate detection scores, above 97 F1, on both in-domain datasets, and out-performs \\citet{he2017deep} by 1.5-2 F1 points even on the out-of-domain Brown test set, suggesting that multi-task learning works well for SRL predicate detection.",
      "tex_start": 55870,
      "tex_end": 56129,
      "text": "LISA attains high predicate detection scores, above 97 F1, on both in-domain datasets, and out-performs Citation (he2017deep) by 1.5-2 F1 points even on the out-of-domain Brown test set, suggesting that multi-task learning works well for SRL predicate detection."
    },
    "relationships": {}
  },
  {
    "id": "3097121",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "lllll}\n& L+/D+ & L--/D+ & L+/D-- & L--/D--",
      "tex_start": 56273,
      "tex_end": 56315,
      "text": "lllll & L+/D+ & L--/D+ & L+/D-- & L--/D--"
    },
    "relationships": {}
  },
  {
    "id": "3097122",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.132773,
          "top": 0.0961995,
          "width": 0.337815,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Proportion & 26\\% &\t12\\% &\t4\\% &\t56\\%",
      "tex_start": 56333,
      "tex_end": 56370,
      "text": "Proportion & 26\\% &\t12\\% &\t4\\% &\t56\\%"
    },
    "relationships": {}
  },
  {
    "id": "3097123",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.132773,
          "top": 0.112827,
          "width": 0.346218,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 79.29 & 75.14\t& 75.97 &\t75.08",
      "tex_start": 56484,
      "tex_end": 56518,
      "text": "SA & 79.29 & 75.14\t& 75.97 &\t75.08"
    },
    "relationships": {}
  },
  {
    "id": "3097124",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.132773,
          "top": 0.129454,
          "width": 0.346218,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 79.51 &\t74.33 &\t79.69 &\t75.00",
      "tex_start": 56523,
      "tex_end": 56559,
      "text": "LISA & 79.51 &\t74.33 &\t79.69 &\t75.00"
    },
    "relationships": {}
  },
  {
    "id": "3097125",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.14958,
          "top": 0.144893,
          "width": 0.329412,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 79.03 &\t76.96 &\t77.73 &\t76.52",
      "tex_start": 56571,
      "tex_end": 56608,
      "text": "+D&M & 79.03 &\t76.96 &\t77.73 &\t76.52"
    },
    "relationships": {}
  },
  {
    "id": "3097126",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.151261,
          "top": 0.16152,
          "width": 0.327731,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{79.61} & \\emph{78.38} & \\emph{81.41} & \\emph{80.47",
      "tex_start": 56626,
      "tex_end": 56691,
      "text": "+Gold & 79.61 & 78.38 & 81.41 & 80.47"
    },
    "relationships": {}
  },
  {
    "id": "3097127",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.22209,
          "width": 0.282353,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.205463,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.181513,
          "top": 0.188836,
          "width": 0.305882,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Average SRL F1 on CoNLL-2005 for sentences where LISA (L) and D\\&M (D) parses were completely correct (+) or incorrect (--).",
      "tex_start": 57210,
      "tex_end": 57334,
      "text": "Average SRL F1 on CoNLL-2005 for sentences where LISA (L) and D&M (D) parses were completely correct (+) or incorrect (--)."
    },
    "relationships": {}
  },
  {
    "id": "3097128",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:parse-srl-by-sents}}",
      "tex_start": 57335,
      "tex_end": 57366,
      "text": "(Label tab:parse-srl-by-sents)"
    },
    "relationships": {}
  },
  {
    "id": "3097129",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.788599,
          "width": 0.107563,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Analysis \\label{sec:analysis}}",
      "tex_start": 57378,
      "tex_end": 57422,
      "text": "Analysis \\label{sec:analysis."
    },
    "relationships": {}
  },
  {
    "id": "3097130",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.828979,
          "width": 0.114286,
          "height": 0.00831354
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.811164,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "First we assess SRL F1 on sentences divided by parse accuracy.",
      "tex_start": 57712,
      "tex_end": 57774,
      "text": "First we assess SRL F1 on sentences divided by parse accuracy."
    },
    "relationships": {}
  },
  {
    "id": "3097131",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.515966,
          "top": 0.85867,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.84323,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 7,
          "left": 0.65042,
          "top": 0.826603,
          "width": 0.228571,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Table \\ref{tab:parse-srl-by-sents} lists average SRL F1 (across sentences) for the four conditions of LISA and D\\&M parses being correct or not ({\\bf L$\\pm$}, {\\bf D$\\pm$}).",
      "tex_start": 57775,
      "tex_end": 57948,
      "text": "Table (Ref tab:parse-srl-by-sents) lists average SRL F1 (across sentences) for the four conditions of LISA and D&M parses being correct or not (L EQUATION_DEPTH_0_START \\pm EQUATION_DEPTH_0_END , D EQUATION_DEPTH_0_START \\pm EQUATION_DEPTH_0_END )."
    },
    "relationships": {}
  },
  {
    "id": "3097132",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 7,
          "left": 0.517647,
          "top": 0.875297,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Both parsers are correct on 26\\% of sentences.",
      "tex_start": 57949,
      "tex_end": 57995,
      "text": "Both parsers are correct on 26\\% of sentences."
    },
    "relationships": {}
  },
  {
    "id": "3097133",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.524941,
          "width": 0.17479,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.509501,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.492874,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Here there is little difference between any of the models, with LISA models tending to perform slightly better than SA.",
      "tex_start": 57996,
      "tex_end": 58115,
      "text": "Here there is little difference between any of the models, with LISA models tending to perform slightly better than SA."
    },
    "relationships": {}
  },
  {
    "id": "3097134",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.557007,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.541568,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.307563,
          "top": 0.524941,
          "width": 0.179832,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Both parsers make mistakes on the majority of sentences (57\\%), difficult sentences where SA also performs the worst.",
      "tex_start": 58116,
      "tex_end": 58233,
      "text": "Both parsers make mistakes on the majority of sentences (57\\%), difficult sentences where SA also performs the worst."
    },
    "relationships": {}
  },
  {
    "id": "3097135",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.654394,
          "width": 0.290756,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.637767,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.622328,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.605701,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.589074,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.573634,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "These examples are likely where gold and D\\&M parses improve the most over other models in overall F1: Though both parsers fail to correctly parse the entire sentence, the D\\&M parser is less wrong (87.5 vs. 85.7 average LAS), leading to higher SRL F1 by about 1.5 average F1.",
      "tex_start": 58234,
      "tex_end": 58510,
      "text": "These examples are likely where gold and D&M parses improve the most over other models in overall F1: Though both parsers fail to correctly parse the entire sentence, the D&M parser is less wrong (87.5 vs. 85.7 average LAS), leading to higher SRL F1 by about 1.5 average F1."
    },
    "relationships": {}
  },
  {
    "id": "3097136",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Following \\citet{he2017deep}, we next apply a series of corrections to model predictions in order to understand which error types the gold parse resolves: e.g. \\emph{Fix Labels} fixes labels on spans matching gold boundaries, and \\emph{Merge Spans} merges adjacent predicted spans into a gold span.\\footnote{Refer to \\citet{he2017deep} for a detailed explanation of the different error types.",
      "tex_start": 58512,
      "tex_end": 58904,
      "text": "Following Citation (he2017deep), we next apply a series of corrections to model predictions in order to understand which error types the gold parse resolves: e.g. Fix Labels fixes labels on spans matching gold boundaries, and Merge Spans merges adjacent predicted spans into a gold span.Refer to Citation (he2017deep) for a detailed explanation of the different error types."
    },
    "relationships": {}
  },
  {
    "id": "3097137",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "scale=0.52]{errors.pdf",
      "tex_start": 58939,
      "tex_end": 58961,
      "text": "scale=0.52errors.pdf"
    },
    "relationships": {}
  },
  {
    "id": "3097138",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Performance of CoNLL-2005 models after performing corrections from \\citet{he2017deep}.",
      "tex_start": 58972,
      "tex_end": 59058,
      "text": "Performance of CoNLL-2005 models after performing corrections from Citation (he2017deep)."
    },
    "relationships": {}
  },
  {
    "id": "3097139",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{errors-fig}}",
      "tex_start": 59059,
      "tex_end": 59078,
      "text": "(Label errors-fig)"
    },
    "relationships": {}
  },
  {
    "id": "3097140",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.86342,
          "width": 0.142857,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.846793,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.831354,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.814727,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.122689,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.121008,
          "top": 0.78266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.141176,
          "top": 0.767221,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In Figure \\ref{errors-fig} we see that much of the performance gap between the gold and predicted parses is due to span boundary errors (\\emph{Merge Spans}, \\emph{Split Spans} and \\emph{Fix Span Boundary}), which supports the hypothesis proposed by \\citet{he2017deep} that incorporating syntax could be particularly helpful for resolving these errors.",
      "tex_start": 59093,
      "tex_end": 59444,
      "text": "In Figure (Ref errors-fig) we see that much of the performance gap between the gold and predicted parses is due to span boundary errors (Merge Spans, Split Spans and Fix Span Boundary), which supports the hypothesis proposed by Citation (he2017deep) that incorporating syntax could be particularly helpful for resolving these errors."
    },
    "relationships": {}
  },
  {
    "id": "3097141",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.337815,
          "top": 0.86342,
          "width": 0.14958,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2017deep} also point out that these errors are due mainly to prepositional phrase (PP) attachment mistakes.",
      "tex_start": 59628,
      "tex_end": 59744,
      "text": "Citation (he2017deep) also point out that these errors are due mainly to prepositional phrase (PP) attachment mistakes."
    },
    "relationships": {}
  },
  {
    "id": "3097142",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also find this to be the case: Figure \\ref{fig:phrase-bar} shows a breakdown of split/merge corrections by phrase type.",
      "tex_start": 59745,
      "tex_end": 59867,
      "text": "We also find this to be the case: Figure (Ref fig:phrase-bar) shows a breakdown of split/merge corrections by phrase type."
    },
    "relationships": {}
  },
  {
    "id": "3097143",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Though the number of corrections decreases substantially across phrase types, the proportion of corrections attributed to PPs remains the same (approx.",
      "tex_start": 59868,
      "tex_end": 60019,
      "text": "Though the number of corrections decreases substantially across phrase types, the proportion of corrections attributed to PPs remains the same (approx."
    },
    "relationships": {}
  },
  {
    "id": "3097144",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "50\\%) even after providing the correct PP attachment to the model, indicating that PP span boundary mistakes are a fundamental difficulty for SRL.",
      "tex_start": 60020,
      "tex_end": 60166,
      "text": "50\\%) even after providing the correct PP attachment to the model, indicating that PP span boundary mistakes are a fundamental difficulty for SRL."
    },
    "relationships": {}
  },
  {
    "id": "3097145",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "scale=0.55]{phrase_bar_percent.pdf",
      "tex_start": 60211,
      "tex_end": 60245,
      "text": "scale=0.55phrase_bar_percent.pdf"
    },
    "relationships": {}
  },
  {
    "id": "3097146",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Percent and count of split/merge corrections performed in Figure \\ref{errors-fig}, by phrase type.",
      "tex_start": 60256,
      "tex_end": 60354,
      "text": "Percent and count of split/merge corrections performed in Figure (Ref errors-fig), by phrase type."
    },
    "relationships": {}
  },
  {
    "id": "3097147",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{fig:phrase-bar}}",
      "tex_start": 60355,
      "tex_end": 60378,
      "text": "(Label fig:phrase-bar)"
    },
    "relationships": {}
  },
  {
    "id": "3097148",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\section{Conclusion}\n",
      "tex_start": 60391,
      "tex_end": 60414,
      "text": "Conclusion."
    },
    "relationships": {}
  },
  {
    "id": "3097149",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We present linguistically-informed self-attention: a multi-task neural network model that effectively incorporates rich linguistic information for semantic role labeling.",
      "tex_start": 60414,
      "tex_end": 60584,
      "text": "We present linguistically-informed self-attention: a multi-task neural network model that effectively incorporates rich linguistic information for semantic role labeling."
    },
    "relationships": {}
  },
  {
    "id": "3097150",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA out-performs the state-of-the-art on two benchmark SRL datasets, including out-of-domain.",
      "tex_start": 60585,
      "tex_end": 60679,
      "text": "LISA out-performs the state-of-the-art on two benchmark SRL datasets, including out-of-domain."
    },
    "relationships": {}
  },
  {
    "id": "3097151",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Future work will explore improving LISA's parsing accuracy, developing better training techniques and adapting to more tasks.",
      "tex_start": 60680,
      "tex_end": 60805,
      "text": "Future work will explore improving LISA's parsing accuracy, developing better training techniques and adapting to more tasks."
    },
    "relationships": {}
  },
  {
    "id": "3097152",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\section*{Acknowledgments}\n",
      "tex_start": 61017,
      "tex_end": 61045,
      "text": "Acknowledgments."
    },
    "relationships": {}
  },
  {
    "id": "3097153",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.752969,
          "width": 0.206723,
          "height": 0.00831354
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.73753,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.720903,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.704276,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.688836,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We are grateful to Luheng He for helpful discussions and code, Timothy Dozat for sharing his code, and to the NLP reading groups at Google and UMass and the anonymous reviewers for feedback on drafts of this work.",
      "tex_start": 61045,
      "tex_end": 61258,
      "text": "We are grateful to Luheng He for helpful discussions and code, Timothy Dozat for sharing his code, and to the NLP reading groups at Google and UMass and the anonymous reviewers for feedback on drafts of this work."
    },
    "relationships": {}
  },
  {
    "id": "3097154",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.817102,
          "width": 0.248739,
          "height": 0.00831354
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.801663,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.517647,
          "top": 0.785036,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.769596,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 8,
          "left": 0.734454,
          "top": 0.752969,
          "width": 0.147899,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This work was supported in part by an IBM PhD Fellowship Award to E.S., in part by the Center for Intelligent Information Retrieval, and in part by the National Science Foundation under Grant Nos.",
      "tex_start": 61259,
      "tex_end": 61455,
      "text": "This work was supported in part by an IBM PhD Fellowship Award to E.S., in part by the Center for Intelligent Information Retrieval, and in part by the National Science Foundation under Grant Nos."
    },
    "relationships": {}
  },
  {
    "id": "3097155",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 8,
          "left": 0.515966,
          "top": 0.833729,
          "width": 0.127731,
          "height": 0.00831354
        },
        {
          "page": 8,
          "left": 0.773109,
          "top": 0.817102,
          "width": 0.105882,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "DMR-1534431 and IIS-1514053.",
      "tex_start": 61456,
      "tex_end": 61484,
      "text": "DMR-1534431 and IIS-1514053."
    },
    "relationships": {}
  },
  {
    "id": "3097156",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.",
      "tex_start": 61485,
      "tex_end": 61644,
      "text": "Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor."
    },
    "relationships": {}
  },
  {
    "id": "3097157",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "emnlp2018}\n\\bibliographystyle{acl_natbib_nourl",
      "tex_start": 61699,
      "tex_end": 61745,
      "text": "emnlp2018 acl_natbib_nourl"
    },
    "relationships": {}
  },
  {
    "id": "3097158",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.488124,
          "width": 0.230252,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\section{Supplemental Material \\label{sec:supplemental}}",
      "tex_start": 61776,
      "tex_end": 61833,
      "text": "Supplemental Material \\label{sec:supplemental."
    },
    "relationships": {}
  },
  {
    "id": "3097159",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.522565,
          "width": 0.220168,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\\subsection{Supplemental analysis \\label{app:analysis}}",
      "tex_start": 61855,
      "tex_end": 61911,
      "text": "Supplemental analysis \\label{app:analysis."
    },
    "relationships": {}
  },
  {
    "id": "3097160",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.551069,
          "width": 0.322689,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Here we continue the analysis from \\S\\ref{sec:analysis}.",
      "tex_start": 61912,
      "tex_end": 61968,
      "text": "Here we continue the analysis from (Ref sec:analysis)."
    },
    "relationships": {}
  },
  {
    "id": "3097161",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "All experiments in this section are performed on CoNLL-2005 development data unless stated otherwise.",
      "tex_start": 61969,
      "tex_end": 62070,
      "text": "All experiments in this section are performed on CoNLL-2005 development data unless stated otherwise."
    },
    "relationships": {}
  },
  {
    "id": "3097162",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "llll}\nCoNLL-2005 & Greedy F1 & Viterbi F1 & $\\Delta$ F1",
      "tex_start": 62102,
      "tex_end": 62157,
      "text": "llll CoNLL-2005 & Greedy F1 & Viterbi F1 & EQUATION_DEPTH_0_START \\Delta EQUATION_DEPTH_0_END F1"
    },
    "relationships": {}
  },
  {
    "id": "3097163",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.132773,
          "top": 0.0961995,
          "width": 0.352941,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 81.99 & 82.24 & +0.25",
      "tex_start": 62175,
      "tex_end": 62203,
      "text": "LISA & 81.99 & 82.24 & +0.25"
    },
    "relationships": {}
  },
  {
    "id": "3097164",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.14958,
          "top": 0.112827,
          "width": 0.332773,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 83.37 & 83.58 & +0.21",
      "tex_start": 62215,
      "tex_end": 62244,
      "text": "+D&M & 83.37 & 83.58 & +0.21"
    },
    "relationships": {}
  },
  {
    "id": "3097165",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.151261,
          "top": 0.128266,
          "width": 0.336134,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{86.57} &\t\\emph{86.81} &\t\\emph{+0.24",
      "tex_start": 62262,
      "tex_end": 62312,
      "text": "+Gold & 86.57 &\t86.81 &\t+0.24"
    },
    "relationships": {}
  },
  {
    "id": "3097166",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "& & &",
      "tex_start": 62317,
      "tex_end": 62322,
      "text": "& & &"
    },
    "relationships": {}
  },
  {
    "id": "3097167",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.131092,
          "top": 0.160333,
          "width": 0.347899,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "CoNLL-2012 & Greedy F1 & Viterbi F1 & $\\Delta$ F1",
      "tex_start": 62326,
      "tex_end": 62375,
      "text": "CoNLL-2012 & Greedy F1 & Viterbi F1 & EQUATION_DEPTH_0_START \\Delta EQUATION_DEPTH_0_END F1"
    },
    "relationships": {}
  },
  {
    "id": "3097168",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.132773,
          "top": 0.179335,
          "width": 0.352941,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 80.11\t& 80.70\t & +0.59",
      "tex_start": 62393,
      "tex_end": 62422,
      "text": "LISA & 80.11\t& 80.70\t & +0.59"
    },
    "relationships": {}
  },
  {
    "id": "3097169",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.14958,
          "top": 0.195962,
          "width": 0.336134,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 81.55 &\t82.05 & +0.50",
      "tex_start": 62434,
      "tex_end": 62463,
      "text": "+D&M & 81.55 &\t82.05 & +0.50"
    },
    "relationships": {}
  },
  {
    "id": "3097170",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.151261,
          "top": 0.212589,
          "width": 0.336134,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{85.94} &\t\\emph{86.43} &\t\\emph{+0.49",
      "tex_start": 62481,
      "tex_end": 62531,
      "text": "+Gold & 85.94 &\t86.43 &\t+0.49"
    },
    "relationships": {}
  },
  {
    "id": "3097171",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.256532,
          "width": 0.337815,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.191597,
          "top": 0.239905,
          "width": 0.295798,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Comparison of development F1 scores with and without Viterbi decoding at test time.",
      "tex_start": 62560,
      "tex_end": 62643,
      "text": "Comparison of development F1 scores with and without Viterbi decoding at test time."
    },
    "relationships": {}
  },
  {
    "id": "3097172",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{viterbi-table}}",
      "tex_start": 62644,
      "tex_end": 62666,
      "text": "(Label viterbi-table)"
    },
    "relationships": {}
  },
  {
    "id": "3097173",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.129412,
          "top": 0.653207,
          "width": 0.356303,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.63658,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.141176,
          "top": 0.619952,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "First, we compare the impact of Viterbi decoding with LISA, D\\&M, and gold syntax trees (Table \\ref{viterbi-table}), finding the same trends across both datasets.",
      "tex_start": 62680,
      "tex_end": 62842,
      "text": "First, we compare the impact of Viterbi decoding with LISA, D&M, and gold syntax trees (Table (Ref viterbi-table)), finding the same trends across both datasets."
    },
    "relationships": {}
  },
  {
    "id": "3097174",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.71734,
          "width": 0.183193,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.700713,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.685273,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.668646,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We find that Viterbi has nearly the same impact for LISA, D\\&M and gold parses: Gold parses provide little improvement over predicted parses in terms of BIO label consistency.",
      "tex_start": 62843,
      "tex_end": 63018,
      "text": "We find that Viterbi has nearly the same impact for LISA, D&M and gold parses: Gold parses provide little improvement over predicted parses in terms of BIO label consistency."
    },
    "relationships": {}
  },
  {
    "id": "3097175",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "scale=0.52]{f1_by_sent_len.pdf",
      "tex_start": 63053,
      "tex_end": 63083,
      "text": "scale=0.52f1_by_sent_len.pdf"
    },
    "relationships": {}
  },
  {
    "id": "3097176",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "F1 score as a function of sentence length.",
      "tex_start": 63094,
      "tex_end": 63136,
      "text": "F1 score as a function of sentence length."
    },
    "relationships": {}
  },
  {
    "id": "3097177",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{fig:length}}",
      "tex_start": 63136,
      "tex_end": 63155,
      "text": "(Label fig:length)"
    },
    "relationships": {}
  },
  {
    "id": "3097178",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "scale=0.52]{f1_by_pred_dist.pdf",
      "tex_start": 63202,
      "tex_end": 63233,
      "text": "scale=0.52f1_by_pred_dist.pdf"
    },
    "relationships": {}
  },
  {
    "id": "3097179",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "CoNLL-2005 F1 score as a function of the distance of the predicate from the argument span.",
      "tex_start": 63244,
      "tex_end": 63334,
      "text": "CoNLL-2005 F1 score as a function of the distance of the predicate from the argument span."
    },
    "relationships": {}
  },
  {
    "id": "3097180",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{fig:dist}}",
      "tex_start": 63334,
      "tex_end": 63351,
      "text": "(Label fig:dist)"
    },
    "relationships": {}
  },
  {
    "id": "3097181",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.752969,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.141176,
          "top": 0.73753,
          "width": 0.346218,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also assess SRL F1 as a function of sentence length and distance from span to predicate.",
      "tex_start": 63366,
      "tex_end": 63457,
      "text": "We also assess SRL F1 as a function of sentence length and distance from span to predicate."
    },
    "relationships": {}
  },
  {
    "id": "3097182",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.801663,
          "width": 0.110924,
          "height": 0.00831354
        },
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.785036,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.769596,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In Figure \\ref{fig:length} we see that providing LISA with gold parses is particularly helpful for sentences longer than 10 tokens.",
      "tex_start": 63458,
      "tex_end": 63589,
      "text": "In Figure (Ref fig:length) we see that providing LISA with gold parses is particularly helpful for sentences longer than 10 tokens."
    },
    "relationships": {}
  },
  {
    "id": "3097183",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.121008,
          "top": 0.833729,
          "width": 0.14958,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.122689,
          "top": 0.817102,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.243697,
          "top": 0.801663,
          "width": 0.243697,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This likely directly follows from the tendency of syntactic parsers to perform worse on longer sentences.",
      "tex_start": 63590,
      "tex_end": 63695,
      "text": "This likely directly follows from the tendency of syntactic parsers to perform worse on longer sentences."
    },
    "relationships": {}
  },
  {
    "id": "3097184",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "With respect to distance between arguments and predicates, (Figure \\ref{fig:dist}), we do not observe this same trend, with all distances performing better with better parses, and especially gold.",
      "tex_start": 63696,
      "tex_end": 63892,
      "text": "With respect to distance between arguments and predicates, (Figure (Ref fig:dist)), we do not observe this same trend, with all distances performing better with better parses, and especially gold."
    },
    "relationships": {}
  },
  {
    "id": "3097185",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "lllll}\n& L+/D+ & L-/D+ & L+/D- & L-/D-",
      "tex_start": 65094,
      "tex_end": 65132,
      "text": "lllll & L+/D+ & L-/D+ & L+/D- & L-/D-"
    },
    "relationships": {}
  },
  {
    "id": "3097186",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.529412,
          "top": 0.311164,
          "width": 0.331092,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Proportion & 37\\% &\t10\\% &\t4\\% &\t49\\%",
      "tex_start": 65211,
      "tex_end": 65248,
      "text": "Proportion & 37\\% &\t10\\% &\t4\\% &\t49\\%"
    },
    "relationships": {}
  },
  {
    "id": "3097187",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.529412,
          "top": 0.327791,
          "width": 0.341176,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 76.12 & 75.97 & 82.25 &\t65.78",
      "tex_start": 65362,
      "tex_end": 65396,
      "text": "SA & 76.12 & 75.97 & 82.25 &\t65.78"
    },
    "relationships": {}
  },
  {
    "id": "3097188",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.529412,
          "top": 0.34323,
          "width": 0.341176,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 76.37 &\t72.38 &\t85.50 &\t65.10",
      "tex_start": 65401,
      "tex_end": 65437,
      "text": "LISA & 76.37 &\t72.38 &\t85.50 &\t65.10"
    },
    "relationships": {}
  },
  {
    "id": "3097189",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.546219,
          "top": 0.359857,
          "width": 0.32437,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & 76.33\t& 79.65 &\t75.62 &\t66.55",
      "tex_start": 65449,
      "tex_end": 65486,
      "text": "+D&M & 76.33\t& 79.65 &\t75.62 &\t66.55"
    },
    "relationships": {}
  },
  {
    "id": "3097190",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.547899,
          "top": 0.375297,
          "width": 0.322689,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{76.71} & \\emph{80.67} & \\emph{86.03} & \\emph{72.22",
      "tex_start": 65504,
      "tex_end": 65569,
      "text": "+Gold & 76.71 & 80.67 & 86.03 & 72.22"
    },
    "relationships": {}
  },
  {
    "id": "3097191",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Average SRL F1 on CoNLL-2012 for sentences where LISA (L) and D\\&M (D) parses were correct (+) or incorrect (-).",
      "tex_start": 65597,
      "tex_end": 65709,
      "text": "Average SRL F1 on CoNLL-2012 for sentences where LISA (L) and D&M (D) parses were correct (+) or incorrect (-)."
    },
    "relationships": {}
  },
  {
    "id": "3097192",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:app:parse-srl-by-sents}}",
      "tex_start": 65710,
      "tex_end": 65745,
      "text": "(Label tab:app:parse-srl-by-sents)"
    },
    "relationships": {}
  },
  {
    "id": "3097193",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Supplemental results}\n\n",
      "tex_start": 65757,
      "tex_end": 65794,
      "text": "Supplemental results."
    },
    "relationships": {}
  },
  {
    "id": "3097194",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Due to space constraints in the main paper we list additional experimental results here.",
      "tex_start": 65794,
      "tex_end": 65882,
      "text": "Due to space constraints in the main paper we list additional experimental results here."
    },
    "relationships": {}
  },
  {
    "id": "3097195",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Table \\ref{tab:conll05-gold-pred-dev} lists development scores on the CoNLL-2005 dataset with predicted predicates, which follow the same trends as the test data.",
      "tex_start": 65883,
      "tex_end": 66045,
      "text": "Table (Ref tab:conll05-gold-pred-dev) lists development scores on the CoNLL-2005 dataset with predicted predicates, which follow the same trends as the test data."
    },
    "relationships": {}
  },
  {
    "id": "3097196",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "llll}\nWSJ Dev & P & R & F1",
      "tex_start": 66077,
      "tex_end": 66103,
      "text": "llll WSJ Dev & P & R & F1"
    },
    "relationships": {}
  },
  {
    "id": "3097197",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.615126,
          "top": 0.768409,
          "width": 0.226891,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{he2018jointly} & 84.2 & 83.7 & 83.9",
      "tex_start": 66121,
      "tex_end": 66163,
      "text": "Citation (he2018jointly) & 84.2 & 83.7 & 83.9"
    },
    "relationships": {}
  },
  {
    "id": "3097198",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.620168,
          "top": 0.783848,
          "width": 0.218487,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\citet{tan2018deep} & 82.6\t& 83.6 &\t83.1",
      "tex_start": 66167,
      "tex_end": 66207,
      "text": "Citation (tan2018deep) & 82.6\t& 83.6 &\t83.1"
    },
    "relationships": {}
  },
  {
    "id": "3097199",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.54958,
          "top": 0.800475,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "SA & 83.12 &\t82.81 &\t82.97",
      "tex_start": 66218,
      "tex_end": 66244,
      "text": "SA & 83.12 &\t82.81 &\t82.97"
    },
    "relationships": {}
  },
  {
    "id": "3097200",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.54958,
          "top": 0.817102,
          "width": 0.302521,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "LISA & 83.6 &\t83.74\t& 83.67",
      "tex_start": 66248,
      "tex_end": 66275,
      "text": "LISA & 83.6 &\t83.74\t& 83.67"
    },
    "relationships": {}
  },
  {
    "id": "3097201",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.566387,
          "top": 0.832542,
          "width": 0.285714,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+D\\&M & {\\bf 85.04} &\t{\\bf 85.51} &\t{\\bf 85.27",
      "tex_start": 66287,
      "tex_end": 66333,
      "text": "+D&M & 85.04 &\t85.51 &\t85.27"
    },
    "relationships": {}
  },
  {
    "id": "3097202",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.568067,
          "top": 0.849169,
          "width": 0.284034,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "+Gold} & \\emph{89.11} &\t\\emph{89.38} & \t\\emph{89.25",
      "tex_start": 66352,
      "tex_end": 66403,
      "text": "+Gold & 89.11 &\t89.38 & \t89.25"
    },
    "relationships": {}
  },
  {
    "id": "3097203",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.515966,
          "top": 0.893112,
          "width": 0.317647,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.583193,
          "top": 0.876485,
          "width": 0.29916,
          "height": 0.00950119
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Precision, recall and F1 on the CoNLL-2005 development set with gold predicates.",
      "tex_start": 66428,
      "tex_end": 66508,
      "text": "Precision, recall and F1 on the CoNLL-2005 development set with gold predicates."
    },
    "relationships": {}
  },
  {
    "id": "3097204",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\\label{tab:conll05-gold-pred-dev}}",
      "tex_start": 66509,
      "tex_end": 66543,
      "text": "(Label tab:conll05-gold-pred-dev)"
    },
    "relationships": {}
  },
  {
    "id": "3097205",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.515966,
          "top": 0.611639,
          "width": 0.292437,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Data and pre-processing details}\n\n",
      "tex_start": 66555,
      "tex_end": 66603,
      "text": "Data and pre-processing details."
    },
    "relationships": {}
  },
  {
    "id": "3097206",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.556303,
          "top": 0.690024,
          "width": 0.0554622,
          "height": 0.00950119
        },
        {
          "page": 12,
          "left": 0.517647,
          "top": 0.672209,
          "width": 0.280672,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.517647,
          "top": 0.65677,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.517647,
          "top": 0.640143,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We initialize word embeddings with 100d pre-trained GloVe embeddings trained on 6 billion tokens of Wikipedia and Gigaword \\citep{pennington2014glove}.",
      "tex_start": 66603,
      "tex_end": 66754,
      "text": "We initialize word embeddings with 100d pre-trained GloVe embeddings trained on 6 billion tokens of Wikipedia and Gigaword Citation (pennington2014glove)."
    },
    "relationships": {}
  },
  {
    "id": "3097207",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 12,
          "left": 0.515966,
          "top": 0.705463,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 12,
          "left": 0.62521,
          "top": 0.688836,
          "width": 0.258824,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.114014,
          "width": 0.0403361,
          "height": 0.00593824
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.0950119,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.0795724,
          "width": 0.366387,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We evaluate the SRL performance of our models using the \\texttt{srl-eval.pl} script provided by the CoNLL-2005 shared task,\\footnote{\\protect\\url{http://www.lsi.upc.es/~srlconll/srl-eval.pl}} which computes segment-level precision, recall and F1 score.",
      "tex_start": 66755,
      "tex_end": 67007,
      "text": "We evaluate the SRL performance of our models using the srl-eval.pl script provided by the CoNLL-2005 shared task,http://www.lsi.upc.es/ srlconll/srl-eval.pl which computes segment-level precision, recall and F1 score."
    },
    "relationships": {}
  },
  {
    "id": "3097208",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.128266,
          "width": 0.211765,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.186555,
          "top": 0.111639,
          "width": 0.30084,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We also report the predicate detection scores output by this script.",
      "tex_start": 67008,
      "tex_end": 67076,
      "text": "We also report the predicate detection scores output by this script."
    },
    "relationships": {}
  },
  {
    "id": "3097209",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.160333,
          "width": 0.141176,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.143705,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.352941,
          "top": 0.128266,
          "width": 0.134454,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We evaluate parsing using the \\texttt{eval.pl} CoNLL script, which excludes punctuation.",
      "tex_start": 67077,
      "tex_end": 67165,
      "text": "We evaluate parsing using the eval.pl CoNLL script, which excludes punctuation."
    },
    "relationships": {}
  },
  {
    "id": "3097210",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.192399,
          "width": 0.181513,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.141176,
          "top": 0.17696,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We train distinct D\\&M parsers for CoNLL-2005 and CoNLL-2012.",
      "tex_start": 67167,
      "tex_end": 67228,
      "text": "We train distinct D&M parsers for CoNLL-2005 and CoNLL-2012."
    },
    "relationships": {}
  },
  {
    "id": "3097211",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.275534,
          "width": 0.0571429,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.152941,
          "top": 0.273159,
          "width": 0.00168067,
          "height": 0.00118765
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.256532,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.241093,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.224466,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.209026,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.317647,
          "top": 0.192399,
          "width": 0.169748,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Our D\\&M parsers are trained and validated using the same SRL data splits, except that for CoNLL-2005 section 22 is used for development (rather than 24), as this section is typically used for validation in PTB parsing.",
      "tex_start": 67229,
      "tex_end": 67448,
      "text": "Our D&M parsers are trained and validated using the same SRL data splits, except that for CoNLL-2005 section 22 is used for development (rather than 24), as this section is typically used for validation in PTB parsing."
    },
    "relationships": {}
  },
  {
    "id": "3097212",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.320665,
          "width": 0.181513,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.305226,
          "width": 0.363025,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.288599,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.205042,
          "top": 0.273159,
          "width": 0.282353,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We use Stanford dependencies v3.5 \\citep{deMarneffe2008} and POS tags from the Stanford CoreNLP \\texttt{left3words} model \\citep{toutanova2003feature}.",
      "tex_start": 67449,
      "tex_end": 67600,
      "text": "We use Stanford dependencies v3.5 Citation (deMarneffe2008) and POS tags from the Stanford CoreNLP left3words model Citation (toutanova2003feature)."
    },
    "relationships": {}
  },
  {
    "id": "3097213",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.385986,
          "width": 0.32437,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.369359,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.353919,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.337292,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.319328,
          "top": 0.320665,
          "width": 0.168067,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We use the pre-trained ELMo models\\footnote{\\protect\\url{https://github.com/allenai/bilm-tf}} and learn task-specific combinations of the ELMo representations which are provided as input instead of GloVe embeddings to the D\\&M parser with otherwise default settings.",
      "tex_start": 67601,
      "tex_end": 67867,
      "text": "We use the pre-trained ELMo modelshttps://github.com/allenai/bilm-tf and learn task-specific combinations of the ELMo representations which are provided as input instead of GloVe embeddings to the D&M parser with otherwise default settings."
    },
    "relationships": {}
  },
  {
    "id": "3097214",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.412114,
          "width": 0.161345,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsubsection{CoNLL-2012}\n",
      "tex_start": 67867,
      "tex_end": 67896,
      "text": "CoNLL-2012."
    },
    "relationships": {}
  },
  {
    "id": "3097215",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.496437,
          "width": 0.312605,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.47981,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.463183,
          "width": 0.366387,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.447743,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.431116,
          "width": 0.29916,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We follow the CoNLL-2012 split used by \\citet{he2018jointly} to evaluate our models, which uses the annotations from here\\footnote{\\protect\\url{http://cemantix.org/data/ontonotes.html}} but the subset of those documents from the CoNLL-2012 co-reference split described here\\footnote{\\protect\\url{http://conll.cemantix.org/2012/data.html}} \\citep{pradhan2013towards}.",
      "tex_start": 67896,
      "tex_end": 68262,
      "text": "We follow the CoNLL-2012 split used by Citation (he2018jointly) to evaluate our models, which uses the annotations from herehttp://cemantix.org/data/ontonotes.html but the subset of those documents from the CoNLL-2012 co-reference split described herehttp://conll.cemantix.org/2012/data.html Citation (pradhan2013towards)."
    },
    "relationships": {}
  },
  {
    "id": "3097216",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.56057,
          "width": 0.0386555,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.543943,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.528504,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.511876,
          "width": 0.364706,
          "height": 0.00950119
        },
        {
          "page": 13,
          "left": 0.455462,
          "top": 0.496437,
          "width": 0.0319328,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This dataset is drawn from seven domains: newswire, web, broadcast news and conversation, magazines, telephone conversations, and text from the bible.",
      "tex_start": 68263,
      "tex_end": 68413,
      "text": "This dataset is drawn from seven domains: newswire, web, broadcast news and conversation, magazines, telephone conversations, and text from the bible."
    },
    "relationships": {}
  },
  {
    "id": "3097217",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.624703,
          "width": 0.154622,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.608076,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.592637,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.57601,
          "width": 0.363025,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.178151,
          "top": 0.56057,
          "width": 0.309244,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The text is annotated with gold part-of-speech, syntactic constituencies, named entities, word sense, speaker, co-reference and semantic role labels based on the PropBank guidelines \\citep{palmer2005proposition}.",
      "tex_start": 68414,
      "tex_end": 68626,
      "text": "The text is annotated with gold part-of-speech, syntactic constituencies, named entities, word sense, speaker, co-reference and semantic role labels based on the PropBank guidelines Citation (palmer2005proposition)."
    },
    "relationships": {}
  },
  {
    "id": "3097218",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.673397,
          "width": 0.0941176,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.65677,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.64133,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 13,
          "left": 0.287395,
          "top": 0.624703,
          "width": 0.198319,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "Propositions may be verbal or nominal, and there are 41 distinct semantic role labels, excluding continuation roles and including the predicate.",
      "tex_start": 68627,
      "tex_end": 68771,
      "text": "Propositions may be verbal or nominal, and there are 41 distinct semantic role labels, excluding continuation roles and including the predicate."
    },
    "relationships": {}
  },
  {
    "id": "3097219",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.720903,
          "width": 0.220168,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.122689,
          "top": 0.705463,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.688836,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.22521,
          "top": 0.673397,
          "width": 0.262185,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We convert the semantic proposition and role segmentations to BIO boundary-encoded tags, resulting in 129 distinct BIO-encoded tags (including continuation roles).",
      "tex_start": 68772,
      "tex_end": 68935,
      "text": "We convert the semantic proposition and role segmentations to BIO boundary-encoded tags, resulting in 129 distinct BIO-encoded tags (including continuation roles)."
    },
    "relationships": {}
  },
  {
    "id": "3097220",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.747031,
          "width": 0.161345,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": " \n\n\\subsubsection{CoNLL-2005}\n",
      "tex_start": 68935,
      "tex_end": 68965,
      "text": "CoNLL-2005."
    },
    "relationships": {}
  },
  {
    "id": "3097221",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.799287,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.157983,
          "top": 0.783848,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.121008,
          "top": 0.767221,
          "width": 0.366387,
          "height": 0.00950119
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.143705,
          "width": 0.203361,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.128266,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.111639,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.0950119,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.0795724,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The CoNLL-2005 data \\citep{carreras2005introduction} is based on the original PropBank corpus \\citep{palmer2005proposition}, which labels the Wall Street Journal portion of the Penn TreeBank corpus (PTB) \\citep{marcus1993building} with predicate-argument structures, plus a challenging out-of-domain test set derived from the Brown corpus \\citep{francis1964manual}.",
      "tex_start": 68965,
      "tex_end": 69330,
      "text": "The CoNLL-2005 data Citation (carreras2005introduction) is based on the original PropBank corpus Citation (palmer2005proposition), which labels the Wall Street Journal portion of the Penn TreeBank corpus (PTB) Citation (marcus1993building) with predicate-argument structures, plus a challenging out-of-domain test set derived from the Brown corpus Citation (francis1964manual)."
    },
    "relationships": {}
  },
  {
    "id": "3097222",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.175772,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.160333,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.729412,
          "top": 0.143705,
          "width": 0.152941,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "This dataset contains only verbal predicates, though some are multi-word verbs, and 28 distinct role label types.",
      "tex_start": 69331,
      "tex_end": 69444,
      "text": "This dataset contains only verbal predicates, though some are multi-word verbs, and 28 distinct role label types."
    },
    "relationships": {}
  },
  {
    "id": "3097223",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.224466,
          "width": 0.146218,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.207838,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.192399,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.860504,
          "top": 0.175772,
          "width": 0.0235294,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We obtain 105 SRL labels including continuations after encoding predicate argument segment boundaries with BIO tags.",
      "tex_start": 69445,
      "tex_end": 69561,
      "text": "We obtain 105 SRL labels including continuations after encoding predicate argument segment boundaries with BIO tags."
    },
    "relationships": {}
  },
  {
    "id": "3097224",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.249406,
          "width": 0.322689,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "\n\n\\subsection{Optimization and hyperparameters}\n",
      "tex_start": 69561,
      "tex_end": 69609,
      "text": "Optimization and hyperparameters."
    },
    "relationships": {}
  },
  {
    "id": "3097225",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.552941,
          "top": 0.337292,
          "width": 0.010084,
          "height": 0.00950119
        },
        {
          "page": 13,
          "left": 0.552941,
          "top": 0.319477,
          "width": 0.329412,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.304038,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.287411,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.271971,
          "width": 0.364706,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We train the model using the Nadam \\citep{dozat2016incorporating} algorithm for adaptive stochastic gradient descent (SGD), which combines Adam \\citep{kingma2014adam} SGD with Nesterov momentum \\citep{nesterov1983method}.",
      "tex_start": 69609,
      "tex_end": 69830,
      "text": "We train the model using the Nadam Citation (dozat2016incorporating) algorithm for adaptive stochastic gradient descent (SGD), which combines Adam Citation (kingma2014adam) SGD with Nesterov momentum Citation (nesterov1983method)."
    },
    "relationships": {}
  },
  {
    "id": "3097226",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.490499,
          "width": 0.0252101,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.475059,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.458432,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.442993,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.531092,
          "top": 0.410926,
          "width": 0.351261,
          "height": 0.0142518
        },
        {
          "page": 13,
          "left": 0.557983,
          "top": 0.384798,
          "width": 0.263866,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.368171,
          "width": 0.29916,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.350356,
          "width": 0.368067,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.576471,
          "top": 0.334917,
          "width": 0.305882,
          "height": 0.0118765
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We additionally vary the learning rate $lr$ as a function of an initial learning rate $lr_0$ and the current training step $step$ as described in \\citet{vaswani2017attention} using the following function:\n\\begin{align}\nlr = lr_0 \\cdot \\min(step^{-0.5},  step\\cdot warm^{-1.5})\n\\end{align}\nwhich increases the learning rate linearly for the first $warm$ training steps, then decays it proportionally to the inverse square root of the step number.",
      "tex_start": 69831,
      "tex_end": 70276,
      "text": "We additionally vary the learning rate EQUATION_DEPTH_0_START lr EQUATION_DEPTH_0_END as a function of an initial learning rate EQUATION_DEPTH_0_START lr_0 EQUATION_DEPTH_0_END and the current training step EQUATION_DEPTH_0_START step EQUATION_DEPTH_0_END as described in Citation (vaswani2017attention) using the following function: EQUATION_DEPTH_0_START lr = lr_0 \\cdot \\min(step^{-0.5},  step\\cdot warm^{-1.5})\nEQUATION_DEPTH_0_END which increases the learning rate linearly for the first EQUATION_DEPTH_0_START warm EQUATION_DEPTH_0_END training steps, then decays it proportionally to the inverse square root of the step number."
    },
    "relationships": {}
  },
  {
    "id": "3097227",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.507126,
          "width": 0.265546,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.551261,
          "top": 0.490499,
          "width": 0.329412,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We found this learning rate schedule essential for training the self-attention model.",
      "tex_start": 70277,
      "tex_end": 70362,
      "text": "We found this learning rate schedule essential for training the self-attention model."
    },
    "relationships": {}
  },
  {
    "id": "3097228",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.554632,
          "width": 0.0907563,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.539192,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.522565,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.793277,
          "top": 0.507126,
          "width": 0.0890756,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We only update optimization moving-average accumulators for parameters which receive gradient updates at a given step.\\footnote{Also known as \\emph{lazy} or \\emph{sparse} optimizer updates.",
      "tex_start": 70363,
      "tex_end": 70552,
      "text": "We only update optimization moving-average accumulators for parameters which receive gradient updates at a given step.Also known as lazy or sparse optimizer updates."
    },
    "relationships": {}
  },
  {
    "id": "3097229",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.603325,
          "width": 0.238655,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.585511,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.536134,
          "top": 0.571259,
          "width": 0.346218,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In all of our experiments we used initial learning rate 0.04, $\\beta_1=0.9$, $\\beta_2=0.98$, $\\epsilon=1\\times10^{-12}$ and dropout rates of 0.1 everywhere.",
      "tex_start": 70586,
      "tex_end": 70742,
      "text": "In all of our experiments we used initial learning rate 0.04, EQUATION_DEPTH_0_START \\beta_1=0.9 EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START \\beta_2=0.98 EQUATION_DEPTH_0_END , EQUATION_DEPTH_0_START \\epsilon=1\\times10^{-12} EQUATION_DEPTH_0_END and dropout rates of 0.1 everywhere."
    },
    "relationships": {}
  },
  {
    "id": "3097230",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.652019,
          "width": 0.188235,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.635392,
          "width": 0.366387,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.619952,
          "width": 0.364706,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.764706,
          "top": 0.603325,
          "width": 0.117647,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We use 10 or 12 self-attention layers made up of 8 attention heads each with embedding dimension 25, with 800d feed-forward projections.",
      "tex_start": 70743,
      "tex_end": 70879,
      "text": "We use 10 or 12 self-attention layers made up of 8 attention heads each with embedding dimension 25, with 800d feed-forward projections."
    },
    "relationships": {}
  },
  {
    "id": "3097231",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.684085,
          "width": 0.268908,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.666271,
          "width": 0.364706,
          "height": 0.0142518
        },
        {
          "page": 13,
          "left": 0.729412,
          "top": 0.652019,
          "width": 0.152941,
          "height": 0.0106888
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "In the syntactically-informed attention head, $Q_{parse}$ has dimension 500 and $K_{parse}$ has dimension 100.",
      "tex_start": 70880,
      "tex_end": 70990,
      "text": "In the syntactically-informed attention head, EQUATION_DEPTH_0_START Q_{parse} EQUATION_DEPTH_0_END has dimension 500 and EQUATION_DEPTH_0_START K_{parse} EQUATION_DEPTH_0_END has dimension 100."
    },
    "relationships": {}
  },
  {
    "id": "3097232",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.731591,
          "width": 0.147899,
          "height": 0.00831354
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.716152,
          "width": 0.368067,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.515966,
          "top": 0.698337,
          "width": 0.366387,
          "height": 0.0118765
        },
        {
          "page": 13,
          "left": 0.798319,
          "top": 0.684085,
          "width": 0.0857143,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "The size of $predicate$ and $role$ representations and the representation used for joint part-of-speech/predicate classification is 200.",
      "tex_start": 70991,
      "tex_end": 71127,
      "text": "The size of EQUATION_DEPTH_0_START predicate EQUATION_DEPTH_0_END and EQUATION_DEPTH_0_START role EQUATION_DEPTH_0_END representations and the representation used for joint part-of-speech/predicate classification is 200."
    },
    "relationships": {}
  },
  {
    "id": "3097233",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.748219,
          "width": 0.327731,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.672269,
          "top": 0.731591,
          "width": 0.210084,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We train with $warm=8000$ warmup steps and clip gradient norms to 1.",
      "tex_start": 71128,
      "tex_end": 71196,
      "text": "We train with EQUATION_DEPTH_0_START warm=8000 EQUATION_DEPTH_0_END warmup steps and clip gradient norms to 1."
    },
    "relationships": {}
  },
  {
    "id": "3097234",
    "type": "sentence",
    "attributes": {
      "bounding_boxes": [
        {
          "page": 13,
          "left": 0.517647,
          "top": 0.764846,
          "width": 0.309244,
          "height": 0.0106888
        },
        {
          "page": 13,
          "left": 0.860504,
          "top": 0.748219,
          "width": 0.0235294,
          "height": 0.00831354
        }
      ],
      "source": "tex-pipeline",
      "tags": [],
      "tex": "We use batches of approximately 5000 tokens.",
      "tex_start": 71197,
      "tex_end": 71241,
      "text": "We use batches of approximately 5000 tokens."
    },
    "relationships": {}
  }
]