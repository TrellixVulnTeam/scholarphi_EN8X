{
  "1908.07816": [
    {
      "text": "More recently, researchers started incorporating affect information into neural dialog models.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8704924242424242,
          "width": 0.37902450980392144,
          "height": 0.012578282828282994,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8855871212121212,
          "width": 0.24203758169934642,
          "height": 0.012578282828282772,
          "page": 0
        }
      ]
    },
    {
      "text": "Recent development in neural language modeling has generated significant excitement in the open-domain dialog generation community.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6138787878787879,
          "width": 0.37903104575163393,
          "height": 0.012578282828282772,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6289734848484848,
          "width": 0.39530392156862737,
          "height": 0.012578282828282772,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6440681818181818,
          "width": 0.1338137254901961,
          "height": 0.012578282828282772,
          "page": 0
        }
      ]
    },
    {
      "text": "Many application areas show significant benefits of integrating affect information in natural language dialogs.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3119810606060606,
          "width": 0.3953039215686275,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3270757575757576,
          "width": 0.32906209150326804,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08736274509803922,
          "top": 0.687959595959596,
          "width": 0.15991503267973856,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7759684343434343,
          "width": 0.3928071895424837,
          "height": 0.010063131313131302,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7885479797979797,
          "width": 0.39256535947712423,
          "height": 0.010063131313131302,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8011275252525253,
          "width": 0.3925653594771242,
          "height": 0.01006313131313119,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8137058080808082,
          "width": 0.2805718954248366,
          "height": 0.01006313131313119,
          "page": 0
        }
      ]
    },
    {
      "text": "IUI 20 Workshops, March 17, 2020, Cagliari, Italy",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8527020202020202,
          "width": 0.25502941176470595,
          "height": 0.01006313131313119,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM ISBN 978-x-xxxx-xxxx-x/YY/MM.",
      "bboxes": [
        {
          "left": 0.08744934640522875,
          "top": 0.8791174242424242,
          "width": 0.21019117647058824,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Furthermore, to the best of our knowledge, the psychology and social science literature does not provide clear rules for emotional interaction.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2557840909090909,
          "width": 0.37670261437908503,
          "height": 0.012578282828282827,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2708787878787879,
          "width": 0.39286928104575164,
          "height": 0.012578282828282827,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2859734848484849,
          "width": 0.15046895424836598,
          "height": 0.012578282828282827,
          "page": 1
        }
      ]
    },
    {
      "text": "Vinyals and Le [42] were one of the first to model dialog generation using neural networks.",
      "bboxes": [
        {
          "left": 0.5189967320261437,
          "top": 0.15766666666666668,
          "width": 0.39584313725490194,
          "height": 0.012578282828282827,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17276136363636363,
          "width": 0.2124199346405229,
          "height": 0.012578282828282827,
          "page": 1
        }
      ]
    },
    {
      "text": "The standard seq2seq framework is applied to single-turn response generation.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3086161616161616,
          "width": 0.3762728758169934,
          "height": 0.012578282828282827,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.32371085858585863,
          "width": 0.1356225490196079,
          "height": 0.012578282828282827,
          "page": 1
        }
      ]
    },
    {
      "text": "Recent work on incorporating affect information into natural language processing tasks has inspired our current work.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5274924242424243,
          "width": 0.39256045751633983,
          "height": 0.012578282828282772,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5425871212121212,
          "width": 0.3950669934640523,
          "height": 0.012578282828282772,
          "page": 1
        }
      ]
    },
    {
      "text": "As much as these work in the above section inspired our work, our approach in generating affect dialogs is significantly different.",
      "bboxes": [
        {
          "left": 0.08733660130718955,
          "top": 0.6935366161616161,
          "width": 0.39343954248366014,
          "height": 0.012578282828282994,
          "page": 2
        },
        {
          "left": 0.08730392156862746,
          "top": 0.7086313131313131,
          "width": 0.3959133986928104,
          "height": 0.012578282828282772,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7237260101010101,
          "width": 0.10292973856209152,
          "height": 0.012578282828282772,
          "page": 2
        }
      ]
    },
    {
      "text": "The Emotional Chatting Machine (ECM) [49] takes a post and generates a response in a predefined emotion category.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3312588383838384,
          "width": 0.3762843137254902,
          "height": 0.012578282828282827,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.34635353535353536,
          "width": 0.39506209150326804,
          "height": 0.012578282828282827,
          "page": 2
        }
      ]
    },
    {
      "text": "Usually the probability distribution p ( y | X ) can be modeled by an RNN language model conditioned on X .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.44583964646464647,
          "width": 0.37902777777777774,
          "height": 0.013622474747474744,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.46192803030303026,
          "width": 0.3469542483660132,
          "height": 0.012616161616161692,
          "page": 2
        }
      ]
    },
    {
      "text": "In parallel to these developments, Zhong et al.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5576818181818182,
          "width": 0.31466830065359475,
          "height": 0.012578282828282772,
          "page": 2
        }
      ]
    },
    {
      "text": "The hierarchical attention structure involves two encoders to produce the dialog context vector c t , namely the word-level encoder and the utterance-level encoder.",
      "bboxes": [
        {
          "left": 0.5190457516339869,
          "top": 0.658719696969697,
          "width": 0.3930539215686275,
          "height": 0.012578282828282772,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6737765151515152,
          "width": 0.39256535947712423,
          "height": 0.013717171717171683,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6889090909090909,
          "width": 0.2664248366013072,
          "height": 0.012578282828282772,
          "page": 2
        }
      ]
    },
    {
      "text": "We describe our model one element at a time, from the basic structure, to the hierarchical component, and finally the emotion embedding layer.",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.1959229797979798,
          "width": 0.3933415032679739,
          "height": 0.012578282828282855,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.21101767676767677,
          "width": 0.39256045751633983,
          "height": 0.012578282828282827,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.22611363636363635,
          "width": 0.17257189542483664,
          "height": 0.012578282828282855,
          "page": 2
        }
      ]
    },
    {
      "text": "The utterance-level encoder is a unidirectional RNN with GRU that goes from the last utterance in the context to the first, with its input at each step as the summary of the corresponding utterance, which is obtained by applying a Bahdanau-style attention mechanism [2] on the word-level",
      "bboxes": [
        {
          "left": 0.5190457516339869,
          "top": 0.8293901515151515,
          "width": 0.39304084967320263,
          "height": 0.012578282828282994,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8444848484848485,
          "width": 0.39256045751633994,
          "height": 0.012578282828282772,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8595795454545455,
          "width": 0.39256045751633983,
          "height": 0.012578282828282772,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8746755050505051,
          "width": 0.39256045751633983,
          "height": 0.012578282828282772,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.889770202020202,
          "width": 0.3925669934640523,
          "height": 0.012578282828282772,
          "page": 2
        }
      ]
    },
    {
      "text": "We first consider the problem of generating response y given a context X consisting of multiple previous utterances by estimating the probability distribution p ( y | X ) from a data set D = {( X ( i ) , y ( i ) )} Ni = 1 containing N context-response pairs.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.24117045454545455,
          "width": 0.37545098039215674,
          "height": 0.01261616161616158,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2562651515151515,
          "width": 0.39256535947712423,
          "height": 0.012616161616161636,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2703661616161616,
          "width": 0.39256209150326793,
          "height": 0.013622474747474744,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.28387247474747473,
          "width": 0.39256209150326793,
          "height": 0.01874747474747479,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3019128787878788,
          "width": 0.03628594771241833,
          "height": 0.012578282828282827,
          "page": 2
        }
      ]
    },
    {
      "text": "We are able to achieve this goal, i.e., capturing the emotion information carried in the context X , in the encoder, thanks to LIWC.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7992007575757576,
          "width": 0.3762875816993463,
          "height": 0.012578282828282772,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8142575757575758,
          "width": 0.39256045751633983,
          "height": 0.012616161616161525,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8293901515151515,
          "width": 0.058419934640522864,
          "height": 0.012578282828282994,
          "page": 3
        }
      ]
    },
    {
      "text": "The main objective of the emotion embedding layer is to recognize the affect information in the given utterances so that the model can respond with emotionally appropriate replies.",
      "bboxes": [
        {
          "left": 0.5190457516339869,
          "top": 0.6935366161616161,
          "width": 0.39304084967320263,
          "height": 0.012578282828282994,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7086313131313131,
          "width": 0.39256209150326793,
          "height": 0.012578282828282772,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7237260101010101,
          "width": 0.39256045751633983,
          "height": 0.012578282828282772,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.738820707070707,
          "width": 0.046616013071895446,
          "height": 0.012578282828282772,
          "page": 3
        }
      ]
    },
    {
      "text": "Here  tj is the utterance-level attention score placed on  tj , and can be calculated as",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.525621212121212,
          "width": 0.3943513071895425,
          "height": 0.017736111111111175,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5433118686868686,
          "width": 0.16008496732026145,
          "height": 0.012578282828282772,
          "page": 3
        }
      ]
    },
    {
      "text": "Here  tjk is the word-level attention score placed on h jk , and can be calculated as",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6330530303030303,
          "width": 0.39256699346405227,
          "height": 0.018579545454545432,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6515883838383838,
          "width": 0.13151633986928107,
          "height": 0.012578282828282772,
          "page": 3
        }
      ]
    },
    {
      "text": "We trained our model using two different datasets and compared its performance with HRAN as well as the basic seq2seq model by performing both offline and online testings.",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.38346590909090905,
          "width": 0.3960947712418301,
          "height": 0.012578282828282827,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3985606060606061,
          "width": 0.39345261437908496,
          "height": 0.012578282828282827,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.41365530303030307,
          "width": 0.35515359477124175,
          "height": 0.012578282828282827,
          "page": 4
        }
      ]
    },
    {
      "text": "We used two different dialog corpora to train our model the Cornell Movie Dialogs Corpus [6] and the DailyDialog dataset [20].",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.45926262626262626,
          "width": 0.3951503267973857,
          "height": 0.012578282828282827,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.47435858585858587,
          "width": 0.39256535947712423,
          "height": 0.012578282828282827,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4894532828282828,
          "width": 0.08141013071895431,
          "height": 0.012578282828282772,
          "page": 4
        }
      ]
    },
    {
      "text": "In our experiments, the models were first trained on the Cornell Movie Dialogs Corpus, and then fine-tuned on the DailyDialog dataset.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6614583333333334,
          "width": 0.3762777777777778,
          "height": 0.012578282828282772,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6765530303030304,
          "width": 0.39255228758169936,
          "height": 0.012578282828282772,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6916477272727273,
          "width": 0.13821405228758166,
          "height": 0.012578282828282772,
          "page": 4
        }
      ]
    },
    {
      "text": "The probability distribution p ( y | X ) can be written as",
      "bboxes": [
        {
          "left": 0.08741666666666667,
          "top": 0.4853535353535353,
          "width": 0.3568366013071895,
          "height": 0.0136224747474748,
          "page": 4
        }
      ]
    },
    {
      "text": "We use the cross-entropy loss as our objective function",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.2950164141414141,
          "width": 0.3666143790849674,
          "height": 0.012578282828282827,
          "page": 4
        }
      ]
    },
    {
      "text": "We model the probability distribution using an RNN language model along with the emotion context vector e .",
      "bboxes": [
        {
          "left": 0.08712418300653595,
          "top": 0.5762550505050505,
          "width": 0.39609640522875816,
          "height": 0.012578282828282772,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5913118686868687,
          "width": 0.3471421568627452,
          "height": 0.012616161616161525,
          "page": 4
        }
      ]
    },
    {
      "text": "We two datasets in Table 1.",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.6312689393939394,
          "width": 0.021411764705882463,
          "height": 0.012578282828282883,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6463636363636364,
          "width": 0.15538071895424832,
          "height": 0.012578282828282772,
          "page": 4
        }
      ]
    },
    {
      "text": "Thus a lower perplexity score indicates that the model has better capability of predicting the target sentence, i.e., the humans response.",
      "bboxes": [
        {
          "left": 0.5190457516339869,
          "top": 0.39586363636363636,
          "width": 0.3930571895424837,
          "height": 0.012578282828282827,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4109583333333333,
          "width": 0.39256045751633983,
          "height": 0.012578282828282827,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4260530303030303,
          "width": 0.1237205882352942,
          "height": 0.012578282828282827,
          "page": 5
        }
      ]
    },
    {
      "text": "Human Evaluation.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6784532828282829,
          "width": 0.12200326797385619,
          "height": 0.012578282828282772,
          "page": 5
        }
      ]
    },
    {
      "text": "Our choice of including S2S is rather obvious.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.2565290404040404,
          "width": 0.32217320261437904,
          "height": 0.012578282828282827,
          "page": 5
        }
      ]
    },
    {
      "text": "BLEU score is often used to measure the quality of machinetranslated text.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5619078282828283,
          "width": 0.380611111111111,
          "height": 0.012578282828282772,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5770025252525253,
          "width": 0.09723529411764709,
          "height": 0.012578282828282772,
          "page": 5
        }
      ]
    },
    {
      "text": "The evaluation of chatbots remains an open problem in the field.",
      "bboxes": [
        {
          "left": 0.08741666666666667,
          "top": 0.8377272727272728,
          "width": 0.3930506535947712,
          "height": 0.012578282828282772,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8528219696969697,
          "width": 0.03312581699346405,
          "height": 0.012578282828282994,
          "page": 5
        }
      ]
    },
    {
      "text": "BLEU score [27] tend to align poorly with human judgement.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.11992929292929293,
          "width": 0.3950702614379086,
          "height": 0.012578282828282841,
          "page": 5
        }
      ]
    },
    {
      "text": "Automatic Evaluation.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.19119065656565656,
          "width": 0.1406732026143791,
          "height": 0.012578282828282827,
          "page": 5
        }
      ]
    },
    {
      "text": "We have made the source code publicly available.",
      "bboxes": [
        {
          "left": 0.08712418300653595,
          "top": 0.7916982323232323,
          "width": 0.3281470588235294,
          "height": 0.012578282828282772,
          "page": 5
        }
      ]
    },
    {
      "text": "Human Evaluation Experiment Design.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7243674242424242,
          "width": 0.24882026143790845,
          "height": 0.012578282828282772,
          "page": 6
        }
      ]
    },
    {
      "text": "Preparation of Natural Dialog Test Set.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3542209595959596,
          "width": 0.2574330065359477,
          "height": 0.012578282828282827,
          "page": 6
        }
      ]
    },
    {
      "text": "Automatic Evaluation Results.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5331287878787879,
          "width": 0.19815686274509803,
          "height": 0.012578282828282772,
          "page": 6
        }
      ]
    },
    {
      "text": "Human Evaluation Results.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6482638888888889,
          "width": 0.1775506535947713,
          "height": 0.012578282828282772,
          "page": 6
        }
      ]
    },
    {
      "text": "In this subsection, we present the experimental results of the automatic evaluation metric as well as human judgement, followed by some analysis.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.47835984848484847,
          "width": 0.39256045751633994,
          "height": 0.012578282828282827,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4934545454545454,
          "width": 0.39435294117647046,
          "height": 0.012578282828282938,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5085492424242425,
          "width": 0.1779754901960784,
          "height": 0.012578282828282772,
          "page": 6
        }
      ]
    },
    {
      "text": "For each criterion, the raters gave scores of either 0, 1 or 2, where 0 means bad, 2 means good, and 1 indicates neutral.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.37077146464646465,
          "width": 0.3943513071895426,
          "height": 0.012578282828282827,
          "page": 6
        },
        {
          "left": 0.5189330065359476,
          "top": 0.3858661616161616,
          "width": 0.36898039215686285,
          "height": 0.012578282828282827,
          "page": 6
        }
      ]
    },
    {
      "text": "With t-SNE [25], we are able to reduce the dimensionality of the weights to two, and visualize them in a straightforward way.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.753915404040404,
          "width": 0.3767009803921567,
          "height": 0.012578282828282772,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.769010101010101,
          "width": 0.39256045751633983,
          "height": 0.012578282828282772,
          "page": 7
        },
        {
          "left": 0.5189330065359476,
          "top": 0.7841060606060606,
          "width": 0.031232026143790947,
          "height": 0.012578282828282994,
          "page": 7
        }
      ]
    },
    {
      "text": "The comparison between perplexity scores and human evaluation results further confirms the fact that in the context",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8526805555555556,
          "width": 0.3762875816993464,
          "height": 0.012578282828282772,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8677752525252526,
          "width": 0.39256045751633994,
          "height": 0.012578282828282772,
          "page": 7
        }
      ]
    },
    {
      "text": "Visualization of Output Layer Weights.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.39165025252525254,
          "width": 0.2477107843137254,
          "height": 0.012578282828282827,
          "page": 7
        }
      ]
    },
    {
      "text": "We pre-trained our model on the Cornell movie subtitles and then fine-tuned it with the DailyDialog dataset.",
      "bboxes": [
        {
          "left": 0.5187532679738561,
          "top": 0.44135101010101013,
          "width": 0.393341503267974,
          "height": 0.012578282828282827,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4564457070707071,
          "width": 0.3109379084967321,
          "height": 0.012578282828282827,
          "page": 8
        }
      ]
    },
    {
      "text": "To extract the affect information contained in the utterances, we used the LIWC text analysis program.",
      "bboxes": [
        {
          "left": 0.08741666666666667,
          "top": 0.769010101010101,
          "width": 0.39484150326797385,
          "height": 0.012578282828282772,
          "page": 8
        },
        {
          "left": 0.08730392156862746,
          "top": 0.7841060606060606,
          "width": 0.28403431372549015,
          "height": 0.012578282828282994,
          "page": 8
        }
      ]
    },
    {
      "text": "Evaluation of dialog models remains an open problem in the response generation field.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6685719696969697,
          "width": 0.39256045751633994,
          "height": 0.012578282828282772,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6836666666666668,
          "width": 0.16548202614379093,
          "height": 0.012578282828282772,
          "page": 8
        }
      ]
    },
    {
      "text": "In this section, we briefly discuss how our framework can incorporate other components, as well as several directions to extend it.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6922310606060605,
          "width": 0.39256045751633994,
          "height": 0.012578282828282772,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7073257575757576,
          "width": 0.39255392156862745,
          "height": 0.012578282828282772,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7224204545454546,
          "width": 0.07924509803921571,
          "height": 0.012578282828282772,
          "page": 8
        }
      ]
    },
    {
      "text": "Our model uses RNNs to encode the input sequences, and GRU cells to capture long-term dependency among different positions in the sequences.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5376830808080808,
          "width": 0.39256045751633994,
          "height": 0.012578282828282772,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5527790404040404,
          "width": 0.3925604575163399,
          "height": 0.012578282828282772,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5678737373737374,
          "width": 0.17981862745098043,
          "height": 0.012578282828282883,
          "page": 9
        }
      ]
    },
    {
      "text": "We believe reproducing conversational and emotional intelligence will make social chatbots more believable and engaging. In this paper, we proposed a multi-turn dialog system",
      "bboxes": [
        {
          "left": 0.08712418300653595,
          "top": 0.8595795454545455,
          "width": 0.39609967320261436,
          "height": 0.012578282828282772,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8746755050505051,
          "width": 0.3953039215686274,
          "height": 0.012578282828282772,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.889770202020202,
          "width": 0.3925604575163399,
          "height": 0.012578282828282772,
          "page": 9
        }
      ]
    }
  ],
  "1810.11143": [
    {
      "text": "A straightforward solution is to empower the affected communities directly.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6353775252525252,
          "width": 0.3787630718954248,
          "height": 0.011320707070706981,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6492146464646464,
          "width": 0.07291503267973853,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Nevertheless, the quality of the gathered data is doubtful.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8152588383838383,
          "width": 0.34767810457516335,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Air pollution has been associated with adverse impacts on human health, including respiratory and cardiovascular diseases [43, 72, 101, 105, 127].",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.4139861111111111,
          "width": 0.39307516339869275,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4278232323232323,
          "width": 0.39417156862745095,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5191977124183007,
          "top": 0.44166035353535354,
          "width": 0.08325326797385613,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7837247474747475,
          "width": 0.3927761437908497,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7937878787878787,
          "width": 0.3925588235294118,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8038510101010101,
          "width": 0.39256045751633994,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.813915404040404,
          "width": 0.07863071895424838,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "Randy Sargent Carnegie Mellon University rsargent@andrew.cmu.edu",
      "bboxes": [
        {
          "left": 0.7098480392156863,
          "top": 0.22657070707070706,
          "width": 0.11673856209150324,
          "height": 0.015095959595959607,
          "page": 0
        },
        {
          "left": 0.6763235294117648,
          "top": 0.24359469696969696,
          "width": 0.1842107843137255,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.6789444444444445,
          "top": 0.25868939393939394,
          "width": 0.1785457516339869,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "Illah Nourbakhsh",
      "bboxes": [
        {
          "left": 0.5647222222222222,
          "top": 0.28570833333333334,
          "width": 0.1387745098039216,
          "height": 0.015095959595959607,
          "page": 0
        }
      ]
    },
    {
      "text": "Michael Tasota Carnegie Mellon University tasota@andrew.cmu.edu",
      "bboxes": [
        {
          "left": 0.17155718954248364,
          "top": 0.22657070707070706,
          "width": 0.12045098039215688,
          "height": 0.015095959595959607,
          "page": 0
        },
        {
          "left": 0.13988888888888887,
          "top": 0.24359469696969696,
          "width": 0.18421078431372548,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.1502908496732026,
          "top": 0.25868939393939394,
          "width": 0.16298366013071897,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "IUI 19, March 1720, 2019, Marina del Ray, CA, USA",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551742424242424,
          "width": 0.23881862745098043,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "Carnegie Mellon University pdille@andrew.cmu.edu",
      "bboxes": [
        {
          "left": 0.6771388888888888,
          "top": 0.1849179292929293,
          "width": 0.1842107843137254,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.688859477124183,
          "top": 0.20001262626262625,
          "width": 0.16034640522875832,
          "height": 0.012578282828282855,
          "page": 0
        }
      ]
    },
    {
      "text": "Carnegie Mellon University jcross1@andrew.cmu.edu Beatrice Dias Carnegie Mellon University mdias@andrew.cmu.edu",
      "bboxes": [
        {
          "left": 0.40891993464052284,
          "top": 0.1849179292929293,
          "width": 0.18421078431372545,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.4162859477124183,
          "top": 0.20001262626262625,
          "width": 0.16905555555555557,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.4473055555555555,
          "top": 0.22657070707070706,
          "width": 0.10538888888888898,
          "height": 0.015095959595959607,
          "page": 0
        },
        {
          "left": 0.4081062091503268,
          "top": 0.24359469696969696,
          "width": 0.1842107843137254,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.4187205882352941,
          "top": 0.25868939393939394,
          "width": 0.16256045751633985,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.720719696969697,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Carnegie Mellon University",
      "bboxes": [
        {
          "left": 0.5422156862745098,
          "top": 0.3027310606060606,
          "width": 0.1842107843137254,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "Because of these challenges, resident-reported smell data did not gain much attention as a critical tool for monitoring air pollution.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6181325757575757,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6319684343434343,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6458055555555555,
          "width": 0.027174836601307192,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "We propose a system, Smell Pittsburgh [2], for citizens to report pollution odors to the local health department with accurate time and GPS location data via smartphones.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7565025252525253,
          "width": 0.3762761437908496,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7703383838383838,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.784175505050505,
          "width": 0.23179411764705887,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Furthermore, the reporting process is not transparent and does not encourage citizens to contribute data.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5074356060606061,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5212727272727273,
          "width": 0.2574852941176471,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "This research is rooted in citizen science, which empowers amateurs and professionals to form partnerships and produce scientific knowledge [16, 17, 46, 85, 114].",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6768888888888889,
          "width": 0.39547875816993483,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907260101010101,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7045631313131313,
          "width": 0.1924509803921569,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Modern technology allows communities to collect data that can contextualize and express their concerns.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.2450063131313131,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2588434343434343,
          "width": 0.2482434640522876,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Citizen science data are typically high-dimensional, noisy, potentially correlated, and spatially or temporally sparse.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.29574242424242425,
          "width": 0.39503758169934633,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.30957954545454547,
          "width": 0.3087401960784314,
          "height": 0.011320707070707037,
          "page": 2
        }
      ]
    },
    {
      "text": "Human-reported data includes observations contributed by users.",
      "bboxes": [
        {
          "left": 0.2658039215686274,
          "top": 0.4401919191919192,
          "width": 0.21713562091503275,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08753921568627451,
          "top": 0.4540290404040404,
          "width": 0.1722222222222222,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Sensing data involves environmental measurements quantified with sensing devices or systems, which enable citizens to monitor their surroundings with minimal to no assistance from experts.",
      "bboxes": [
        {
          "left": 0.21101307189542481,
          "top": 0.7875845959595961,
          "width": 0.2719248366013072,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8014217171717172,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152588383838383,
          "width": 0.3950294117647059,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8290959595959596,
          "width": 0.11225,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Prediction techniques aim to forecast the future accurately based on previous observations.",
      "bboxes": [
        {
          "left": 0.6276421568627452,
          "top": 0.43096717171717175,
          "width": 0.28445751633986927,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.44480429292929297,
          "width": 0.25488235294117645,
          "height": 0.011320707070707037,
          "page": 2
        }
      ]
    },
    {
      "text": "Interpretationtechniquesaimtoextractknowledge from the collected data.",
      "bboxes": [
        {
          "left": 0.647235294117647,
          "top": 0.6768888888888889,
          "width": 0.2733316993464051,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907260101010101,
          "width": 0.18394607843137245,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In summary, when developing Smell Pittsburgh, we considered the system as an ongoing infrastructure to sustain communities over time (as mentioned in [34]), rather than a software product which solves a single well-defined problem.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.22026767676767678,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.23410479797979797,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.24794191919191919,
          "width": 0.39256209150326793,
          "height": 0.011320707070707065,
          "page": 3
        },
        {
          "left": 0.5189918300653594,
          "top": 0.26177904040404043,
          "width": 0.25450980392156863,
          "height": 0.011320707070707037,
          "page": 3
        }
      ]
    },
    {
      "text": "Moreover, to sustain participation, we visualized smell report data on a map and also engage residents through push notifications.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8014217171717172,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152588383838383,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Outside the scope of citizen science, a few works have collected human-reported smell data in various manners.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.2848409090909091,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2986780303030303,
          "width": 0.2937843137254902,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Smell Pittsburgh is a system, distributed through iOS and Android devices, to collect smell reports and track urban pollution odors.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3655568181818182,
          "width": 0.39255392156862734,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.37939267676767674,
          "width": 0.3948202614379085,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The system visualized smell reports on a map that also depicted fine particulate matter and wind data from government-operated air quality monitoring stations (Figure 1, right).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6768888888888889,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907260101010101,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7045631313131313,
          "width": 0.28779411764705876,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "There is a lack of research in understanding the potential of using smell as an indicator of urban air pollution.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5385189393939394,
          "width": 0.3930016339869281,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5523560606060606,
          "width": 0.2652254901960785,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Users could report odor complaints via Smell Pittsburgh from their mobile devices via the submission console (Figure 1, left).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4693333333333333,
          "width": 0.3928316993464054,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.48317045454545454,
          "width": 0.3314248366013073,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "In this study, we show the usage patterns on mobile devices by parsing server logs and Google Analytics events.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.621540404040404,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6353775252525252,
          "width": 0.2559444444444445,
          "height": 0.011320707070706981,
          "page": 4
        }
      ]
    },
    {
      "text": "To investigate the distribution of smell reports and interaction events among our users, we divided all users into four types: enthusiasts, explorers, contributors, and observers (Table 1).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8152588383838383,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8290959595959596,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8429330808080807,
          "width": 0.3140653594771242,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The user group study showed highly skewed user contributions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7875845959595961,
          "width": 0.3785359477124183,
          "height": 0.011320707070706981,
          "page": 4
        }
      ]
    },
    {
      "text": "Smell Pittsburgh sent post hoc and predictive event notifications to encourage participation.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.12686742424242425,
          "width": 0.39256699346405227,
          "height": 0.011320707070707065,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.14070454545454547,
          "width": 0.16333006535947714,
          "height": 0.011320707070707065,
          "page": 4
        }
      ]
    },
    {
      "text": "The evaluation shows that using smell experiences is practical for revealing urban air quality concerns and empowering communities to advocate for a sustainable environment.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.4503080808080808,
          "width": 0.3932761437908497,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.46414520202020204,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.47798232323232326,
          "width": 0.25399346405228757,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We framed the smell event prediction as a supervised learning task to approximate the function F that maps a predictor matrix X to a response vector y .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7045631313131313,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7184002525252525,
          "width": 0.3929166666666666,
          "height": 0.011332070707070652,
          "page": 5
        },
        {
          "left": 0.51909477124183,
          "top": 0.7322373737373737,
          "width": 0.15317156862745107,
          "height": 0.011332070707070763,
          "page": 5
        }
      ]
    },
    {
      "text": "To identify critical topics in citizen-contributed smell reports, we analyzed the frequency of words (unigram) and phrases (bigram) in the text fields.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6543851010101011,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6682222222222222,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6820593434343435,
          "width": 0.08315032679738564,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "To build y that represents smell events, we aggregated highrating smell reports over the future 8 hours at the beginning of each hour.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.856770202020202,
          "width": 0.3787516339869281,
          "height": 0.011332070707070763,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8706073232323231,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8844431818181818,
          "width": 0.061838235294117694,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "In this study, we show that human-reported smell data, despite noisy, can still enable prediction and contribute scientific knowledge of interpretable air pollution patterns.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8429330808080807,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.856770202020202,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8706073232323231,
          "width": 0.2647924836601307,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Figure 2: Text analysis of high frequency words (unigram) and phrases (bigram) in the text fields of all smell reports.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.4281073232323232,
          "width": 0.3934820261437908,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4419444444444444,
          "width": 0.3950637254901961,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "To evaluate model performance, we defined and computed true positives (TP), false positives (FP), and false negatives (FN) to obtain precision, recall, and F-score [104] (Figure 5).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7460732323232323,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7599103535353536,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7737474747474747,
          "width": 0.2939754901960785,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "When performing classification and regression, we added 3-hour lagged predictor variables, days of the week, hours of the day, and days of the month into the original predictor variable, which expanded its length from 64 to 195.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5385189393939394,
          "width": 0.3765669934640523,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5523560606060606,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5661931818181818,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.580030303030303,
          "width": 0.19589542483660133,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We chose model parameters by using time-series cross-validation [5, 77], where the entire dataset was partitioned and rolled into several pairs of training and testing subsets for evaluation.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4001489898989899,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4139861111111111,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4278232323232323,
          "width": 0.3417908496732026,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "During data interpretation, we only considered the classification approach due to better performance.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7737474747474747,
          "width": 0.3787549019607842,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7875845959595961,
          "width": 0.25322549019607843,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "While these models enabled us to predict future smell events, they were typically considered as black box models and not suitable for interpreting patterns.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5938661616161616,
          "width": 0.37788888888888894,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6077032828282828,
          "width": 0.39502941176470574,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.621540404040404,
          "width": 0.18466339869281045,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Then, we used DBSCAN [48] to cluster positive samples and to choose a representative subset.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6554835858585859,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.669320707070707,
          "width": 0.1852418300653595,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In this study, we show that the system can motivate active community members to contribute data and increase their self-efficacy, beliefs about how well an individual can achieve desired effects through actions [7].",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6907260101010101,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7045631313131313,
          "width": 0.39417483660130737,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7184002525252525,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7322373737373737,
          "width": 0.12024509803921568,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Finally, we used recursive feature elimination [56] to remove 50 features that had the smallest weights iteratively, which resulted in 30 most important features.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7800164141414142,
          "width": 0.3762761437908496,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7938535353535353,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8076906565656566,
          "width": 0.1827156862745098,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For Self-Efficacy Changes, we measured changes to user confidence mitigating air quality problems.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.44166035353535354,
          "width": 0.3787565359477124,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4554962121212121,
          "width": 0.22749836601307188,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "For Self-Efficacy, we averaged the scale items to produce total self-efficacy pre score (Mdn=3.50) and post score (Mdn=4.13) for each participant (Figure 7, left).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.38262878787878785,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.39646590909090906,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4103030303030303,
          "width": 0.19655882352941179,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "In the System Usage Information section, we collected individual experiences with Smell Pittsburgh.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7184002525252525,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7322373737373737,
          "width": 0.20975490196078433,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "At the end of the survey, we asked an open-response question Do you have any other comments, questions, or concerns?",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.856770202020202,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08625,
          "top": 0.8706073232323231,
          "width": 0.3668725490196078,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Factors, we averaged the internal (Mdn=4.29) and external (Mdn=3.14) motivation scores for each participant (Figure 7, center).",
      "bboxes": [
        {
          "left": 0.6260392156862745,
          "top": 0.47948863636363637,
          "width": 0.2860539215686275,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4933257575757576,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5071628787878788,
          "width": 0.08206535947712412,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "For System Usage Information, we reported the counts for system usage frequency questions (Table 5).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3945757575757576,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4084128787878788,
          "width": 0.22242647058823528,
          "height": 0.011320707070706981,
          "page": 9
        }
      ]
    },
    {
      "text": "Also, four participants (16%) indicated the benefit to validate personal experiences based on the data provided by others.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.33599242424242426,
          "width": 0.3955473856209151,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3498295454545455,
          "width": 0.3332957516339869,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "We also found that altruism, the concern about the welfare of others, was another motivation.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.49260353535353535,
          "width": 0.3948725490196078,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08736437908496732,
          "top": 0.5064406565656565,
          "width": 0.14138235294117646,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "In the open-ended question to freely provide comments and concerns, two participants (8%) were frustrated about the lack of responses from regulators and unclear values of using the data to take action.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6671843434343434,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6810202020202021,
          "width": 0.39502941176470585,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6948573232323232,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7086944444444444,
          "width": 0.06915196078431374,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "We have also shown that the transparency of smell data empowered communities to advocate for better air quality.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7599103535353536,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7737474747474747,
          "width": 0.3121732026143791,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Furthermore, from a machine-learning standpoint, communitypowered projects such as Smell Pittsburgh often face two challenges that compromise model performances: data sparsity and label unreliability.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6492146464646464,
          "width": 0.3787581699346404,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6630517676767677,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6768888888888889,
          "width": 0.39504084967320263,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907260101010101,
          "width": 0.06101633986928112,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We have shown that the smell data gathered through the system is practical in identifying local air pollution patterns.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.3863118686868687,
          "width": 0.39326470588235296,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4001489898989899,
          "width": 0.2963921568627451,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "The Heinz Endowments, the CREATE Lab (Jessica Pachuta, Ana Tsuhlares), Allegheny County Clean Air Now (ACCAN), PennEnvironment, Group Against Smog and Pollution (GASP), Sierra Club, Reducing Outdoor Contamination in Indoor Spaces (ROCIS), Blue Lens, PennFuture, Clean Water Action, Clean Air Council, the Global Communication Center of Carnegie Mellon University (Ryan Roderick), the Allegheny County Health Department, and all other participants.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5859002525252526,
          "width": 0.39299673202614377,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.0874656862745098,
          "top": 0.5997373737373738,
          "width": 0.39547549019607847,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.613574494949495,
          "width": 0.3941764705882353,
          "height": 0.011320707070706981,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6274116161616162,
          "width": 0.39255882352941174,
          "height": 0.011320707070706981,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6412474747474748,
          "width": 0.39256372549019614,
          "height": 0.011320707070706981,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.655084595959596,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6689217171717171,
          "width": 0.3928447712418301,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6827588383838384,
          "width": 0.07439705882352941,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "This paper explores the design and impact of a mobile smell reporting system, Smell Pittsburgh, to empower communities in advocating for better air quality.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.29238762626262627,
          "width": 0.39547549019607847,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3062247474747475,
          "width": 0.3950408496732026,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3200618686868687,
          "width": 0.1432924836601307,
          "height": 0.011320707070707037,
          "page": 11
        }
      ]
    },
    {
      "text": "The followings provide the corrections for the last two paragraphs in section 5.2 (Smell Dataset Study).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.3830416666666667,
          "width": 0.39299346405228763,
          "height": 0.011320707070706981,
          "page": 14
        },
        {
          "left": 0.08790522875816993,
          "top": 0.39687878787878783,
          "width": 0.21016993464052292,
          "height": 0.011320707070707092,
          "page": 14
        }
      ]
    },
    {
      "text": "We found errors in the system usage study and the analysis of the air pollution patterns when discussing this research with a colleague.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.2258030303030303,
          "width": 0.3935375816993465,
          "height": 0.011320707070707037,
          "page": 14
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2396401515151515,
          "width": 0.39481209150326796,
          "height": 0.011320707070707092,
          "page": 14
        }
      ]
    },
    {
      "text": "In the caption of Table 2, and also in the second paragraph of section 5.1 (System Usage Study), the interquartile range texts should be semi-interquartile range.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.31134090909090906,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 14
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3251767676767677,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 14
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3390138888888889,
          "width": 0.2204673202614379,
          "height": 0.011320707070707037,
          "page": 14
        }
      ]
    }
  ],
  "2010.07358": [
    {
      "text": "Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.7404305555555556,
          "width": 0.7002941176470588,
          "height": 0.04654292929292925,
          "page": 0
        }
      ]
    },
    {
      "text": "Making progress towards this objective of pervasive AR assistance is challenging for myriad reasons.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5730694444444444,
          "width": 0.5937140522875817,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To address the first challenge in the context of object-rearrangement tasks, we formalize the problem of computing and displaying AR assistance by (1) associating an optimal action sequence with the policy of an embodied agent and (2) presenting this optimal action sequence to the user as suggestion notifications in the AR systems heads-up display.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7633282828282829,
          "width": 0.6837222222222222,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.780625,
          "width": 0.7008790849673203,
          "height": 0.011332070707070763,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7979204545454545,
          "width": 0.6620294117647058,
          "height": 0.011332070707070763,
          "page": 1
        }
      ]
    },
    {
      "text": "Compared with current personal computing devices, always-on AR devices (1) have access to a much larger volume and more diverse set of sensor data and (2) are able to display real-time information to the user in a much lower friction manner [24].",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.3655151515151515,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.382810606060606,
          "width": 0.6999967320261438,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.40010732323232323,
          "width": 0.07863235294117646,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.17951960784313725,
          "top": 0.26229545454545455,
          "width": 0.14084477124183004,
          "height": 0.010063131313131302,
          "page": 1
        }
      ]
    },
    {
      "text": "In summary, our contributions are: (1) a novel framework for computing and displaying AR assistance for objectrearrangement tasks that employs a hybrid single agent (i.e., the userAR-system) and CVRP formulation, (2) a novel AR simulator that can enable large-scale web-based evaluation of AR-like assistance, and (3) a large-scale web-based study that assesses how users respond to the proposed form of AR assistance in a house-cleaning task over a range of task difficulties.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5390075757575757,
          "width": 0.6861993464052287,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5563030303030303,
          "width": 0.6999967320261438,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.11948856209150326,
          "top": 0.5735997474747475,
          "width": 0.7005147058823529,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5908964646464646,
          "width": 0.7003807189542484,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6081919191919192,
          "width": 0.06494444444444443,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To address the second challenge, we propose a novel AR simulator that can enable large-scale web-based evaluation of AR assistance and associated data collection.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.2795631313131313,
          "width": 0.6837156862745097,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2968598484848485,
          "width": 0.28593790849673206,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To address the third challenge, we define house cleaning as a specific object-rearrangement task, implement the task and the proposed CVRP-based assistance using OR-Tools [19] in the proposed AR simulator, and evaluate it at scale using AMT.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.4006376262626263,
          "width": 0.6841013071895424,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4179330808080808,
          "width": 0.7000032679738563,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.435229797979798,
          "width": 0.07025980392156862,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We now review related work that relates to our three key contributions.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.7223472222222223,
          "width": 0.41027941176470584,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To date, most work on employing AR devices to assist users has focused on displaying predefined information overlays that can be useful in completing a prescribed task; the information overlays are often spatially registered to objects or locations",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.7949924242424242,
          "width": 0.7004362745098038,
          "height": 0.011332070707070763,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.8122878787878788,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Our AR-assistance application is fundamentally different from these, in that actions that can modify the physical state of the environment belong to the human agent.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5943560606060606,
          "width": 0.6837205882352941,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6116515151515152,
          "width": 0.27189705882352944,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Critically, none of the above approaches are truly robust for complex multi-step tasks, as they do not leverage the devices on-board sensors to infer the current task state; as such, they are unable to provide the user with up-to-date assistance toward optimal task completion or properly adapt when users deviate from the systems suggested steps.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.1930820707070707,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.2103787878787879,
          "width": 0.6999918300653595,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.22767424242424245,
          "width": 0.7022483660130718,
          "height": 0.011320707070707037,
          "page": 3
        }
      ]
    },
    {
      "text": "The robotics and embodied AI communities have leveraged simulation frameworks to train and evaluate embodiedagent policies in lieu of expensive real-world experimentation infrastructure [16, 25, 26, 37].",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.5424671717171717,
          "width": 0.70290522875817,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5597626262626263,
          "width": 0.5416944444444444,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Instead, our proposed approach for AR assistance applicable to complex object-rearrangement tasks described in Sec. 3 leverages only the sensor measurements of the AR device, and executes a policy whose state is informed only by these sensor measurements, thus enabling up-to-date assistance toward optimal task completion.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.3314520202020202,
          "width": 0.6837173202614378,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.3487487373737374,
          "width": 0.7003807189542482,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.3660441919191919,
          "width": 0.5646748366013072,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The goal of our AR assistance model is to formalize the problem of computing and displaying AR assistance for objectrearrangement tasks.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.7431035353535353,
          "width": 0.7029101307189543,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7603989898989899,
          "width": 0.12791993464052293,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The sense of agency refers to the feeling of being in the drivers seat when it comes to selecting ones actions [31].",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.47328156565656565,
          "width": 0.65675,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Arguably the closest related work is in the field of humanrobot interaction (HRI), where researchers are interested in evaluatingusersresponsetoroboticassistance[10].",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.158489898989899,
          "width": 0.683720588235294,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The study presented in Sec. 5 evaluates task performance and the users sense of agency on the proposed cleaninghouse task.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5943560606060606,
          "width": 0.6861993464052287,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6116515151515152,
          "width": 0.06522549019607841,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "It is generally challenging to characterize the user experience for digital assistance owing to a plethora of factors involved and owing to the difficulty of measuring some of these factors with high fidelity [2].",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.35220833333333335,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.36950378787878785,
          "width": 0.5029232026143792,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Thus, we believe that our proposed evaluation frameworkwhich is based on an AR simulator and is described in Sec. 4combines the attractive attributes of each of these paradigms, as it enables scalable, first-person interaction of a user with an embodied assistant and thus we hypothesize can capture more realistic user experiencesand thus yield higher quality user-experience dataat scale.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.26226767676767676,
          "width": 0.6837173202614378,
          "height": 0.011320707070707037,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2795631313131313,
          "width": 0.6999918300653595,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2968598484848485,
          "width": 0.6999901960784314,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.3141565656565657,
          "width": 0.2674983660130719,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Regarding the choice of embodied agent, one could adopt a fully multiagent perspective and consider the user and AR system to be independent but cooperating agents with the shared aforementioned objective but with different observation and action spaces.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.23113383838383839,
          "width": 0.6837222222222222,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.24843055555555557,
          "width": 0.6999934640522876,
          "height": 0.011320707070707065,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.2657272727272727,
          "width": 0.10955392156862745,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "As mentioned above, the embodied-agents observations correspond to those of the AR system.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4213926767676768,
          "width": 0.5609313725490196,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Wenowformulatethe(single-vehicle)CVRP[12,18]forobject-rearrangementtasks.Weassumethatwearerearranging  objectssuchthateachobjecthasaninitiallocationandfinal(desired)location,thusyielding2  + 1totallocationsofinterest (including the initial position of the user).",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.6644861111111111,
          "width": 0.7001879084967321,
          "height": 0.013834595959596019,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6817828282828282,
          "width": 0.7000000000000001,
          "height": 0.013834595959596019,
          "page": 5
        },
        {
          "left": 0.17956209150326796,
          "top": 0.7015921717171717,
          "width": 0.2470212418300654,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Webeginbydefiningtheobjective(andassociatedreward)ofthetaskasmovingeachobjectinquestionfromitsinitialpositiontoitsfinaldesiredpositioninaslittletimeaspossible.Minimaltimetotaskcompletionisnotonlyanintuitivechoicefor an objective and reward, it also draws inspiration from the long history of AI assistants for task and time management [33].",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.17924494949494948,
          "width": 0.7031813725490196,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.19654166666666667,
          "width": 0.7002810457516339,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.21383838383838386,
          "width": 0.7022532679738562,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "Finally, we assume that the user can carry only two objects at once, the AR device has knowledge of the desired final location of all objects in question (i.e., the goal state of the environment), and the AR device can calculate the shortest path between any two points on the map.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5424671717171717,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5597626262626263,
          "width": 0.7000049019607842,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5770593434343434,
          "width": 0.24546895424836598,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "To satisfy the above criteria, we build our AR simulator upon Habitat [37].",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6628421717171717,
          "width": 0.4535457516339869,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "To evaluate how the proposed AR-assistance model described in Section 3 affects the user experience, an AR simulator must (1) support the observations and actions of the embodied-agent policy, (2) emulate the first-person view through an AR device, including support of the display of suggestion-notifications in the form of digital objects and information in a heads-up display (HUD), (3) enable a user in the loop to autonomously perform the task-execution actions, and (4) be deployable on the web at scale and support data collection related to task performance and sense of agency.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.5763611111111111,
          "width": 0.7007156862745099,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5936565656565657,
          "width": 0.6999950980392158,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6109532828282829,
          "width": 0.6999983660130719,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.62825,
          "width": 0.7008692810457516,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6455454545454545,
          "width": 0.6475882352941176,
          "height": 0.011320707070707203,
          "page": 6
        }
      ]
    },
    {
      "text": "The objective function in problem (1) corresponds to the transportation costs (i.e., total distance traveled); the first set of constraints corresponds to the capacity constraints; the second set of constraints ensures that each objects pickup location is visited before its dropoff location; the third set of constraints enforces that the solution is computed from the current state of the task at step  .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.393020202020202,
          "width": 0.6837124183006535,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4103169191919192,
          "width": 0.7000032679738563,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4276123737373737,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.44239520202020205,
          "width": 0.20304575163398697,
          "height": 0.013834595959595963,
          "page": 6
        }
      ]
    },
    {
      "text": "Finally, we note that Habitat supports reinforcement-learning training algorithms (e.g., PPO) [45] that we can employ to train embodied-agent policies in future studies that assume reduced observation fidelity (e.g., assume only RGBD video); this obviates the need to employ different platforms for policy training and evaluation in future work.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.3473396464646465,
          "width": 0.7000032679738561,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.364635101010101,
          "width": 0.7010326797385621,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.3819318181818182,
          "width": 0.5978186274509804,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "We make several modifications to Habitat to generate our AR simulator.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.39922853535353536,
          "width": 0.4223186274509805,
          "height": 0.011320707070707037,
          "page": 7
        }
      ]
    },
    {
      "text": "The main house-cleaning task is explained to participants through the following prompt:",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.758989898989899,
          "width": 0.5235816993464052,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "ByleveragingHabitatsexistingWebGLJavaScriptAPI,wecandeployourARsimulatoratscaleonAMTandcollectdata related to task performance and sense of agency by leveraging psiTurk [20].",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5894873737373738,
          "width": 0.6837124183006537,
          "height": 0.011320707070706981,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6067828282828283,
          "width": 0.4357401960784313,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "The overarching goal of our study is to evaluate how users respond to the AR assistance generated by the proposed framework on a specific quotidian object-rearrangement taskhouse cleaningusing our proposed AR simulator.",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.6517537878787878,
          "width": 0.7004395424836602,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6690492424242424,
          "width": 0.6758807189542483,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In this HIT, you are a guest at a short-term rental.",
      "bboxes": [
        {
          "left": 0.21988562091503266,
          "top": 0.7806136363636363,
          "width": 0.2933153594771242,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Optimal assistance .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7288661616161616,
          "width": 0.11105555555555555,
          "height": 0.011332070707070763,
          "page": 8
        }
      ]
    },
    {
      "text": "Noassistance(None) .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.486729797979798,
          "width": 0.11385784313725492,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Each assistance level is characterized by both a world-locked digital-object component and a text-information component; see Fig. 2.",
      "bboxes": [
        {
          "left": 0.3209705882352941,
          "top": 0.43482954545454544,
          "width": 0.49902450980392155,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.45212626262626265,
          "width": 0.2601944444444445,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Object-highlighting assistance .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.573199494949495,
          "width": 0.17924346405228755,
          "height": 0.011332070707070763,
          "page": 8
        }
      ]
    },
    {
      "text": "We vary two key variables across experiments: assistance fidelity , which represents how much assistance the AR simulator provides to the user toward efficient task completion; and task difficulty as measured by the number of objects that must be cleaned up.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.3389002525252525,
          "width": 0.7009787581699346,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.3561969696969697,
          "width": 0.6999918300653595,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.3734936868686869,
          "width": 0.08115196078431373,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The participant is then placed in a virtual environment within the AR simulator described in Sec. 4 and must complete the task using the keyboard navigation and pick/place actions; they can leverage any AR assistance we provide in the HUD.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.17977525252525253,
          "width": 0.683720588235294,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.1970707070707071,
          "width": 0.7000049019607842,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.21436742424242425,
          "width": 0.03352941176470588,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "To control for certain objects being easier to reorganize (due to visual salience or bin location), the number of each object type remained fixed for each difficulty setting.",
      "bboxes": [
        {
          "left": 0.42928921568627454,
          "top": 0.45818560606060604,
          "width": 0.45071078431372535,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4754823232323232,
          "width": 0.5343235294117645,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "To determine the effect of assistance fidelity and task difficulty on participants task performance and experience, we collect an array of objective and subjective participant-response data.",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.5827184343434343,
          "width": 0.7004395424836601,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6000151515151515,
          "width": 0.40855718954248355,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The HIT for the study consists of four phases: (1) task setup, (2) house familiarization and navigation-controls training, (3) cleaning-task execution, and (4) survey.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.3428674242424242,
          "width": 0.7029052287581701,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.36016414141414144,
          "width": 0.2794591503267974,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We now conduct a study that varies the assistance fidelity and fixes task difficulty to the easiest level (i.e., 6 total objects).",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.6853333333333333,
          "width": 0.7029591503267973,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We conducted a 3  4 between-subjects user study (  = 447 participants, male = 265, female = 177, other = 1, no answer = 4; three assistance-fidelity levels; four task-difficulty levels) on AMT using our AR simulator setup described in Sec.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.5582866161616161,
          "width": 0.7017418300653595,
          "height": 0.013834595959596019,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5780972222222223,
          "width": 0.6883807189542485,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "With regards to varying the assistance fidelity, we had the following hypotheses:",
      "bboxes": [
        {
          "left": 0.23665032679738565,
          "top": 0.7168131313131313,
          "width": 0.4755114379084968,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Objective metrics .",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.45103156565656566,
          "width": 0.11771241830065357,
          "height": 0.011343434343434378,
          "page": 11
        }
      ]
    },
    {
      "text": "Even though participants tend to follow optimal assistance, this does not necessarily translate to improvements in all performance metrics.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5894242424242424,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6067209595959596,
          "width": 0.12392320261437909,
          "height": 0.011320707070706981,
          "page": 11
        }
      ]
    },
    {
      "text": "For an in-depth reporting of the statistical analyses, see Sec.",
      "bboxes": [
        {
          "left": 0.2931797385620915,
          "top": 0.4337575757575758,
          "width": 0.3520637254901961,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Subjective metrics .",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.796955808080808,
          "width": 0.12300163398692812,
          "height": 0.011343434343434433,
          "page": 11
        }
      ]
    },
    {
      "text": "Usability and Utility .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5561313131313131,
          "width": 0.12454901960784312,
          "height": 0.011332070707070652,
          "page": 12
        }
      ]
    },
    {
      "text": "H5 As the task difficulty increases, participants will be more willing to accept the assistance.",
      "bboxes": [
        {
          "left": 0.13387254901960785,
          "top": 0.737294191919192,
          "width": 0.5475424836601307,
          "height": 0.011343434343434322,
          "page": 12
        }
      ]
    },
    {
      "text": "For an in-depth reporting of the statistical analyses, see Sec.",
      "bboxes": [
        {
          "left": 0.26713888888888887,
          "top": 0.7636590909090909,
          "width": 0.3520637254901961,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "We had the following hypothesis:",
      "bboxes": [
        {
          "left": 0.2343202614379085,
          "top": 0.7165151515151515,
          "width": 0.19764215686274508,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Across the board, we observed that participants deviated more from the optimal ordering as task-difficulty increased (Fig. 8).",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7809558080808081,
          "width": 0.6837254901960784,
          "height": 0.011320707070706981,
          "page": 12
        },
        {
          "left": 0.11956209150326796,
          "top": 0.7982525252525252,
          "width": 0.04483169934640521,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "This work has presented (1) a novel framework for computing and displaying AR assistance for object-rearrangement tasks that characterize a broad category of quotidian tasks, (2) a novel AR simulator that can enable web-based evaluation of AR-like assistance and large-scale data collection, and (3) a study that assesses how users respond to the proposed AR assistance in the AR simulator on a specific object-rearrangement task: house cleaning.",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.6034090909090909,
          "width": 0.7004330065359478,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6207058080808081,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6380025252525252,
          "width": 0.6999918300653595,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.17948856209150327,
          "top": 0.6552979797979798,
          "width": 0.5343366013071895,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "The study illustrated several salient trends.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.672594696969697,
          "width": 0.25044117647058817,
          "height": 0.011320707070706981,
          "page": 13
        }
      ]
    },
    {
      "text": "Wealsoobservedthatparticipantsweremorelikelytotakeshorterpathsintheoptimal-assistanceconditionthanintheother two conditions, and that participants provided with object-highlighting assistance were more likely to take shorter paths than those provided with no assistance (Fig. 8) .",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4892651515151515,
          "width": 0.6837124183006537,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5065618686868687,
          "width": 0.7000049019607841,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5238472222222222,
          "width": 0.23058333333333328,
          "height": 0.011332070707070763,
          "page": 13
        }
      ]
    },
    {
      "text": "Futureworkwillexploreextensionsofthecurrentframeworkandstudy,includingdevelopingandassessingperceptionbased learned policies that assume lower fidelity of the embodied agents observations, considering multi-agent formulations that incorporate models of the users behavior, and extending the current assistance framework and AR simulator to other quotidian object-rearrangement tasks and assessing the user experience in those settings.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.12389772727272727,
          "width": 0.6861960784313725,
          "height": 0.011320707070707092,
          "page": 14
        },
        {
          "left": 0.1200016339869281,
          "top": 0.14119318181818183,
          "width": 0.702468954248366,
          "height": 0.011320707070707065,
          "page": 14
        },
        {
          "left": 0.1200016339869281,
          "top": 0.158489898989899,
          "width": 0.7002712418300654,
          "height": 0.011320707070707092,
          "page": 14
        },
        {
          "left": 0.1200016339869281,
          "top": 0.17578661616161617,
          "width": 0.5765751633986929,
          "height": 0.011320707070707037,
          "page": 14
        }
      ]
    },
    {
      "text": "The authors would like to thank Gideon Stocek and Blaise Ritchie for setting up the back-end servers, front-end development and design of the study logic and flow, integration with ORTools for online optimal path calculations, and integration with psiTurk for deployment on AMT.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.22075631313131314,
          "width": 0.7029052287581699,
          "height": 0.011320707070707092,
          "page": 14
        },
        {
          "left": 0.11963562091503267,
          "top": 0.23805303030303032,
          "width": 0.7003660130718955,
          "height": 0.011320707070707037,
          "page": 14
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2553484848484848,
          "width": 0.2883790849673203,
          "height": 0.011320707070707092,
          "page": 14
        }
      ]
    },
    {
      "text": "Acknowledgments",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.19828282828282828,
          "width": 0.12390359477124184,
          "height": 0.011320707070707092,
          "page": 14
        }
      ]
    },
    {
      "text": "The setup works as follows: we serve a Human Intelligence Task (HIT) to AMT using a psiTurk server, which also allows us to advertise our HIT on through the AMT web portal.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.346969696969697,
          "width": 0.7004395424836602,
          "height": 0.011320707070707092,
          "page": 16
        },
        {
          "left": 0.1200016339869281,
          "top": 0.3642664141414142,
          "width": 0.38984477124183015,
          "height": 0.011320707070707037,
          "page": 16
        }
      ]
    },
    {
      "text": "We now describe how we generated the disorganized house for the study described in Section 5.1.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.5649027777777778,
          "width": 0.5741715686274509,
          "height": 0.011320707070707092,
          "page": 16
        }
      ]
    },
    {
      "text": "Table 1 shows the number of participant in each of our twelve conditions.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.14638257575757577,
          "width": 0.42202287581699344,
          "height": 0.011320707070707065,
          "page": 16
        }
      ]
    },
    {
      "text": "Bins were placed manually within the environment in semantically reasonable locations.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.6029545454545455,
          "width": 0.5230261437908497,
          "height": 0.011320707070706981,
          "page": 16
        }
      ]
    },
    {
      "text": "The starting position of each participant was held constant for any individual scene.",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.17924494949494948,
          "width": 0.4882450980392157,
          "height": 0.011320707070707092,
          "page": 17
        }
      ]
    },
    {
      "text": "The full list of Likert-scale questions used in our study is below (a subset was described in Sec. 5.3 and used for analysis in Sec. 6.1):",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.29340025252525254,
          "width": 0.7004395424836602,
          "height": 0.011320707070707092,
          "page": 17
        },
        {
          "left": 0.18000163398692812,
          "top": 0.3106969696969697,
          "width": 0.06569444444444444,
          "height": 0.011320707070707092,
          "page": 17
        }
      ]
    },
    {
      "text": "Objectivemetrics .",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.14290025252525254,
          "width": 0.11336928104575165,
          "height": 0.011320707070707065,
          "page": 18
        }
      ]
    },
    {
      "text": "We conducted two individual two-way factorial ANOVA tests to measure the main effects of assistance type and task difficulty on normalized deviations and IPL, and any combined effects of assistance type and difficulty (see Fig. 8).",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.33664141414141413,
          "width": 0.7010833333333333,
          "height": 0.011320707070707092,
          "page": 18
        },
        {
          "left": 0.1200016339869281,
          "top": 0.35393813131313134,
          "width": 0.702248366013072,
          "height": 0.011320707070707092,
          "page": 18
        }
      ]
    },
    {
      "text": "Subjective metrics .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.2293813131313131,
          "width": 0.12425980392156857,
          "height": 0.011343434343434378,
          "page": 18
        }
      ]
    }
  ],
  "2103.06807": [
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7816818181818181,
          "width": 0.3927761437908497,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7917449494949496,
          "width": 0.3925588235294118,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8018080808080809,
          "width": 0.39256045751633994,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8118724747474748,
          "width": 0.0767401960784314,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551830808080807,
          "width": 0.19444607843137257,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.5190522875816994,
          "top": 0.8224810606060605,
          "width": 0.1421470588235293,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM ISBN 978-1-4503-8096-6/21/05..",
      "bboxes": [
        {
          "left": 0.08750653594771242,
          "top": 0.874263888888889,
          "width": 0.2073676470588235,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "We believe that adaptive systems could provide greater benefits by planning sequences of adaptations that gracefully lead a user through gradual changes.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4978409090909091,
          "width": 0.3762859477124183,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5116780303030304,
          "width": 0.3928382352941176,
          "height": 0.013958333333333184,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5255151515151516,
          "width": 0.15421732026143792,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "Adaptive user interfaces can autonomously change the content, layout, or style of an interface to improve their fit with the users capabilities and interests.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.12424116161616161,
          "width": 0.3946862745098039,
          "height": 0.011320707070707065,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.13807828282828283,
          "width": 0.39255392156862745,
          "height": 0.011320707070707065,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.15191540404040405,
          "width": 0.15148366013071896,
          "height": 0.011320707070707065,
          "page": 1
        }
      ]
    },
    {
      "text": "Our work contributes to methods for adaptive interfaces designed to operate autonomously, that is without explicit feedback or training samples from user.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5880934343434343,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6019305555555555,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6157664141414142,
          "width": 0.1163235294117646,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Our general approach can be applied for various HCI applications, such as adaptive mobile homescreens, graphical layouts, and application menus.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.20380429292929295,
          "width": 0.3787549019607842,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.21764141414141416,
          "width": 0.3925669934640523,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.23147853535353535,
          "width": 0.11119771241830068,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Estimation of utility is required for selecting an adaptation.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.317959595959596,
          "width": 0.3365604575163398,
          "height": 0.01395833333333335,
          "page": 1
        }
      ]
    },
    {
      "text": "Early work on this topic studied rule systems, heuristics, and logic as the basis of deciding what to adapt (see, e.g., [44]).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7157739898989899,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7296111111111111,
          "width": 0.3284950980392157,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Model-based reinforcement learning is here developed as a principled and effective approach to these issues.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6223737373737374,
          "width": 0.3787598039215686,
          "height": 0.013958333333333406,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6362108585858586,
          "width": 0.2462679738562092,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To sum up, this paper makes three key contributions:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4113598484848485,
          "width": 0.3185555555555556,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "We formulate the problem of adaptation as a stochastic sequential decision-making problem [7].",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.4580643939393939,
          "width": 0.3932598039215688,
          "height": 0.01395833333333335,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4719015151515151,
          "width": 0.16618790849673193,
          "height": 0.01395833333333335,
          "page": 2
        }
      ]
    },
    {
      "text": "In the following, we formulate this problem as a Markov decision process (MDP).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6656199494949495,
          "width": 0.3762794117647059,
          "height": 0.013958333333333295,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6794570707070707,
          "width": 0.08538235294117646,
          "height": 0.013958333333333295,
          "page": 2
        }
      ]
    },
    {
      "text": "The prevailing understanding is that learning is a key capability for adaptive systems [32].",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.12424116161616161,
          "width": 0.3933807189542484,
          "height": 0.013958333333333323,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.13807828282828283,
          "width": 0.15169934640522875,
          "height": 0.011320707070707065,
          "page": 2
        }
      ]
    },
    {
      "text": "Bayesian optimisation generalises bandit systems to the case of multiple interrelated decision variables [47].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5514595959595959,
          "width": 0.3762875816993464,
          "height": 0.013958333333333295,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5652967171717171,
          "width": 0.26042156862745097,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Model-based RL uses a predictive model to simulate possibilities without first trying them out, which is useful for adaptive interfaces, because it significantly improves the efficiency of finding good solutions [28].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1346199494949495,
          "width": 0.3762859477124183,
          "height": 0.01395833333333335,
          "page": 2
        },
        {
          "left": 0.5189918300653594,
          "top": 0.1484570707070707,
          "width": 0.3947140522875817,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1622929292929293,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1761300505050505,
          "width": 0.08486111111111105,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In this paper, we approach the fundamental problem of selecting user interface adaptations by applying model-based RL, and exploiting predictive HCI models, to simulate and plan adaptations.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3836856060606061,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3975227272727273,
          "width": 0.3925637254901959,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4113598484848485,
          "width": 0.3948153594771242,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "Unlike bandits, reinforcement learning permits learning policies for sequences of actions where rewards are not immediately achievable.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8126325757575757,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.826469696969697,
          "width": 0.39481372549019605,
          "height": 0.013958333333333406,
          "page": 2
        }
      ]
    },
    {
      "text": "The problem of adaptive interfaces is that of maximising expected cumulative discounted rewards  (   ,  ) from acting according to an optimal policy   (see e.g. [26]):",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7486414141414142,
          "width": 0.3787549019607842,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7624785353535354,
          "width": 0.39503594771241823,
          "height": 0.013097222222222205,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7757171717171718,
          "width": 0.24816013071895426,
          "height": 0.012021464646464475,
          "page": 2
        }
      ]
    },
    {
      "text": "Bandit systems are one of the most successful probabilistic approaches to this problem, not only for recommendation systems but also for interface design and adaptation [38].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.4130896464646464,
          "width": 0.39503431372549025,
          "height": 0.01395833333333335,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.426925505050505,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.44076262626262624,
          "width": 0.2920947712418301,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Consider the case of adapting the homescreen layout of smartphones, consisting of a grid of application icons.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.23868939393939395,
          "width": 0.3787614379084967,
          "height": 0.011320707070707065,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.25252651515151514,
          "width": 0.28938725490196077,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Given an initial homescreen design, with which the user has interacted, an adaptation  would result in a new design by, for example, changing the layout or ordering of icons.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.34938510101010106,
          "width": 0.3762745098039215,
          "height": 0.011320707070707037,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3632222222222223,
          "width": 0.3928447712418301,
          "height": 0.011422979797979738,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3770593434343434,
          "width": 0.2907205882352941,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Monte Carlo Tree Search (MCTS) has been successfully employed in various game-playing applications to plan a sequence of moves efficiently (see [9]).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1484570707070707,
          "width": 0.3762859477124183,
          "height": 0.01395833333333335,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1622929292929293,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1761300505050505,
          "width": 0.10012908496732031,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Finding a policy to select adaptations can be challenging for adaptive interfaces.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5292664141414141,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5431035353535353,
          "width": 0.0853872549019608,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The core of this approach considers planning: the selection of a sequence of adaptation with the goal of maximising utility to user.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7849583333333333,
          "width": 0.3929967320261438,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7987954545454545,
          "width": 0.3948202614379085,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "In contrast to game-playing applications, where a win/loss defines the terminal state, our case does not have a well-defined horizon.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.33531818181818185,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.349155303030303,
          "width": 0.3948202614379086,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "This is computationally expensive given the large number of possible adaptations (breadth) and long horizons (depth) in adaptive interfaces.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.10694570707070707,
          "width": 0.39547058823529435,
          "height": 0.011320707070707078,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.12078282828282828,
          "width": 0.39255718954248375,
          "height": 0.011320707070707078,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1346199494949495,
          "width": 0.06153431372549023,
          "height": 0.011320707070707065,
          "page": 3
        }
      ]
    },
    {
      "text": "At this point,   + 1 ,  + 1 = 0.",
      "bboxes": [
        {
          "left": 0.8334477124183006,
          "top": 0.6594709595959597,
          "width": 0.08025816993464052,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5189493464052287,
          "top": 0.6733080808080808,
          "width": 0.08520261437908494,
          "height": 0.014391414141414205,
          "page": 3
        }
      ]
    },
    {
      "text": "As illustrated in Figure 3, we propose an  -headed  -tailed architecture that is trained end-to-end with backpropagation.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5880277777777778,
          "width": 0.3787532679738562,
          "height": 0.011422979797979682,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.601864898989899,
          "width": 0.3458839869281045,
          "height": 0.011320707070706981,
          "page": 4
        }
      ]
    },
    {
      "text": "We support several ways for selecting adaptation that allows controlling for the trade-off between risk and gain.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.508,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5218371212121212,
          "width": 0.3057434640522876,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "To address large problem sizes in online settings, where repeating a sufficient number of MCTS simulations to attain robust estimates is infeasible, we develop a deep neural network architecture that can efficiently provide predictions in real-time.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7987954545454545,
          "width": 0.3930016339869281,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8126325757575757,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.826469696969697,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8403068181818182,
          "width": 0.292468954248366,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "With certain conditions we outline here, the approach we outline is broadly useful across applications of adaptive interfaces.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.8541439393939394,
          "width": 0.3932614379084969,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8679810606060606,
          "width": 0.3493562091503267,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Selecting the next adaptation : Given these value estimates, the system can now choose the best adaptation (by setting  = 0 in Equation 2) to maximise expected utility for the user while avoiding costly changes.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.45265151515151514,
          "width": 0.3779003267973856,
          "height": 0.013912878787878835,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.46648863636363636,
          "width": 0.3925604575163399,
          "height": 0.013301767676767717,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4803257575757576,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4941628787878788,
          "width": 0.0906748366013072,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The above steps (14) are repeated several times to obtain value estimates for each adapted state.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4249785353535354,
          "width": 0.3762859477124183,
          "height": 0.011320707070707037,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4388143939393939,
          "width": 0.19384640522875818,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Feasible Adaptations (  ): The set of possible adaptations  , through which a menu can be reorganised, includes (1) moving a menu item to a certain position, (2) swapping two items, (3) adding or removing a separator, (4) moving an entire group, (5) swapping two groups, and (6) not making any changes.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7142739898989899,
          "width": 0.377892156862745,
          "height": 0.013912878787878835,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.728111111111111,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7419482323232324,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7557853535353535,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7696224747474748,
          "width": 0.26918300653594773,
          "height": 0.011320707070706981,
          "page": 5
        }
      ]
    },
    {
      "text": "To demonstrate the applicability of our approach, we tackle a challenging and open question in the field of adaptive interfaces: adaptive menus .",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.6189141414141415,
          "width": 0.39547549019607847,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6327512626262627,
          "width": 0.39402450980392156,
          "height": 0.013958333333333184,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6465883838383838,
          "width": 0.06827124183006535,
          "height": 0.013958333333333406,
          "page": 5
        }
      ]
    },
    {
      "text": "We define a design    as a pair < , > where  is a nonhierarchical linear menu [40] containing an ordered list of items.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.41933585858585853,
          "width": 0.3787499999999999,
          "height": 0.0130189393939395,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.43317171717171715,
          "width": 0.3720065359477125,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Transition function (  ): We use MCTS, where the probability of making an adaptation from state  0 to  1 is given by UCT (Equation 2).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7834595959595959,
          "width": 0.3787565359477124,
          "height": 0.013912878787878835,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7972967171717171,
          "width": 0.3930016339869281,
          "height": 0.013015151515151646,
          "page": 5
        },
        {
          "left": 0.51909477124183,
          "top": 0.8111338383838383,
          "width": 0.07444607843137263,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "State (  ): A state    gives information about the menu design and the user.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3916616161616162,
          "width": 0.3762794117647059,
          "height": 0.013912878787878724,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4054987373737373,
          "width": 0.07628758169934635,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Following the general formulation in section 3, we first define the adaptive menu problem.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3639873737373738,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.377824494949495,
          "width": 0.1403921568627451,
          "height": 0.011320707070706981,
          "page": 5
        }
      ]
    },
    {
      "text": "The system observes user clicks on menu items to approximate a users expertise and interest .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5161944444444445,
          "width": 0.3762794117647059,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5300315656565657,
          "width": 0.18028267973856216,
          "height": 0.013958333333333184,
          "page": 5
        }
      ]
    },
    {
      "text": "To support foraging search, it is desirable for an adaptive system to create groups of related items, or eliminate groups where items have no associations.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8541439393939394,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8679810606060606,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8818169191919192,
          "width": 0.12634967320261437,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "When an adapted state is assumed to be displayed (visible) to the user, we simulate an interaction session (new clicks) based on user interest, and update expertise accordingly.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.21764141414141416,
          "width": 0.3762745098039215,
          "height": 0.011320707070707037,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.23147853535353535,
          "width": 0.3925637254901961,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.24531565656565654,
          "width": 0.31726143790849676,
          "height": 0.011320707070707065,
          "page": 6
        }
      ]
    },
    {
      "text": "Reward (  ): We extend predictive HCI models of menu use to obtain reward estimates.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10694570707070707,
          "width": 0.3762875816993464,
          "height": 0.013912878787878794,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12078282828282828,
          "width": 0.14911764705882352,
          "height": 0.011320707070707078,
          "page": 6
        }
      ]
    },
    {
      "text": "To support serial search, it is advantageous for an adaptive system to move frequently-used items towards the top.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.40417424242424244,
          "width": 0.3787581699346404,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.41801010101010105,
          "width": 0.30989705882352947,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "Consider a menu where   is the number of groups,   (   ) is the location of the group that contains the target (   ), and  the expected target location within the group.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5230694444444445,
          "width": 0.3762761437908496,
          "height": 0.013097222222222205,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5369065656565657,
          "width": 0.39255392156862734,
          "height": 0.013097222222222205,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5507436868686869,
          "width": 0.19395098039215686,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "Here, semantic structure (grouping) is exploited to avoid wasting time inspecting groups that most likely do not contain the target item [4].",
      "bboxes": [
        {
          "left": 0.6774183006535948,
          "top": 0.44004797979797977,
          "width": 0.23468137254901966,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.453885101010101,
          "width": 0.3929411764705881,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4677222222222222,
          "width": 0.2053692810457517,
          "height": 0.01395833333333335,
          "page": 6
        }
      ]
    },
    {
      "text": "Several predictive models explain how users search within linear menus [5, 10, 12, 24, 40].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.344530303030303,
          "width": 0.3928382352941176,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.35836742424242424,
          "width": 0.14552124183006537,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Our choice of the three models was made with the hypothesis that they would provide bounds for best-case and worst-case performance.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.49025883838383844,
          "width": 0.39256699346405227,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5040959595959597,
          "width": 0.39502941176470585,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5179330808080808,
          "width": 0.04126470588235294,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "When searching for a menu item   at an expected position  , serial search [5, 13, 40] consists of a top-tobottom inspection of the menu, until the item is reached.",
      "bboxes": [
        {
          "left": 0.223812091503268,
          "top": 0.8541439393939394,
          "width": 0.25665032679738564,
          "height": 0.013097222222222205,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679810606060606,
          "width": 0.39504084967320263,
          "height": 0.011422979797979904,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8818169191919192,
          "width": 0.32819444444444446,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "In a poorly organised menu, where the target item is not located within the expected group(s), a user first attempts foraging search by inspecting all anchors, and all items within related anchors (given by Equation 9).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7711212121212121,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5189918300653594,
          "top": 0.7849583333333333,
          "width": 0.3931045751633987,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7987954545454545,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.51909477124183,
          "top": 0.8126325757575757,
          "width": 0.1276715686274511,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Where  trail is a constant pointing time assuming that the mouse cursor trails the eye-gaze (tracking strategy) during serial search [5, 10].",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.2511843434343434,
          "width": 0.39326307189542486,
          "height": 0.013631313131313105,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.265020202020202,
          "width": 0.39255555555555544,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2788573232323232,
          "width": 0.047408496732026184,
          "height": 0.02515782828282831,
          "page": 6
        }
      ]
    },
    {
      "text": "Notation Description   Target item  at location  model (  ) Search time for an item  with a given model  Constant for cautious inspection cost of an item   Constant surprise penalty when an item is not found as expected  trail Constant pointing time when the cursor trails eye gaze  (   ,  ) Boolean relationship between items   and   , from association matrix   (   ) Activation level for  at",
      "bboxes": [
        {
          "left": 0.09768790849673202,
          "top": 0.6844002525252525,
          "width": 0.15232679738562088,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1467467320261438,
          "top": 0.6956452020202021,
          "width": 0.17638398692810459,
          "height": 0.013878787878787824,
          "page": 6
        },
        {
          "left": 0.10931535947712417,
          "top": 0.7094823232323232,
          "width": 0.32996732026143794,
          "height": 0.01363131313131316,
          "page": 6
        },
        {
          "left": 0.1485277777777778,
          "top": 0.7233194444444445,
          "width": 0.3111732026143791,
          "height": 0.011422979797979793,
          "page": 6
        },
        {
          "left": 0.14244934640522877,
          "top": 0.7371565656565656,
          "width": 0.3245767973856209,
          "height": 0.013097222222222316,
          "page": 6
        },
        {
          "left": 0.17259967320261438,
          "top": 0.750993686868687,
          "width": 0.10774346405228757,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.12793954248366013,
          "top": 0.7648308080808081,
          "width": 0.3390751633986928,
          "height": 0.01363131313131316,
          "page": 6
        },
        {
          "left": 0.17259967320261438,
          "top": 0.7786679292929294,
          "width": 0.026782679738562104,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1056437908496732,
          "top": 0.7925050505050505,
          "width": 0.3613823529411765,
          "height": 0.013878787878787824,
          "page": 6
        },
        {
          "left": 0.17259967320261438,
          "top": 0.8063421717171718,
          "width": 0.12492810457516335,
          "height": 0.011422979797979571,
          "page": 6
        },
        {
          "left": 0.12670424836601307,
          "top": 0.8201780303030303,
          "width": 0.19075653594771247,
          "height": 0.013878787878787935,
          "page": 6
        }
      ]
    },
    {
      "text": "serial (   ) =  serial (   ) +   + (    )   +  pointing",
      "bboxes": [
        {
          "left": 0.5678186274509804,
          "top": 0.38312752525252525,
          "width": 0.2940049019607843,
          "height": 0.01353030303030306,
          "page": 6
        }
      ]
    },
    {
      "text": "The above search models enable us to predict selection times for varying user strategies.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.39218434343434344,
          "width": 0.39328104575163403,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5191683006535948,
          "top": 0.406020202020202,
          "width": 0.13687418300653587,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Each input is treated as an independent model branch (head) that is eventually concatenated and passed to three independent model branches (tails), one for each output reward.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6135757575757576,
          "width": 0.3771568627450981,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6274128787878788,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.64125,
          "width": 0.29527124183006537,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Recall (direct) search [5] relies on users memory, given by activations  , to directly glance at items without inspecting the entire menu.",
      "bboxes": [
        {
          "left": 0.22759640522875815,
          "top": 0.3748876262626263,
          "width": 0.2528692810457517,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3887247474747475,
          "width": 0.39255882352941174,
          "height": 0.011422979797979738,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4025618686868687,
          "width": 0.1720947712418301,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "If recall search fails (    or  ( , ) <  ), the user eventually reverts to serial search under caution (Equation 8).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.826469696969697,
          "width": 0.3766666666666667,
          "height": 0.013301767676767717,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8403068181818182,
          "width": 0.3021323529411765,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "If found at  , the user then performs a pointing task.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4717462121212121,
          "width": 0.3165980392156863,
          "height": 0.011422979797979849,
          "page": 7
        }
      ]
    },
    {
      "text": "If not found at  , after incurring surprise penalty   , the user attempts local search , by randomly inspecting   items in the vicinity of location  .",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5770997474747475,
          "width": 0.3765588235294117,
          "height": 0.013097222222222205,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5909368686868687,
          "width": 0.392562091503268,
          "height": 0.013958333333333406,
          "page": 7
        },
        {
          "left": 0.08753921568627451,
          "top": 0.6047739898989899,
          "width": 0.12449673202614378,
          "height": 0.011422979797979793,
          "page": 7
        }
      ]
    },
    {
      "text": "In non-ordered menus,  local is equal to 2 times the number of items in the Fovea.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6547803030303031,
          "width": 0.392562091503268,
          "height": 0.01363131313131305,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6686174242424242,
          "width": 0.07755718954248368,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "To support recall, it is advantageous for an adaptive system to place frequently-encountered items at locations where they have been seen before.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8541439393939394,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679810606060606,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8818169191919192,
          "width": 0.10349509803921568,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "With the above setup, we first evaluated whether our approach, and implementation, could successfully identify promising adaptations.",
      "bboxes": [
        {
          "left": 0.6803676470588235,
          "top": 0.6664381313131312,
          "width": 0.23172385620915048,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6802752525252526,
          "width": 0.395576797385621,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6941123737373737,
          "width": 0.16489215686274517,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The overall success rate with model-based simulation was 92.7%, indicating that in most cases an improvement was found.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7632967171717171,
          "width": 0.37788725490196073,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7771338383838384,
          "width": 0.33528758169934625,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The concatenated inputs are passed to each network tail, which comprises two stacked fully connected layers.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1346199494949495,
          "width": 0.3762859477124183,
          "height": 0.011320707070707065,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1484570707070707,
          "width": 0.27775653594771244,
          "height": 0.011320707070707065,
          "page": 8
        }
      ]
    },
    {
      "text": "Reward Estimation: We compare two methods of estimating rewards: model-based simulations and value neural network predictions .",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7631704545454546,
          "width": 0.3787549019607843,
          "height": 0.013958333333333295,
          "page": 8
        },
        {
          "left": 0.08736437908496732,
          "top": 0.7770075757575757,
          "width": 0.3953562091503268,
          "height": 0.013958333333333406,
          "page": 8
        }
      ]
    },
    {
      "text": "During each trial, a combination of {menu size  user history  menu design  objective function  reward source} was selected, and given as input to the system.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5894280303030303,
          "width": 0.3762810457516339,
          "height": 0.013018939393939388,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6032651515151515,
          "width": 0.39416503267973857,
          "height": 0.013018939393939388,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6171022727272727,
          "width": 0.18925163398692812,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "We conducted a technical evaluation with realistic and challenging scenarios, where the adaptive system must adapt menus for simulated users.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4738055555555556,
          "width": 0.39573202614379077,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.48764141414141415,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5014785353535354,
          "width": 0.0963888888888889,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Menu Designs and User Interest: We considered 3 menu sizes  5, 10, and 15 items  to address varying cases, from short contextual menus to longer application menus.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5971262626262626,
          "width": 0.3941764705882353,
          "height": 0.013958333333333406,
          "page": 8
        },
        {
          "left": 0.08756862745098039,
          "top": 0.6109633838383838,
          "width": 0.39289705882352943,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.624800505050505,
          "width": 0.22184313725490196,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "We validate our method, applied to adaptive menus, through technical and empirical evaluations.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4149078282828283,
          "width": 0.395733660130719,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42874494949494946,
          "width": 0.18936437908496734,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "To assess the scalability of our solution, we compared computation time for model-based simulations vs. value network predictions.",
      "bboxes": [
        {
          "left": 0.6736715686274509,
          "top": 0.8403068181818182,
          "width": 0.24003104575163414,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.8541439393939394,
          "width": 0.39535784313725497,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5191683006535948,
          "top": 0.8679810606060606,
          "width": 0.1647271241830065,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Our MCTS-based planning algorithm, and the predictive menu models, are implemented in Python 3.7.",
      "bboxes": [
        {
          "left": 0.22906209150326798,
          "top": 0.8541439393939394,
          "width": 0.25140849673202614,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679810606060606,
          "width": 0.36533496732026144,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Condition had a statistically significant effect on selection time ( 2 , 17 ) = 5.47,  < 0.05, with grand means Static = 2283 ms, Freqency = 2298 ms, and MCTS = 2162 ms (Figure 9a).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7987954545454545,
          "width": 0.3762777777777778,
          "height": 0.013958333333333406,
          "page": 9
        },
        {
          "left": 0.5287205882352941,
          "top": 0.8126325757575757,
          "width": 0.3858496732026143,
          "height": 0.0130189393939395,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.826469696969697,
          "width": 0.3121143790849673,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "During each condition, the participant interacted with two different menus during 3 blocks.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4999166666666667,
          "width": 0.3787630718954248,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5137537878787879,
          "width": 0.15555392156862746,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The primary goal of this evaluation is to test whether our planning approach (henceforth MCTS) applied to linear menus improves performance in comparison with static menus (Static), and with the well-known frequency-based adaptive approach (Freqency) as a baseline (e.g. as in [34]).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5840997474747475,
          "width": 0.3930065359477124,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5979368686868687,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6117739898989899,
          "width": 0.39255718954248364,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6256111111111111,
          "width": 0.39343790849673205,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6394482323232323,
          "width": 0.1686552287581699,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "For each menu within a condition, a Zipfian distribution, known to accurately capture real-world command selections [13, 37], with shape  = 1.5 was used to control the frequency distribution of target items.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.826469696969697,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8403068181818182,
          "width": 0.3925522875816994,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8541439393939394,
          "width": 0.39256699346405227,
          "height": 0.011422979797979793,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679810606060606,
          "width": 0.07266503267973858,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Figure 8 illustrates computation time results for each depth level (for 400 MCTS iterations).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.45682954545454546,
          "width": 0.3762794117647059,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.0874656862745098,
          "top": 0.4706666666666666,
          "width": 0.1506013071895425,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The experiment began with an introductory briefing and participant consent.",
      "bboxes": [
        {
          "left": 0.6928856209150327,
          "top": 0.43073106060606065,
          "width": 0.22168464052287573,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.44456818181818186,
          "width": 0.24000816993464058,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "For the experiment, linear menus with 15 item labels were randomly generated.",
      "bboxes": [
        {
          "left": 0.19409150326797386,
          "top": 0.7296111111111111,
          "width": 0.28637254901960785,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7434469696969697,
          "width": 0.19815686274509803,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Participants took mandatory breaks (1 minute) between two consecutive blocks, and longer breaks (5 minutes) between conditions where they answered open-ended interview questions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6382866161616162,
          "width": 0.3787630718954248,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6521237373737373,
          "width": 0.39255392156862734,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6659608585858586,
          "width": 0.3186454248366013,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The target item name was displayed at the top of the browser window.",
      "bboxes": [
        {
          "left": 0.6771454248366013,
          "top": 0.3394065656565657,
          "width": 0.2349444444444443,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3532436868686869,
          "width": 0.17941666666666667,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The experiment was conducted on a Macbook Pro, with a 15 Retina display.",
      "bboxes": [
        {
          "left": 0.6305179738562091,
          "top": 0.24808333333333332,
          "width": 0.2819640522875817,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.26192045454545454,
          "width": 0.17554084967320271,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Average Selection Time: We created a mixed-effect model for repeated measures analysis of variance (one-way ANOVA) with selection time (in ms) as dependent variable, conditions (Static, Freqency, MCTS) as fixed independent variable, and participant ID and menu design as random variables.",
      "bboxes": [
        {
          "left": 0.5238643790849673,
          "top": 0.7296111111111111,
          "width": 0.39070588235294124,
          "height": 0.013958333333333406,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7434469696969697,
          "width": 0.39503758169934633,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7572840909090909,
          "width": 0.39503431372549025,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7711212121212121,
          "width": 0.39255718954248375,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7849583333333333,
          "width": 0.2286584967320262,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Results from our simulation-based evaluation offer evidence for our approach and technical solutions.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4132487373737374,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4270858585858586,
          "width": 0.22307026143790853,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Target Item Position: Given the menu selection scenario, items near the top of the menu are typically faster to select than items that are near the bottom.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3959520202020202,
          "width": 0.3762859477124183,
          "height": 0.01395833333333335,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4097891414141414,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42362626262626263,
          "width": 0.14662581699346405,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "During the study, participants were not informed about adaptations (if any) in advance.",
      "bboxes": [
        {
          "left": 0.24574019607843137,
          "top": 0.6604255050505051,
          "width": 0.23472712418300654,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6742626262626262,
          "width": 0.2873480392156863,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We have presented a model-based reinforcement learning method suitable for adaptive interactions.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.6509911616161617,
          "width": 0.393263071895425,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6648282828282828,
          "width": 0.20322712418300648,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We see several exciting topics for future research on model-based RL and its applications in HCI.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4334141414141414,
          "width": 0.3936372549019608,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.44725126262626264,
          "width": 0.15990522875816993,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "To study and demonstrate the viability of the approach, we have applied it to the challenging case of adaptive menus by extending predictive models.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.23688636363636364,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.25072348484848483,
          "width": 0.3925604575163399,
          "height": 0.011320707070707037,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.26456060606060605,
          "width": 0.10634967320261439,
          "height": 0.011320707070707037,
          "page": 11
        }
      ]
    },
    {
      "text": "To conclude, we hope our work can be broadly appealing, and invite contributions from both the HCI and the machine learning community.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6548068181818182,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6686439393939394,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.682479797979798,
          "width": 0.0724640522875817,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Finland projects Human Automata and BAD, Agence Nationale de la Recherche (grant number ANR-16-CE33-0023), and HumaneAI Net (H2020 ICT 48 Network of Centers of Excellence).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.10694570707070707,
          "width": 0.3925637254901959,
          "height": 0.011320707070707078,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.12078282828282828,
          "width": 0.39256045751633983,
          "height": 0.011320707070707078,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1346199494949495,
          "width": 0.3227467320261438,
          "height": 0.011320707070707065,
          "page": 11
        }
      ]
    },
    {
      "text": "We support adoption and further research efforts by providing an open code repository, with examples and instructions, on our project page: https://userinterfaces.aalto.fi/adaptive .",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.7683118686868687,
          "width": 0.39326633986928106,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7821489898989898,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7959861111111112,
          "width": 0.3770571895424837,
          "height": 0.013267676767676706,
          "page": 11
        }
      ]
    },
    {
      "text": "We thank all study participants for their time, and colleagues and reviewers for their helpful comments.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.8403068181818182,
          "width": 0.39326307189542486,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8541439393939394,
          "width": 0.2318562091503268,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    }
  ],
  "2104.03820": [
    {
      "text": "Recent advances in deep generative models have enabled them to produce content of a quality indistinguishable from that produced by a human being.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.6748825757575757,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6921792929292929,
          "width": 0.23094607843137255,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Recently, generative techniques have been applied to the realm of software engineering.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7613636363636364,
          "width": 0.5201307189542483,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Our research focuses on understanding the extent to which generative models are still useful to human stakeholders despite their potential to produce imperfect output.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.2942222222222222,
          "width": 0.6837222222222222,
          "height": 0.013969696969696965,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.31151893939393943,
          "width": 0.3034836601307189,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "We address these questions by considering the use of an NMT model within the context of application modernization [27, 64, 72].",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.3807032828282828,
          "width": 0.6861993464052287,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.398,
          "width": 0.11356862745098037,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To explore the utility of NMT models, we conducted a series of scenario-based design interviews with 11 professional software engineers who work across a variety of technology areas.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4671843434343434,
          "width": 0.6837124183006537,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4844810606060606,
          "width": 0.3955375816993464,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Several studies have examined the notion of an imperfect AI system.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.4369166666666667,
          "width": 0.405014705882353,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In recent years, several efforts have focused on the use of AI and machine learning techniques for various tasks related to software engineering, including code completion [15, 41, 75, 84], code classification [49, 68], API recommendation [16, 33], variable and method naming [3, 5], type inference [39, 93], bug detection and repair [25, 40, 71, 74, 89, 95], comment description and generation [4, 44, 48, 65, 80, 91], code change summarization [66], and code clone detection [96].",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.23800883838383838,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.25530555555555556,
          "width": 0.7016078431372549,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.11963562091503267,
          "top": 0.2726022727272727,
          "width": 0.7003627450980393,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2898977272727273,
          "width": 0.6862254901960784,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Given the imperfect output of state-of-the-art NMT models, we posit that such systems will act in concert with human software engineers as a collaborative partner or teammate.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.7396010101010101,
          "width": 0.7,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7568964646464647,
          "width": 0.34180555555555553,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We discuss three areas relevant to our work: recent advances in the use of AI techniques, and specifically deep generative models, in software engineering; studies of the utility of imperfect AI; and studies of human-AI co-creation with generative AI.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.1428800505050505,
          "width": 0.7006944444444443,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.16017676767676767,
          "width": 0.7,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.11945915032679738,
          "top": 0.17747222222222223,
          "width": 0.11533333333333334,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Despite identifying favorable outcomes of human-AI partnerships, we note that these outcomes are all subjective: the quality of the generated output lies in the perceptions of the people using the system.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5790757575757576,
          "width": 0.6854493464052289,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5963724747474748,
          "width": 0.5234330065359476,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Much of the recent focus of the generative AI community has been on developing new capabilities and exploring their applications in creative domains such as art [29, 51, 70, 92], photography [10], music [45, 57], video games [37], and literature [21], as well as scientific domains such as drug discovery [24], materials discovery [98], and software engineering [69].",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4234090909090909,
          "width": 0.6837222222222223,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.44070580808080806,
          "width": 0.7016078431372548,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.45800252525252527,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4752979797979798,
          "width": 0.10299183006535947,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "We developed an exploratory design scenario in order to engage software engineers in a discussion about the role of generative AI in application modernization.",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.7062714646464646,
          "width": 0.7007042483660132,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7235669191919193,
          "width": 0.2531307189542483,
          "height": 0.011320707070706981,
          "page": 3
        }
      ]
    },
    {
      "text": "Each interview was attended by at least three of the authors.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6843686868686868,
          "width": 0.367361111111111,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The UX variants were designed to resemble a simple programming environment with two code panes: a source pane on the left for input code, and a target pane on the right for the code output by the NMT model.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.12126010101010101,
          "width": 0.6853725490196079,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.13855555555555557,
          "width": 0.6204558823529411,
          "height": 0.011320707070707065,
          "page": 4
        }
      ]
    },
    {
      "text": "Our scenario used real output from TransCoder that contained flaws.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.31151893939393943,
          "width": 0.405109477124183,
          "height": 0.011320707070707037,
          "page": 4
        }
      ]
    },
    {
      "text": "We conducted an interview study with software engineers in which we used the design scenario to spark discussions around the role of generative AI in application modernization.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.4422209595959596,
          "width": 0.7006944444444444,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.45951767676767674,
          "width": 0.3838970588235294,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We conducted a thematic analysis of our data to identify important ideas and themes from our interviews.",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.4566830808080808,
          "width": 0.6401535947712419,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We begin by highlighting the difficulties faced by our software engineers in modernizing legacy applications, motivating the need for AI support.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6642386363636363,
          "width": 0.6853316993464053,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6815340909090909,
          "width": 0.20596568627450976,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Our interviews generated a wealth of material: 11 hours of recorded videos, approximately 63 pages of notes, and a corpus of approximately 400 pages of interview transcripts containing about 89k words.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5258686868686868,
          "width": 0.6837222222222223,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5431641414141414,
          "width": 0.5334330065359476,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We recruited 11 full-time software engineers within our organization, an international information technology company.",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.1428800505050505,
          "width": 0.7029509803921569,
          "height": 0.011320707070707065,
          "page": 5
        }
      ]
    },
    {
      "text": "For each UX variant, we asked participants about what they liked and disliked and how they might improve the design.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.2824848484848485,
          "width": 0.7022565359477124,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "P4 described application modernization as a rats nest [of] very impossible, undocumented, uncommitted, lots of dead unit tests that hadnt been run [in] year[s] kind of situation, and complained that there was an architecture at some point... then you had other folks come along and write additional pieces that... kind of go their own way.",
      "bboxes": [
        {
          "left": 0.5011683006535947,
          "top": 0.7433068181818181,
          "width": 0.3792091503267975,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7606035353535354,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7778989898989899,
          "width": 0.6999967320261437,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.18000163398692812,
          "top": 0.795195707070707,
          "width": 0.2411062091503268,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "In discussing whether they would accept code produced by the NMT model, participants felt that they would treat it in the same fashion that they would treat the output of their fellow software developers: by reviewing and testing it.",
      "bboxes": [
        {
          "left": 0.3613709150326797,
          "top": 0.48463636363636364,
          "width": 0.460233660130719,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5019330808080809,
          "width": 0.7000000000000001,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.519229797979798,
          "width": 0.23117483660130722,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We recognize that trust is a complex, multi-faceted construct that has been described as being an attitude [78], an intention [62], and a behavior [1].",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.35429040404040407,
          "width": 0.683720588235294,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.37158712121212123,
          "width": 0.19429738562091503,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "Some participants had questions about the underlying mechanics of the NMT model, as they were curious how it works (P5) and would like to know what its thinking (P10).",
      "bboxes": [
        {
          "left": 0.33141666666666664,
          "top": 0.5976868686868687,
          "width": 0.49019444444444443,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6149835858585858,
          "width": 0.561625816993464,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "P9 offered a more nuanced view on who would need to have an understanding of how the AI model operated.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7782045454545454,
          "width": 0.6625980392156862,
          "height": 0.013969696969697076,
          "page": 6
        }
      ]
    },
    {
      "text": "Many participants discussed the issue of trust in software engineering and how practices such as testing and code review help establish trust amongst human teams of software engineers.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.22566161616161615,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2429570707070707,
          "width": 0.4484689542483661,
          "height": 0.011320707070707065,
          "page": 6
        }
      ]
    },
    {
      "text": "One way of producing such explanations is via the alternate translations shown in Figure 1C.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5476982323232323,
          "width": 0.5615604575163399,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Understanding the models operation could also eliminate some of the confusion caused by the confidence highlights in Figure 1B.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.2250366161616162,
          "width": 0.6837124183006537,
          "height": 0.011320707070707037,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.24233333333333332,
          "width": 0.07773856209150323,
          "height": 0.011320707070707065,
          "page": 7
        }
      ]
    },
    {
      "text": "This discrepancy in confidence, in which participants were more confident in their own abilities to translate the code than the NMT model, caused many participants to desire additional insight into why the NMT model was not confident.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.44392045454545453,
          "width": 0.6837124183006537,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4612171717171717,
          "width": 0.7022598039215685,
          "height": 0.01396969696969702,
          "page": 7
        }
      ]
    },
    {
      "text": "Despite the feelings that having an understanding of the NMT models operation wasnt important, we observed that having such understanding does have benefits.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.15585227272727273,
          "width": 0.6837124183006537,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.17314898989898989,
          "width": 0.28227450980392155,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Participants identified the importance of being able to give feedback (P4), such as by unflag[ing] (P7) low-confidence tokens identified by the NMT model.",
      "bboxes": [
        {
          "left": 0.35497712418300653,
          "top": 0.679611111111111,
          "width": 0.5254019607843138,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.17834640522875816,
          "top": 0.6969078282828283,
          "width": 0.4203398692810458,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "P6 further imagined that Im just going to rewrite this and through my action the AI can learn.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7947171717171718,
          "width": 0.5606781045751634,
          "height": 0.011320707070706981,
          "page": 7
        }
      ]
    },
    {
      "text": "Participants also appreciated the feature of the alternate translation UI in which downstream edits could be made when selecting an alternate translation (e.g. because selecting an alternate may have renamed a variable or changed a loop index).",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6210934343434343,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.11945915032679738,
          "top": 0.6383901515151515,
          "width": 0.7005359477124182,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6556868686868687,
          "width": 0.08280392156862747,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Participants responded positively to the confidence highlights (Figure 1B) and the alternate translations (Figure 1C) and felt that both views were helpful.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.1428800505050505,
          "width": 0.7008709150326797,
          "height": 0.011320707070707065,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.16017676767676767,
          "width": 0.22180882352941178,
          "height": 0.011320707070707065,
          "page": 8
        }
      ]
    },
    {
      "text": "We initially thought that the translation would produce only content in the form of the translated code.",
      "bboxes": [
        {
          "left": 0.5411143790849673,
          "top": 0.2564772727272727,
          "width": 0.27888725490196087,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.2737727272727273,
          "width": 0.34687254901960785,
          "height": 0.013969696969696965,
          "page": 8
        }
      ]
    },
    {
      "text": "Software developers typically work with deterministic tools and a great deal of work goes into ensuring that these tools are highly reliable [19].",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.7779318181818181,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7952272727272728,
          "width": 0.16895915032679737,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "Many participants were initially skeptical of the accuracy and value of the confidence highlights (P1, P2, P3, P5, P7, P9).",
      "bboxes": [
        {
          "left": 0.48274999999999996,
          "top": 0.45655555555555555,
          "width": 0.3376274509803922,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4738510101010101,
          "width": 0.374781045751634,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "In addition, the alternate translations had additional explanatory power in helping participants understand the nature of the underlying code.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.525739898989899,
          "width": 0.6837173202614379,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5430366161616161,
          "width": 0.18079738562091507,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Thus, although many participants expressed a willingness to accept imperfectly-translated code as a starting point, acceptance may depend on how many errors the translated code contains as well as the nature of those errors (e.g. if they are easy to spot and fix, or if they take attention away from the central problem).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.725564393939394,
          "width": 0.6853316993464054,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7428598484848485,
          "width": 0.7000049019607842,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7601565656565656,
          "width": 0.5177058823529412,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Participants also expressed mixed feelings about their tolerance for easy-to-spot or easy-to-fix errors.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4895366161616162,
          "width": 0.5857467320261438,
          "height": 0.011320707070707037,
          "page": 9
        }
      ]
    },
    {
      "text": "For large codebases, the downside of imperfectly-translated code may be less than the upside of simply having automatically-produced translations.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5760176767676768,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5933143939393939,
          "width": 0.21612581699346403,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "In some cases, although not an explicit part of the study, participants actually found the errors in the translation.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.15585227272727273,
          "width": 0.6859738562091504,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Overall, many participants felt that even the erroneous output was desirable and that it would be something they would find useful to have.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.2250366161616162,
          "width": 0.6840931372549021,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.17945915032679738,
          "top": 0.24233333333333332,
          "width": 0.16245588235294117,
          "height": 0.011320707070707065,
          "page": 9
        }
      ]
    },
    {
      "text": "Despite the positive reception of potentially error-prone code, there did seem to be a threshold regarding how many errors would be acceptable.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.33999116161616166,
          "width": 0.6841045751633988,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.35728661616161617,
          "width": 0.16003431372549018,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Participants described the lifecycle of modernizing applications as consisting of three general phases: (1) creating an understanding of the legacy application and its architecture by reviewing code and documentation; (2) performing the migration work, which may include translating and/or refactoring the code; and (3) reviewing and testing the migrated code.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.1428800505050505,
          "width": 0.6999967320261439,
          "height": 0.011320707070707065,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.16017676767676767,
          "width": 0.7,
          "height": 0.011320707070707065,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.17747222222222223,
          "width": 0.7000032679738563,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.1947689393939394,
          "width": 0.03042647058823529,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Generating documentation from source is an active area of research in the machine learning community (e.g. [44, 48, 65, 91]) and our results highlight the importance of this functionality in user experiences, even when generated documentation may be imperfect.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6726565656565657,
          "width": 0.685330065359477,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.11966339869281045,
          "top": 0.6899532828282828,
          "width": 0.7003284313725489,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7072487373737373,
          "width": 0.2015539215686275,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "One helpful improvement to the code translation user interface would be to show a stronger visual correspondence between input and output source code.",
      "bboxes": [
        {
          "left": 0.3282320261437908,
          "top": 0.7344722222222222,
          "width": 0.49176633986928114,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7517676767676768,
          "width": 0.4176830065359477,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Participants also described how generative methods could be used to fill in missing documentation to help others understand ones own code, to create an understanding of poorly-documented code, or to re-align documentation with code when drift has occurred [30, 85].",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.4559722222222222,
          "width": 0.6837140522875816,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4732689393939394,
          "width": 0.7000000000000001,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.49056439393939394,
          "width": 0.2220196078431373,
          "height": 0.011320707070707037,
          "page": 10
        }
      ]
    },
    {
      "text": "As described in Section 5.0.1, one of the main challenges in migrating legacy applications is due to the fact that code and code architectures are undocumented, (P4) with specifications sometimes living in the gray matter storage (P7) of engineers that dont work here anymore (P4).",
      "bboxes": [
        {
          "left": 0.3043169934640523,
          "top": 0.23928787878787877,
          "width": 0.5156797385620916,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.25658333333333333,
          "width": 0.6999901960784314,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.11834640522875817,
          "top": 0.27388005050505054,
          "width": 0.4432303921568628,
          "height": 0.011320707070707037,
          "page": 10
        }
      ]
    },
    {
      "text": "Translation could also help software engineers better understand codebases in languages with which they are less familiar: Ive got a bunch of engineers that know Python, but they dont know Java. So, it might be easier to delve in and spelunk through... auto gen[erated] Python code than it would be to go back and spelunk the original Java. (P4).",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.40408333333333335,
          "width": 0.6837156862745097,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.4213800505050505,
          "width": 0.6999983660130719,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.1200016339869281,
          "top": 0.438675505050505,
          "width": 0.6986323529411764,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "P6: Its very tedious to write these comments... It really takes so much time... If the AI generated this for me I think that is gonna be really helpful.",
      "bboxes": [
        {
          "left": 0.15988398692810457,
          "top": 0.5496666666666666,
          "width": 0.6202254901960784,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.15988398692810457,
          "top": 0.5669633838383838,
          "width": 0.21548692810457515,
          "height": 0.011320707070706981,
          "page": 10
        }
      ]
    },
    {
      "text": "Generating a whole slew of automated unit tests (P4) as well as more realistic test values (P3) ensures that the right hand side code not only runs and doesnt crash but produces expected output (P4).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5964709595959595,
          "width": 0.6837173202614378,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6137676767676767,
          "width": 0.5337369281045752,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Many participants described how code translation could be used to take advantage of functionality defined in third party libraries, because the same libraries in Java dont exist in Python, or similar libraries exist but theyre not... syntactically the same. (P0).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.17314898989898989,
          "width": 0.6837238562091503,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.19044444444444444,
          "width": 0.7022483660130718,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.20774116161616163,
          "width": 0.16701960784313727,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Participants were eager to accept help from an imperfect AI assistant (e.g. as discussed by P2 & P3).",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.7250416666666666,
          "width": 0.5942875816993464,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Finally, P7 discussed how an AI partner might monitor his work and make proactive suggestions: It would be cool if the AI knew what I was trying to build, like a controller or view, and it would finish it for me. Like give me a shell of what Im trying to do so I can fill in the details.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.398,
          "width": 0.6837124183006538,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4152954545454545,
          "width": 0.7000000000000001,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.17945915032679738,
          "top": 0.43259217171717174,
          "width": 0.2852254901960784,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "As discussed in Section 5.1.1, testing seems to be one of the primary ways that software engineers will accept and use AI-translated code: Im very much a supporter of test-driven development, which typically means you write tests that validate behavior. (P3).",
      "bboxes": [
        {
          "left": 0.3488790849673203,
          "top": 0.46170959595959593,
          "width": 0.5311241830065359,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.47900505050505054,
          "width": 0.7003807189542482,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4963017676767677,
          "width": 0.29514215686274514,
          "height": 0.011320707070706981,
          "page": 11
        }
      ]
    },
    {
      "text": "We note that our system only examined one kind of human-AI interaction pattern, in which the human provided code and the translator produced a translation.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.17314898989898989,
          "width": 0.6837254901960784,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.19044444444444444,
          "width": 0.25008986928104576,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "While conventional software development tools are generally quite reliable, software engineers themselves are not.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.3807032828282828,
          "width": 0.7029509803921569,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Our results motivate the need for explainable generative AI.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5709621212121212,
          "width": 0.35481535947712417,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Our study identified a number of areas that could be pursued for the use of generative AI in application modernization.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.7093320707070708,
          "width": 0.7022598039215686,
          "height": 0.011320707070706981,
          "page": 12
        }
      ]
    },
    {
      "text": "Incorporating feedback to the generative model from the edits made by software engineers is another fruitful research opportunity.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7958131313131313,
          "width": 0.6837254901960784,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.8131098484848485,
          "width": 0.07378758169934639,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Participants identified many opportunities for generative models to aid the overall application modernization workflow of building understanding, performing the migration, and reviewing & testing.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.19044444444444444,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.17945915032679738,
          "top": 0.20774116161616163,
          "width": 0.5505816993464052,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "Our study is a preliminary examination of how probabilistic generative models can be applied to a use case that requires an objective level of quality.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.3841628787878788,
          "width": 0.6999934640522876,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.18000163398692812,
          "top": 0.4014583333333333,
          "width": 0.16816013071895422,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "Generative AI techniques are enabling new forms of human-AI co-creation.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.5951767676767676,
          "width": 0.4724248366013072,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    }
  ],
  "2102.09039": [
    {
      "text": "To battle the issue, previous work has attempted to apply Artificial Intelligence algorithms to enable efficient search of a large design space [5, 13, 16, 19, 22].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.39347853535353533,
          "width": 0.3787614379084967,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.40731565656565655,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.42115277777777776,
          "width": 0.18356045751633987,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "To address challenge 1), We designed the HTML annotation as a simple extension of the existing HTML and CSS grammar, where instead of specifying a single value for an attribute, a designer can provide multiple candidate values for it, which are to be explored by Spacewalker.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7255656565656566,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7394027777777777,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7532398989898991,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7670770202020202,
          "width": 0.39255392156862734,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7809141414141415,
          "width": 0.09825653594771244,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "To ease the effort for exploring a design space, previous work has extensively investigated using crowdsourcing as an essential component in UI design and evaluation [3, 911, 14, 15, 17, 25, 26], which lowers the threshold for acquiring user feedback at scale.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.2827828282828283,
          "width": 0.3766633986928105,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.29661868686868686,
          "width": 0.39255718954248375,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3104558080808081,
          "width": 0.39417156862745095,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5189918300653594,
          "top": 0.32429292929292924,
          "width": 0.39535784313725497,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "In this paper, we present Spacewalker, a tool that allows designers to rapidly search a design space of a web UI for an optimal design within that space (see Figure 1).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.545685606060606,
          "width": 0.3787565359477124,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5595227272727272,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5733598484848484,
          "width": 0.24064379084967324,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "User interface design is a complex task that often requires designers to explore a wide range of options, which is expensive and time consuming.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6707891414141414,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6846262626262627,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6984633838383838,
          "width": 0.0705065359477124,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Yang Li Google Research Mountain View, CA liyang@google.com",
      "bboxes": [
        {
          "left": 0.7388316993464052,
          "top": 0.16785732323232325,
          "width": 0.05983496732026139,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.7135294117647059,
          "top": 0.18488383838383837,
          "width": 0.11100490196078439,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.7027941176470588,
          "top": 0.19997853535353535,
          "width": 0.13304575163398702,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.7030866013071895,
          "top": 0.2150732323232323,
          "width": 0.13189052287581693,
          "height": 0.012578282828282855,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8038421717171718,
          "width": 0.3927761437908497,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8139065656565657,
          "width": 0.3925588235294118,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8239696969696969,
          "width": 0.39256045751633994,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8340328282828282,
          "width": 0.07573529411764705,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.5621376262626263,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Although existing methods are widely adopted, they often require substantial engineering effort to build and instrument a test.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5736401515151515,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5874772727272727,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Usability testing [2] is a commonly used approach for evaluating a UI design, which often requires a user experience researcher to",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8340012626262626,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.847838383838384,
          "width": 0.39255718954248364,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "We evaluated Spacewalker by asking interaction designers to use it for exploring a set of UI design tasks, and Spacewalker received positive feedback.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.46294444444444444,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.47678156565656565,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.49061742424242427,
          "width": 0.10406699346405228,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Previous work has incorporated crowdsourcing for UI design and evaluation.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.798324494949495,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8121616161616161,
          "width": 0.06723366013071896,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Our work is related to three areas of the literature, including UI evaluation methods, crowdsourcing-based design support, and interactive UI design optimization.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.761003787878788,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7748409090909091,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7886780303030303,
          "width": 0.19503431372549018,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "This instructs Spacewalker to explore three different alternatives for the page background: image \" bg1.jpg \", image \" bg2.jpg \", and a solid background with a dark gray color \" #333 \".",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.23409343434343433,
          "width": 0.3930049019607845,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.24726262626262627,
          "width": 0.39255392156862745,
          "height": 0.011988636363636368,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.26109974747474746,
          "width": 0.28547549019607843,
          "height": 0.011988636363636396,
          "page": 2
        }
      ]
    },
    {
      "text": "The crowd can be more actively involved in UI design tasks to provide feedback [14, 17, 25, 26] or participate in the design process [10, 11, 15].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.20641919191919192,
          "width": 0.3762745098039215,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22025631313131314,
          "width": 0.3925653594771242,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.23409343434343433,
          "width": 0.07009313725490195,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To address the issue, Salem [19] combined crowdsourcing and genetic programming [12] for the design of landing pages.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5246704545454546,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5385075757575758,
          "width": 0.3408872549019608,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "After creating the specifications for all the design aspects in questioning, Alex launches a Spacewalker task by specifying 50",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8705959595959595,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8844318181818183,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "This ensures that Spacewalker would globally apply these options: either color1 for titles and color2 for body text, or color3 for titles and color4 for body text.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.8152474747474748,
          "width": 0.39473202614379077,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8290845959595959,
          "width": 0.39255555555555544,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.14893464052287586,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "We here describe how UI designers or developers would use Spacewalker to explore the design space of their user interfaces.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.8014103535353535,
          "width": 0.3957352941176471,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08736437908496732,
          "top": 0.8152474747474748,
          "width": 0.341718954248366,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Using Artificial Intelligence algorithms to optimize interface design is a longstanding topic.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.4139747474747475,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42781186868686866,
          "width": 0.13661111111111113,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In this example, Spacewalker uses either \" nav-1 \" or \" nav-2 \" at a time, while the rest children are unaffected.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5240025252525252,
          "width": 0.39255555555555544,
          "height": 0.011988636363636451,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5385075757575758,
          "width": 0.27861601307189554,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In addition to exploring individual CSS properties, Alex wants to determine which design of the navigation bar she should use for the Product page.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3447891414141414,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3586262626262626,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.37246338383838384,
          "width": 0.08324673202614385,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Instead of specifying exploration strategies based on nodes, which can be tedious, designers can directly explore at the level of CSS specification using the explore-css tag.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5800189393939394,
          "width": 0.37788888888888883,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5189918300653594,
          "top": 0.593854797979798,
          "width": 0.3930996732026145,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6070239898989899,
          "width": 0.2660130718954249,
          "height": 0.01198863636363634,
          "page": 2
        }
      ]
    },
    {
      "text": "In addition to explore individual elements, Spacewalker allows a designer to easily explore a large component of a design as a whole, which might contain a branch of elements and sub-trees, such as a side bar or a navigation bar.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7322260101010101,
          "width": 0.3762843137254901,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7460618686868686,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5189918300653594,
          "top": 0.75989898989899,
          "width": 0.3947156862745098,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.23681699346405227,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Alex can monitor the progress of the task in the Progress Viewer (see Figure 4), which allows her to see the sample designs of the current generation (iteration).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6829886363636364,
          "width": 0.3765669934640523,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.0874656862745098,
          "top": 0.6968257575757575,
          "width": 0.3929967320261438,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7106628787878788,
          "width": 0.17824509803921568,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "In this section, we discuss the system design and algorithmic details that underline the Spacewalker.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8100050505050506,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8238421717171717,
          "width": 0.18967810457516343,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "As shown in the above example, Spacewalker supports a rich set of methods for exploring a design space through simple HTML extensions, which are intuitive to designers as shown in our experiments.",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.469530303030303,
          "width": 0.39307843137254905,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.48336742424242424,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.49720454545454545,
          "width": 0.3948153594771242,
          "height": 0.011320707070707037,
          "page": 3
        }
      ]
    },
    {
      "text": "Spacewalker supports all CSS properties and any number of them for an element.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6262121212121212,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6400492424242424,
          "width": 0.12963888888888886,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "To explore a property of an individual element, a designer follows a simple syntax by prefixing \" explore\" to the property, and specifying the alternative values for the property delimited by spaces:",
      "bboxes": [
        {
          "left": 0.6100898692810458,
          "top": 0.5340366161616161,
          "width": 0.30200326797385624,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5472058080808081,
          "width": 0.3925669934640523,
          "height": 0.01198863636363634,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5617108585858586,
          "width": 0.39293790849673205,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5755479797979798,
          "width": 0.1201372549019607,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "In our early exploration, we found conventional GA sensitive to the random initialization of design options.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.75989898989899,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.27940849673202606,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "A specific genetic sequence indicates a UI configuration, which can be rendered as a design instance shown to a crowd worker for feedback.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1649078282828283,
          "width": 0.3762777777777778,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17874494949494948,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1925820707070707,
          "width": 0.05510457516339873,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The pairwise comparison of designs eases the rater task and yields more reliable feedback than rating a design individually on an absolute scale.",
      "bboxes": [
        {
          "left": 0.7451078431372549,
          "top": 0.6492032828282828,
          "width": 0.16697875816993468,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6630404040404041,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6768775252525252,
          "width": 0.28088398692810457,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "As the number of attributes and nodes to be explored increases, the search space for a design grows combinatorially.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.3271136363636364,
          "width": 0.39307843137254905,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3409507575757576,
          "width": 0.29160294117647056,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The Spacewalker parser analyzes a design specification file by parsing its HTML structure, which derives an internal representation for the design search space.",
      "bboxes": [
        {
          "left": 0.17905228758169933,
          "top": 0.15827146464646463,
          "width": 0.3038856209150327,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17210858585858585,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.18594570707070707,
          "width": 0.2536960784313726,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We refer an instance of a UI design, which is acquired by selecting a specific option for each attribute to be explored, as a configuration of the design.",
      "bboxes": [
        {
          "left": 0.4615653594771242,
          "top": 0.7427878787878788,
          "width": 0.018895424836601227,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.756625,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7704621212121212,
          "width": 0.39256045751633994,
          "height": 0.011332070707070763,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7842992424242424,
          "width": 0.06349019607843136,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "A typical genetic algorithm (GA) follows an iterative process, where potential solutions evolve from a multi-generation process.",
      "bboxes": [
        {
          "left": 0.3167761437908497,
          "top": 0.4726843434343434,
          "width": 0.16369281045751638,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.0874656862745098,
          "top": 0.4865214646464646,
          "width": 0.3930016339869281,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5003585858585858,
          "width": 0.19708169934640524,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Initialization.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.35860353535353534,
          "width": 0.09064542483660129,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "To do so, we introduce a bit mask, named feedback mask , for each genetic sequencethat corresponds a design instance, which has the same length as a genetic sequence.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10956060606060607,
          "width": 0.3762859477124183,
          "height": 0.011332070707070707,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12339772727272727,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1372348484848485,
          "width": 0.22974673202614382,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We invited five participants for this remote user study.",
      "bboxes": [
        {
          "left": 0.7086290849673202,
          "top": 0.5293876262626263,
          "width": 0.20346732026143788,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5432247474747475,
          "width": 0.10915196078431366,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We evaluate Spacewalker in multiple dimensions.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.3218320707070707,
          "width": 0.3049624183006536,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "The Spacewalker system is built as a web service based on AppEngine 7 .",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7910239898989899,
          "width": 0.3954787581699347,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8023914141414141,
          "width": 0.06010784313725491,
          "height": 0.013790404040404103,
          "page": 5
        }
      ]
    },
    {
      "text": "In this study, we evaluate the usability of our proposed HTML extensions by gather informal feedback from web designers.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.45108333333333334,
          "width": 0.39293790849673205,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.46491919191919195,
          "width": 0.36536274509803923,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Finally, we consider nested designs (where one option value depend on another parent value).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6907146464646465,
          "width": 0.37627450980392163,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7045517676767676,
          "width": 0.20579411764705885,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "All participants were able to learn the Spacewalker markup syntax using the description we provided and were able to create syntactically correct specifications.",
      "bboxes": [
        {
          "left": 0.6833088235294118,
          "top": 0.8429217171717173,
          "width": 0.22878104575163383,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5189918300653594,
          "top": 0.8705959595959595,
          "width": 0.33919934640522875,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We conducted two experiments to evaluate whether Spacewalker was able to efficiently search a design space and generate better designs by utilizing the responses from the crowd workers.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4878926767676768,
          "width": 0.39354901960784316,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08736437908496732,
          "top": 0.501729797979798,
          "width": 0.3933856209150327,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5155669191919192,
          "width": 0.36811601307189545,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "On average, each task took about 1 hour to finish.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8567588383838384,
          "width": 0.28203267973856205,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We received largely positive feedback from the participants.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.34482323232323236,
          "width": 0.3582385620915032,
          "height": 0.011320707070707037,
          "page": 6
        }
      ]
    },
    {
      "text": "We conducted both experiments following the same procedure.",
      "bboxes": [
        {
          "left": 0.3279264705882353,
          "top": 0.6076919191919191,
          "width": 0.1550081699346405,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6215290404040403,
          "width": 0.22123692810457518,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "For each search specification, we calculate the percentage of votes received by Spacewalker genetic method (the rest of the votes are received by uniform sampling).",
      "bboxes": [
        {
          "left": 0.689547385620915,
          "top": 0.7958598484848485,
          "width": 0.22502287581699354,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8096969696969697,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8235340909090909,
          "width": 0.3948202614379086,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Experiment #2: Effects of Web Page Designs.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.400114898989899,
          "width": 0.29360620915032687,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Experiment #1: Effects of Search Space Sizes.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.2894191919191919,
          "width": 0.3021029411764705,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Another challenge lies in how well designers can understand the effect when complex design alternatives exist in one design space, e.g., design options nested within a parent option or global options via CSS.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3789532828282828,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.392790404040404,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4066275252525252,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.42046464646464643,
          "width": 0.0941307189542483,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Dependency between elements and designer specified options also presents two challenges to Spacewalker.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.517324494949495,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5311603535353535,
          "width": 0.268483660130719,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Crowd raters, from the cross-method evaluation, showed significant preference for the designs generated by Spacewalker for all the search space sizes in Experiment 1 (see Table 2).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.33744318181818184,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.35128030303030305,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.36511742424242427,
          "width": 0.30173202614379085,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Our quantitative experiments for examining the performance of Spacewalker algorithms for searching a design space indicate that it improves designs over time by producing better design candidates, particularly when the search space is large.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8355744949494949,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8494116161616162,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8632487373737373,
          "width": 0.39417320261437905,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8770858585858586,
          "width": 0.25522549019607843,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For the experiment where Spacewalker is used to search for different web page types, we find that crowd raters, from the crossmethod evaluation, preferred the results produced by Spacewalker genetic method in all cases we tested when they are compared with those from the uniform sampling method (see Table 3).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.43430176767676765,
          "width": 0.3765588235294117,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.44813888888888886,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4619760101010101,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4758131313131313,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4896502525252525,
          "width": 0.3386454248366013,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "The Spacewalker markup extension is easy to understand and use for specifying design exploration.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8014103535353535,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152474747474748,
          "width": 0.23391830065359476,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In this section, we discuss the strengths and limitation of our work, and our plan for future work.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6492032828282828,
          "width": 0.3941683006535948,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6630404040404041,
          "width": 0.17506535947712415,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For each of the tasks, our GA-based algorithm only visited a small portion of the design space.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.17874494949494948,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1925820707070707,
          "width": 0.19990686274509806,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Finally, we want to emphasize that Spacewalker is able to identify an optimal design in a defined design space, instead of finding a globally optimal design.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5385075757575758,
          "width": 0.3787516339869281,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.552344696969697,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5661818181818182,
          "width": 0.15059640522875817,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Spacewalker provides integrated support to enable designers to rapidly explore a large design space to improve their web UI design.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8290845959595959,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8429217171717173,
          "width": 0.3948153594771242,
          "height": 0.011320707070706981,
          "page": 9
        }
      ]
    },
    {
      "text": "We would like to thank anonymous reviewers for their insightful feedback for improving the paper.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.24478535353535355,
          "width": 0.39325816993464047,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.25862247474747474,
          "width": 0.2007859477124183,
          "height": 0.011320707070707037,
          "page": 9
        }
      ]
    }
  ],
  "2101.11778": [
    {
      "text": "In the attention economy, social media apps employ a variety of design mechanismssuch as eye-catching notification icons, tempting clickbait, and never-ending autoplayto maximize their share of the users time.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.38983459595959596,
          "width": 0.3925637254901959,
          "height": 0.011320707070707037,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4036717171717172,
          "width": 0.39503104575163417,
          "height": 0.011320707070707037,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.41750757575757574,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.43134469696969696,
          "width": 0.10871568627450978,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "In response, digital wellbeing researchers have innovated what we term external mechanisms that help users manage or monitor their app use, such as lockout timers [56] and productivity dashboards [58].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5558775252525252,
          "width": 0.3762810457516339,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5189918300653594,
          "top": 0.5697146464646464,
          "width": 0.3933839869281047,
          "height": 0.011332070707070763,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5835517676767676,
          "width": 0.3950424836601307,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5973888888888889,
          "width": 0.07223366013071897,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "It is no accident then that social media use is often associated with a loss of sense of agency [10].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4728560606060606,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5189918300653594,
          "top": 0.48669318181818183,
          "width": 0.2174133986928105,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7172765151515151,
          "width": 0.3927761437908497,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7273396464646464,
          "width": 0.3925588235294118,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7374027777777779,
          "width": 0.39256045751633994,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7474659090909092,
          "width": 0.07863071895424838,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "University of Oxford ulrik.lyngs@cs.ox.ac.uk",
      "bboxes": [
        {
          "left": 0.4318415032679738,
          "top": 0.15972474747474746,
          "width": 0.13794607843137258,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.42232516339869286,
          "top": 0.17481944444444444,
          "width": 0.15739869281045749,
          "height": 0.012578282828282855,
          "page": 0
        }
      ]
    },
    {
      "text": "Himanshu Zade University of Washington himanz@uw.edu",
      "bboxes": [
        {
          "left": 0.7054183006535948,
          "top": 0.14269949494949494,
          "width": 0.12722875816993462,
          "height": 0.015095959595959607,
          "page": 0
        },
        {
          "left": 0.6832516339869281,
          "top": 0.15972474747474746,
          "width": 0.17156209150326795,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.7133022875816993,
          "top": 0.17481944444444444,
          "width": 0.11146078431372552,
          "height": 0.012578282828282855,
          "page": 0
        }
      ]
    },
    {
      "text": "J. Vera Liao University of Washington ljzj@uw.edu",
      "bboxes": [
        {
          "left": 0.1862075163398693,
          "top": 0.20132323232323232,
          "width": 0.09083660130718954,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.1460016339869281,
          "top": 0.21834848484848482,
          "width": 0.17156209150326798,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.19062091503267972,
          "top": 0.23344318181818183,
          "width": 0.08232189542483662,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.6346237373737373,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "University of Washington kai1@uw.edu",
      "bboxes": [
        {
          "left": 0.14681535947712418,
          "top": 0.15972474747474746,
          "width": 0.17156209150326798,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.18758496732026145,
          "top": 0.17481944444444444,
          "width": 0.09002124183006535,
          "height": 0.012578282828282855,
          "page": 0
        }
      ]
    },
    {
      "text": "University of Washington",
      "bboxes": [
        {
          "left": 0.548328431372549,
          "top": 0.2769027777777778,
          "width": 0.17156209150326784,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "James Choi University of Washington jchoi408@uw.edu",
      "bboxes": [
        {
          "left": 0.45476797385620915,
          "top": 0.20132323232323232,
          "width": 0.09015196078431365,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.414218954248366,
          "top": 0.21834848484848482,
          "width": 0.1715620915032679,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.4411274509803922,
          "top": 0.23344318181818183,
          "width": 0.11774346405228753,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "YouTube is an important case for better understanding the design mechanisms of attention capture.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.23409343434343433,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.24793055555555554,
          "width": 0.20589869281045747,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "However, a weakness of this approach is that reducing screentime is often a poor proxy for what users actually want.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5410227272727273,
          "width": 0.3787598039215687,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5548598484848485,
          "width": 0.34271078431372537,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Within YouTube, there are two digital wellbeing features that do move beyond time spent controls and offer more granular control.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6240454545454546,
          "width": 0.3762745098039215,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6378825757575757,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.651719696969697,
          "width": 0.02404738562091513,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "One promising alternative to the screentime paradigm is to design for sense of agency , the focus of this paper.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7900896464646464,
          "width": 0.3787532679738562,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8039267676767677,
          "width": 0.2804460784313726,
          "height": 0.011332070707070652,
          "page": 1
        }
      ]
    },
    {
      "text": "Reducing screentime in certain apps is a common measure of success in digital wellbeing tools.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4026527777777778,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.416489898989899,
          "width": 0.1789689542483659,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "We investigate two research questions in two studies that build upon each other:",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1649078282828283,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17874494949494948,
          "width": 0.10088725490196078,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Design practitioners have raised concerns about dark patterns, interfaces that are designed to manipulate a user into behavior that goes against their best interests [43, 67].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6787954545454545,
          "width": 0.39417810457516345,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6926325757575759,
          "width": 0.39256045751633994,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.706469696969697,
          "width": 0.2424950980392157,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "The two contributions of this work are:",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.3911439393939394,
          "width": 0.23560294117647057,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Second, internal mechanisms shift the focus from fighting distractions to aligning interests.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.30327777777777776,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.317114898989899,
          "width": 0.17688725490196078,
          "height": 0.011320707070707037,
          "page": 2
        }
      ]
    },
    {
      "text": "At the other end of the spectrum, internal mechanisms contribute to the redesign or rebuild of an experience.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.666030303030303,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6798674242424243,
          "width": 0.31119444444444444,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "In contrast to external mechanisms, the space of internal mechanisms is relatively underexplored (see [45, 66] for notable exceptions), but holds particular promise for increasing user agency in two ways.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1372348484848485,
          "width": 0.3787598039215686,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1510719696969697,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1649078282828283,
          "width": 0.39255718954248375,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17874494949494948,
          "width": 0.06224183006535944,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The mechanisms 1 of digital wellbeing interventions can be placed along a spectrum (see Figure 1 ).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.552864898989899,
          "width": 0.3929950980392156,
          "height": 0.013790404040404103,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5691489898989899,
          "width": 0.20142156862745103,
          "height": 0.011343434343434322,
          "page": 2
        }
      ]
    },
    {
      "text": "Sense of agency matters for digital wellbeing in at least three ways.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1372348484848485,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08736437908496732,
          "top": 0.1510719696969697,
          "width": 0.034156862745098035,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Study 1 examines how existing mechanisms in the YouTube mobile app support or undermine sense of agency ( RQ1 ).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4995126262626262,
          "width": 0.39256045751633983,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5133270202020203,
          "width": 0.30318627450980395,
          "height": 0.011343434343434322,
          "page": 2
        }
      ]
    },
    {
      "text": "At present, design researchers have innovated many tools on the external side of the spectrum, that monitor and police multiple apps in the same way [27, 56, 57, 79, 86].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7905631313131313,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8044002525252526,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8182373737373737,
          "width": 0.21451470588235294,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To obtain a general sample of users of the YouTube mobile app, we recruited from Amazon Mechanical Turk workers in the United States.",
      "bboxes": [
        {
          "left": 0.6417385620915033,
          "top": 0.6127234848484848,
          "width": 0.27035130718954237,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.519109477124183,
          "top": 0.626560606060606,
          "width": 0.39336601307189534,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6403977272727273,
          "width": 0.17248366013071892,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "Participants answered questions in an online survey.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.42104545454545456,
          "width": 0.32447875816993454,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "RQ1 , one question table asked about things that made participants feel most in control of how they spend their time on YouTube (See Table 2 ).",
      "bboxes": [
        {
          "left": 0.6234117647058823,
          "top": 0.5040441919191919,
          "width": 0.2886862745098039,
          "height": 0.011343434343434322,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5179040404040404,
          "width": 0.3925669934640523,
          "height": 0.011332070707070652,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5317184343434344,
          "width": 0.16295915032679742,
          "height": 0.011343434343434322,
          "page": 3
        }
      ]
    },
    {
      "text": "We conducted a coding reliability thematic analysis [12, 15], in which we first established reliable codes for design mechanisms and then used them to generate themes that captured shared meanings.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.797159090909091,
          "width": 0.393263071895425,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5189918300653594,
          "top": 0.8109962121212121,
          "width": 0.3931013071895426,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8248333333333334,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8386704545454545,
          "width": 0.028736928104575177,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Participants spent a median of 101 minutes per day (interquartile range: 57-156) on YouTube across all devices in the week prior to the survey.",
      "bboxes": [
        {
          "left": 0.20840032679738563,
          "top": 0.6967916666666667,
          "width": 0.27234150326797385,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7106287878787878,
          "width": 0.3925588235294118,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7244659090909091,
          "width": 0.1751209150326798,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "A total of 120 participants met the inclusion criteria and completed the survey (see demographics in Table 1 ).",
      "bboxes": [
        {
          "left": 0.22288888888888886,
          "top": 0.5514810606060606,
          "width": 0.26005065359477136,
          "height": 0.011343434343434322,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5653181818181818,
          "width": 0.39256045751633994,
          "height": 0.011343434343434322,
          "page": 3
        },
        {
          "left": 0.08752450980392157,
          "top": 0.579155303030303,
          "width": 0.015256535947712424,
          "height": 0.011343434343434322,
          "page": 3
        }
      ]
    },
    {
      "text": "In summary, recommendations were the most frequently mentioned mechanism, accounting for 27% of all responses.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6611414141414141,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6749772727272727,
          "width": 0.321609477124183,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We further limited coding to responses that specified a mechanism within the interface of the YouTube mobile app, i.e., something the apps designers could directly change.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.43723358585858585,
          "width": 0.37875000000000003,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.45106944444444447,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4649065656565657,
          "width": 0.24682026143790853,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The design mechanisms we identified in the YouTube mobile app informed three higher-level themes.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.7856742424242424,
          "width": 0.39299509803921573,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7995113636363635,
          "width": 0.21192320261437914,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Non-consent was often felt as a result of (perceived) deception.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7626742424242424,
          "width": 0.37853104575163377,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Participants sense of agency depended on whether it felt like they had agreed to the actions of the app.",
      "bboxes": [
        {
          "left": 0.2826960784313725,
          "top": 0.7834305555555555,
          "width": 0.20025000000000004,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7972664141414141,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8111035353535354,
          "width": 0.04627614379084967,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Given their mixed experiences with recommendations, participants expressed frustration with the customization settings at their disposal (or lack thereof).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7806553030303031,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7944924242424243,
          "width": 0.39283333333333337,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8083282828282828,
          "width": 0.15861601307189543,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "For relevant recommendations, participants control responses were divided nearly 50-50.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4624040404040404,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5189918300653594,
          "top": 0.4762411616161616,
          "width": 0.1656846405228759,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Notifications sometimes supported planning and sometimes not.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1925820707070707,
          "width": 0.37854248366013077,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "By contrast, sense of agency was diminished by mechanisms that prompted and pressured participants with suggestions that were hard to decline.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.850010101010101,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8638472222222222,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8776843434343434,
          "width": 0.09282189542483661,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Irrelevant recommendations, i.e., those that were repetitive or unrelated to personal interests, universally undermined sense of agency:  Seeing recommended videos that have nothing to do with my viewing history leads to unwanted scrolling and possibly unwanted content.  Similarly, irrelevant search results undermined control because they forced participants to keep scrolling for what they wanted, e.g.,  I use specific search terms, but I still have to scan past a lot of vaguely or even unrelated stuff to find what I want.",
      "bboxes": [
        {
          "left": 0.5493235294117647,
          "top": 0.35170833333333335,
          "width": 0.3627663398692811,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.36554545454545456,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3793813131313132,
          "width": 0.392563725490196,
          "height": 0.011332070707070652,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.39322979797979796,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4070555555555555,
          "width": 0.39255555555555555,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4208926767676767,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.43472979797979794,
          "width": 0.39255882352941174,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.44856691919191916,
          "width": 0.3743447712418301,
          "height": 0.011332070707070763,
          "page": 6
        }
      ]
    },
    {
      "text": "Participants felt more in control when they planned their consumption in advance.",
      "bboxes": [
        {
          "left": 0.22577287581699346,
          "top": 0.5871073232323232,
          "width": 0.2550702614379085,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6009444444444444,
          "width": 0.2257794117647059,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "A minority of responses described recommendation settings that do support sense of agency.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.275604797979798,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2894419191919192,
          "width": 0.19744771241830067,
          "height": 0.011332070707070707,
          "page": 7
        }
      ]
    },
    {
      "text": "We note that although our research focuses at the level of design mechanisms, the details of these designs matter.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4001376262626263,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4139747474747475,
          "width": 0.31480555555555556,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In preparation for the evaluation co-design activity, five of the authors (KL, HZ, JVL, JC, KF), all advanced-degree students in a technology design program, created mockups of changes to mechanisms in the YouTube mobile app that we expected to impact sense of agency.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7120984848484848,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7259356060606061,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7397727272727272,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7536098484848486,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7674469696969697,
          "width": 0.05879575163398694,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Study 1 identified existing mechanisms in the YouTube mobile app that influence user sense of agency ( RQ1 ).",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5297020202020202,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5435164141414142,
          "width": 0.2572728758169935,
          "height": 0.011343434343434322,
          "page": 7
        }
      ]
    },
    {
      "text": "We recruited YouTube users in Seattle via email lists and social media channels to  Help us understand how people spend their time in the YouTube mobile app.  We did not initially set inclusion criteria for participation (beyond adult YouTube users) as we viewed our co-design activities as exploratory.",
      "bboxes": [
        {
          "left": 0.6377483660130719,
          "top": 0.6102083333333334,
          "width": 0.2743513071895425,
          "height": 0.011320707070706981,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6240454545454546,
          "width": 0.39255392156862734,
          "height": 0.011332070707070652,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6378825757575757,
          "width": 0.39255882352941185,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.651719696969697,
          "width": 0.3934460784313726,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6655568181818181,
          "width": 0.3146944444444444,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "We used codebook thematic analysis to analyze the data [13, 15], wherein we generated themes that are more interpretive than just a summary of all of the data, but less interpretive than in reflexive thematic analysis where the researchers subject position plays a central role in the analysis [14].",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.6724747474747476,
          "width": 0.394874183006536,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08736437908496732,
          "top": 0.6863118686868687,
          "width": 0.39310457516339875,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7001489898989899,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7139861111111111,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7278232323232323,
          "width": 0.19085620915032686,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Toelicitparticipant-generated ideas, we asked participants to sketch over paper mockups of three key screens: home, search, and video player (see Figure 3 ).",
      "bboxes": [
        {
          "left": 0.309656862745098,
          "top": 0.2790631313131313,
          "width": 0.175468954248366,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.29290025252525254,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.30671464646464647,
          "width": 0.35923856209150323,
          "height": 0.011343434343434322,
          "page": 9
        }
      ]
    },
    {
      "text": "Sessions included an initial think-aloud demonstration of their current YouTube use, followed by sketching and evaluation codesign activities.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.1268560606060606,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.14069318181818183,
          "width": 0.39502941176470585,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.15453030303030305,
          "width": 0.10146895424836604,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "We generated two themes about how participants expected changes to the design mechanisms of YouTube would affect their sense of agency.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.7205025252525253,
          "width": 0.39326470588235296,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7343396464646464,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7481767676767678,
          "width": 0.043777777777777804,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "To receive feedback on our changes from YouTube users, we asked participants to evaluate our mockups of the redesigned mechanisms in the YouTube mobile app (see Table 5 ).",
      "bboxes": [
        {
          "left": 0.321062091503268,
          "top": 0.49353661616161615,
          "width": 0.15967810457516346,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5073737373737374,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5212108585858586,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.0874656862745098,
          "top": 0.5350252525252526,
          "width": 0.08199999999999998,
          "height": 0.011343434343434322,
          "page": 9
        }
      ]
    },
    {
      "text": "When individual participants reviewed the different versions of their own sketches and our mockups, they were often conflicted about how much control they preferred.",
      "bboxes": [
        {
          "left": 0.7896225490196079,
          "top": 0.8242803030303031,
          "width": 0.12494281045751632,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8381174242424242,
          "width": 0.39255718954248375,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8519545454545455,
          "width": 0.39255555555555544,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8657916666666666,
          "width": 0.09051633986928109,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "In a modified version of a think-aloud-protocol [53], the participant opened YouTube on their smartphone and talked us through a typical engagement cycle (how they start and stop use) [115].",
      "bboxes": [
        {
          "left": 0.42024673202614377,
          "top": 0.1891237373737374,
          "width": 0.06268790849673206,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20295959595959595,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08748039215686274,
          "top": 0.21679671717171717,
          "width": 0.39545424836601306,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.23063383838383839,
          "width": 0.32369444444444445,
          "height": 0.011320707070707037,
          "page": 9
        }
      ]
    },
    {
      "text": "Together, our two studies identify design mechanisms that influence sense of agency in the YouTube mobile app and how they might be changed to increase it.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.5410227272727273,
          "width": 0.3930065359477125,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5548598484848485,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5686969696969697,
          "width": 0.13137581699346412,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Sometimes participants held intentions with a moderate level of specificity, in which case participants wanted to retain some control but also delegate some to YouTube.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3447891414141414,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3586262626262626,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.37246338383838384,
          "width": 0.21701633986928104,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We expect that our findings on how design mechanisms influence sense of agency on YouTube are most likely to generalize to other social media and media apps where users",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8315997474747474,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8454368686868687,
          "width": 0.39283660130718945,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8592739898989898,
          "width": 0.24844444444444447,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "When participants envisioned and evaluated changes in Study 2, they wanted more opportunities to make active choices, rather than respond to a set of choices proposed by the app.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7347411616161615,
          "width": 0.3778872549019606,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7485782828282829,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.762415404040404,
          "width": 0.2935,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "More choice alone did not lead to more control.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.37246338383838384,
          "width": 0.28865849673202604,
          "height": 0.011332070707070707,
          "page": 10
        }
      ]
    },
    {
      "text": "For participants, specific intentions varied from watching a video of a favorite dance, to the latest basketball highlight, to a tutorial on solving a Rubiks Cube.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1510719696969697,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1649078282828283,
          "width": 0.39255718954248364,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17874494949494948,
          "width": 0.16326307189542488,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "The Study 1 theme Spectrum of consent addressed whether the user had agreed to an action taken by the app (e.g., autoplaying the next video).",
      "bboxes": [
        {
          "left": 0.29384313725490196,
          "top": 0.7253068181818182,
          "width": 0.1866225490196079,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7391439393939394,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7529810606060606,
          "width": 0.27265359477124185,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "By contrast, when participants had only a non-specific intention (e.g., to unwind or explore), they wanted YouTube to lead the way.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5385075757575758,
          "width": 0.37875490196078443,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.552344696969697,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08736437908496732,
          "top": 0.5661818181818182,
          "width": 0.028109477124183005,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Our findings call for rethinking what relevance means for recommendations in the context of digital wellbeing.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5435391414141414,
          "width": 0.3787598039215686,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5573762626262626,
          "width": 0.3030800653594771,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "However, it does suggest that recommender systems could first start with the global problem of when to show recommendations, before moving on to the local problem of which items to recommend.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.695746212121212,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7095833333333333,
          "width": 0.3941764705882353,
          "height": 0.011332070707070763,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7234204545454544,
          "width": 0.39503104575163406,
          "height": 0.011332070707070763,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7372575757575758,
          "width": 0.03596732026143791,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Whereas both of the studies in this work elicit user preferences (what users say), the dominant paradigm of recommender systems today, including YouTube, is behaviorism: recommendations largely neglect explicit preferences and instead rely on behavior traces (what users do) [37].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1510719696969697,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.51909477124183,
          "top": 0.1649078282828283,
          "width": 0.3954787581699347,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17874494949494948,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1925820707070707,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.20641919191919192,
          "width": 0.17385784313725483,
          "height": 0.011320707070707037,
          "page": 11
        }
      ]
    },
    {
      "text": "Second, recommendations were sometimes too relevant, which presents a more vexing problem from a digital wellbeing perspective.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3636578282828283,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3774949494949495,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "First, recommendations were sometimes irrelevant, showing videos that participants were simply not interested in.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.28063636363636363,
          "width": 0.3762745098039215,
          "height": 0.011320707070707037,
          "page": 11
        },
        {
          "left": 0.08753921568627451,
          "top": 0.29447348484848485,
          "width": 0.33244444444444443,
          "height": 0.011320707070707037,
          "page": 11
        }
      ]
    },
    {
      "text": "Participants also wanted to customize the content of recommendations, e.g.,  I do not want my entire screen to recommend cat videos.  Today, the dominant paradigm of recommender systems, including YouTube, is behaviorism: recommendations rely on behavior traces (what users do) and largely neglect explicit preferences (what users say).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.2894419191919192,
          "width": 0.3787598039215686,
          "height": 0.011332070707070707,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.30327777777777776,
          "width": 0.39421568627450987,
          "height": 0.011332070707070707,
          "page": 11
        },
        {
          "left": 0.51909477124183,
          "top": 0.317114898989899,
          "width": 0.3954787581699347,
          "height": 0.011320707070707037,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3309520202020202,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3447891414141414,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.51909477124183,
          "top": 0.3586262626262626,
          "width": 0.10907679738562093,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Behavior change researchers have long known that plans can help bridge the gap between intentions and behavior.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7347411616161615,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7485782828282829,
          "width": 0.28089869281045754,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Recommendations were mentioned by participants as undermining sense of agency far more times than any other design mechanism in the YouTube mobile app, suggesting that recommender systems [93] should be of central concern to digital wellbeing designers.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.19761363636363635,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.21145075757575757,
          "width": 0.39256535947712423,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2252878787878788,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.239125,
          "width": 0.3948169934640523,
          "height": 0.011320707070707065,
          "page": 11
        }
      ]
    },
    {
      "text": "To summarize, we encourage designers of recommender systems to think beyond just optimizing for the item that is most likely to be clicked, watched, or liked.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5661818181818182,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5800189393939394,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.593854797979798,
          "width": 0.1784918300653594,
          "height": 0.011320707070706981,
          "page": 11
        }
      ]
    },
    {
      "text": "These types of actions might be called microplanning, making lightweight plans that guide behavior for a short time, usually just a single session of use.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10956060606060607,
          "width": 0.3762794117647059,
          "height": 0.011320707070707065,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12339772727272727,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1372348484848485,
          "width": 0.12083660130718955,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Similarly, we hope that the concept of microplans encourages the use of behavior planning knowledge in the design of digital wellbeing tools.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.26176767676767676,
          "width": 0.3762761437908496,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.275604797979798,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08736437908496732,
          "top": 0.2894419191919192,
          "width": 0.09700163398692808,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "How might a single app support sense of agency for both ritualized and instrumental use?",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.792604797979798,
          "width": 0.3787549019607843,
          "height": 0.011320707070706981,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8064419191919192,
          "width": 0.1878578431372549,
          "height": 0.011332070707070763,
          "page": 12
        }
      ]
    },
    {
      "text": "We caution that the message of attention capture dark patterns should not be never X, but rather be careful when X.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8341161616161616,
          "width": 0.3762777777777778,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8479532828282828,
          "width": 0.3198415032679738,
          "height": 0.011332070707070763,
          "page": 12
        }
      ]
    },
    {
      "text": "In Study 2, participants suggested ways that the YouTube mobile app might be redesigned to increase sense of agency (e.g., by reducing the number of recommendations it displays).",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5297020202020202,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5435391414141414,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5573762626262626,
          "width": 0.29831209150326804,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "A second approach then is an interface that is personalized for the user based on a prediction model.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1925820707070707,
          "width": 0.3765588235294116,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.20641919191919192,
          "width": 0.2233643790849673,
          "height": 0.011320707070707037,
          "page": 12
        }
      ]
    },
    {
      "text": "Developing such a lingua franca of attention capture design patterns could be integrated into design education [43], influence designer thinking, and reputations, as is done by the name-andshame campaign of the darkpatterns.org website [16].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5573762626262626,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5712133838383838,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.585050505050505,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5988876262626263,
          "width": 0.3203496732026143,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Our findings address what and when to design to increase sense of agency.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4881906565656566,
          "width": 0.39256045751633983,
          "height": 0.011332070707070707,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5020277777777777,
          "width": 0.044820261437908515,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "In addition to the previously stated limitations of our participant sampling and focus on design mechanisms as a unit of analysis, our work also has at least four conceptual limitations that could be explored in future work.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.23660858585858588,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.25044570707070707,
          "width": 0.3941781045751635,
          "height": 0.011320707070707037,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2642828282828283,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2781199494949495,
          "width": 0.16204738562091503,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "Whereas a common approach to digital wellbeing is designing to reduce screentime, this work takes an alternative approach of designing to increase sense of agency.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.695746212121212,
          "width": 0.3932565359477125,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7095833333333333,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7234204545454544,
          "width": 0.22209803921568633,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "This work was funded in part by National Science Foundation award #1849955.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.18126136363636364,
          "width": 0.39299673202614394,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.5195343137254902,
          "top": 0.19509848484848485,
          "width": 0.10042320261437898,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    }
  ],
  "2102.00625": [
    {
      "text": "We conducted two survey studies (  =200 each) that collect the public perception on moral responsibility of AI and human agents in high-stakes scenarios.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6471944444444444,
          "width": 0.3762777777777778,
          "height": 0.013834595959596019,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6635454545454545,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6773825757575758,
          "width": 0.15184640522875825,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Most research on the responsibility gap has been normative in that they prescribed ethical principles and proposed solutions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.525175505050505,
          "width": 0.3762859477124183,
          "height": 0.011320707070706981,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5390126262626262,
          "width": 0.3590359477124182,
          "height": 0.011320707070706981,
          "page": 0
        }
      ]
    },
    {
      "text": "Our findings suggest that the eight notions of responsibility considered can be re-grouped into two clusters: one encompasses present-looking and forward-looking notions (e.g., responsibility-astask, as-power, as-authority, as-obligation), and the other includes backward-looking notions (e.g., blame, praise, liability) and causal",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.801915404040404,
          "width": 0.3766633986928104,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8157525252525253,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8295896464646464,
          "width": 0.39503104575163417,
          "height": 0.011332070707070763,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8434255050505051,
          "width": 0.392563725490196,
          "height": 0.011320707070706981,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8572626262626263,
          "width": 0.39256045751633994,
          "height": 0.011332070707070763,
          "page": 0
        }
      ]
    },
    {
      "text": "Who should be held responsible for the harm caused by artificial intelligence (AI)?",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.30378282828282827,
          "width": 0.39326960784313736,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3176199494949495,
          "width": 0.10039052287581696,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Max Planck Institute for Software",
      "bboxes": [
        {
          "left": 0.38862091503267976,
          "top": 0.19997853535353535,
          "width": 0.22438562091503272,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.783715909090909,
          "width": 0.3927761437908497,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7937790404040405,
          "width": 0.3925588235294118,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8038421717171718,
          "width": 0.39256045751633994,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8139065656565657,
          "width": 0.0767401960784314,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "Collective Goods",
      "bboxes": [
        {
          "left": 0.444359477124183,
          "top": 0.24526262626262624,
          "width": 0.11291013071895428,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "Nina Grgi-Hlaa nghlaca@mpi-sws.org Systems Max Planck Institute for Research on Germany",
      "bboxes": [
        {
          "left": 0.4309869281045752,
          "top": 0.16785732323232325,
          "width": 0.13965359477124184,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.42615849673202616,
          "top": 0.18488257575757575,
          "width": 0.14930882352941172,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.4736846405228758,
          "top": 0.2150732323232323,
          "width": 0.05425653594771246,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.377843137254902,
          "top": 0.2301679292929293,
          "width": 0.24593954248366007,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.47003104575163396,
          "top": 0.26035732323232325,
          "width": 0.061990196078431314,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "Meeyoung Cha mcha@ibs.re.kr Data Science Group, IBS School of Computing, KAIST Republic of Korea",
      "bboxes": [
        {
          "left": 0.7083970588235294,
          "top": 0.16785732323232325,
          "width": 0.12127124183006532,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.7172009803921569,
          "top": 0.18488383838383837,
          "width": 0.10397222222222213,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.6883545751633987,
          "top": 0.19997853535353535,
          "width": 0.1613545751633988,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.6728725490196078,
          "top": 0.2150732323232323,
          "width": 0.19280555555555556,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.710078431372549,
          "top": 0.2301679292929293,
          "width": 0.11790686274509798,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551742424242424,
          "width": 0.19444607843137257,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.6685997474747474,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM ISBN 978-1-4503-8096-6/21/05..",
      "bboxes": [
        {
          "left": 0.08750653594771242,
          "top": 0.8762979797979799,
          "width": 0.2073676470588235,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "Scanlon [85] has proposed moral responsibility to be a bipartite concept.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.593854797979798,
          "width": 0.3762794117647058,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6076919191919191,
          "width": 0.050869281045751655,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "In answering this question, some scholars have defended the existence of a (techno-)responsibility gap [68] for autonomous and selflearning systems.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5015593434343435,
          "width": 0.3787630718954248,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5153964646464647,
          "width": 0.39503594771241823,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5292335858585859,
          "width": 0.10558169934640527,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Although a clear separation is fuzzy, one may find two schools of thought on the responsibility gap issue.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6952777777777778,
          "width": 0.3762777777777777,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.709114898989899,
          "width": 0.2608774509803923,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Holding an agent responsible fulfills a wide range of social and legal functions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1372348484848485,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1510719696969697,
          "width": 0.09064705882352941,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Attributing responsibility to an entity can be both descriptive (e.g., causal responsibility) and normative (e.g., blameworthiness).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.718388888888889,
          "width": 0.3762745098039215,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.0874656862745098,
          "top": 0.7322260101010101,
          "width": 0.3952614379084967,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Theories of moral responsibility date back to Aristotle, who argued that an entity should satisfy both freedom and epistemic conditions to appropriately be ascribed to moral responsibility.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.46932196969696965,
          "width": 0.3930065359477124,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.48315909090909087,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4969962121212121,
          "width": 0.34623529411764714,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "AI systems and robots are being widely adopted across society.",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.3908636363636364,
          "width": 0.395328431372549,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "Responsibility can take many forms.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8290845959595959,
          "width": 0.2223366013071895,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "In comparing AI agents against human agents, we found a striking difference in the way people attribute responsibility.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1372348484848485,
          "width": 0.3787565359477124,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1510719696969697,
          "width": 0.32832352941176474,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "The findings of this study have several implications for the development and regulation of AI.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.30327777777777776,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08753921568627451,
          "top": 0.317114898989899,
          "width": 0.19660294117647062,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "Existing studies addressing how users might attribute blame to automated agents have mostly focused on robots.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8014103535353535,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152474747474748,
          "width": 0.3135294117647059,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "On the opposite side, some scholars propose autonomous systems could be held responsible per se [61].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.17874494949494948,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1925820707070707,
          "width": 0.24623202614379086,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "This study makes use of publicly available COMPAS data released by ProPublica [2] and considers the machine judgments as either an AI advisor (later in Study 1) or an AI decision-maker (in Study 2).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3580896464646465,
          "width": 0.3762794117647059,
          "height": 0.011320707070707037,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.37192550505050503,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.38576262626262625,
          "width": 0.3929460784313725,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.39959974747474747,
          "width": 0.014689542483660167,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The regulation of AI and robots poses new challenges to policymaking, as in the previously introduced techno-responsibility gap, which society must discuss at large [24].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.38630050505050506,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4001376262626263,
          "width": 0.3941699346405228,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08736437908496732,
          "top": 0.4139747474747475,
          "width": 0.24718137254901962,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We use 100 randomly selected cases from this dataset, the corresponding bail suggestions, and information about whether the defendant re-offended within two years of sentencing.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.46878535353535356,
          "width": 0.3787581699346404,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4826224747474748,
          "width": 0.392563725490196,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.496459595959596,
          "width": 0.3150718954248366,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "A growing number of HCI research has been devoted to understanding how people perceive algorithmic decisions and their consequences in society.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.6076919191919191,
          "width": 0.39555228758169936,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6215290404040403,
          "width": 0.3950424836601308,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6353661616161616,
          "width": 0.12615359477124183,
          "height": 0.011320707070707203,
          "page": 2
        }
      ]
    },
    {
      "text": "Likewise, other authors argue that society should hold humans responsible because doing so for a machine would be meaningless as it does not understand the consequences of their actions or the reactive attitudes towards them [89, 96], possibly undermining the definition of responsibility [47].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.10956060606060607,
          "width": 0.3950375816993464,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12339772727272727,
          "width": 0.3925637254901961,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1372348484848485,
          "width": 0.3925555555555555,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1510719696969697,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1649078282828283,
          "width": 0.1897156862745098,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "AI-based algorithms are now used to assist humans in various scenarios, including high-stakes tasks such as medical diagnostics [35] and bail decisions [2].",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.23355555555555554,
          "width": 0.39555065359477115,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.24739267676767676,
          "width": 0.39256045751633994,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.261229797979798,
          "width": 0.13639379084967318,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Ascribing responsibility is a complex moral and legal practice that encompasses various functions, entities, and social practices [71, 91].",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.6006426767676768,
          "width": 0.39306862745098037,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.614479797979798,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We employed a factorial survey design [107] and showed participants eight vignettes that described a defendant from the ProPublica dataset, information about who the advisor was (i.e., an AI program or a human judge), which advice they gave, what the judges final decision was, and whether the defendant committed a new crime within the next two years (i.e., re-offended).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8014103535353535,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8290845959595959,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.39256045751633983,
          "height": 0.011320707070706981,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5189918300653594,
          "top": 0.8705959595959595,
          "width": 0.27006862745098037,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Imagine that you read the following story in your local newspaper: A court in Broward County, Florida, is starting to use an artificial intelligence (AI) program to help them decide if a defendant can be released on bail before trial.",
      "bboxes": [
        {
          "left": 0.5594183006535948,
          "top": 0.7011868686868687,
          "width": 0.3142581699346406,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5594183006535948,
          "top": 0.7150239898989899,
          "width": 0.3127957516339869,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5594183006535948,
          "top": 0.7288611111111112,
          "width": 0.3127941176470589,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5594183006535948,
          "top": 0.7426982323232323,
          "width": 0.3127892156862746,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5594183006535948,
          "top": 0.7565353535353536,
          "width": 0.06567810457516343,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "To study how the perceived responsibility for bail decisions differs when judges are advised by the COMPAS tool or by another human judge, we considered the following scenario:",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6562891414141413,
          "width": 0.3930016339869281,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6701262626262626,
          "width": 0.393107843137255,
          "height": 0.011332070707070763,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6839633838383837,
          "width": 0.26607679738562084,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "ProPublica dataset does not provide this information.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.3772146464646465,
          "width": 0.32413562091503273,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We interviewed six demographically diverse respondents.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7784886363636363,
          "width": 0.338173202614379,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Bail decisions aim to procure a balance between protecting future victims, e.g., prevent further offenses, and to impede any unnecessary burdens towards the defendant, e.g., by ensuring that their rights are protected [43].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6124444444444445,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08753921568627451,
          "top": 0.6262815656565657,
          "width": 0.39540359477124176,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6401174242424242,
          "width": 0.39283986928104575,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6539545454545455,
          "width": 0.1516307189542484,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Each participant in the study was exposed to a random subset of four cases with human advice and another four with AI advice.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5017474747474747,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5155845959595959,
          "width": 0.3948104575163399,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Towards the end of the survey, we asked demographic questions (presented in Table 1).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7923244949494949,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8061616161616162,
          "width": 0.16550816993464051,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The respondents demographics are shown in Table 1.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.75989898989899,
          "width": 0.34034967320261444,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Third, we can quantify variations across vignette conditions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5056439393939395,
          "width": 0.3785310457516339,
          "height": 0.011320707070706981,
          "page": 5
        }
      ]
    },
    {
      "text": "We conducted a power analysis to calculate the minimum sample size.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.6353661616161616,
          "width": 0.3932549019607843,
          "height": 0.011320707070707203,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6492032828282828,
          "width": 0.025446078431372546,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "First, responsibility-as-answerability (i.e., the bar in the middle) was the notion ascribed the highest to both human and AI advisors and decision-makers, followed by responsibility-as-obligation, astask, as-authority, and as-power (i.e., the first four bars).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.27041540404040404,
          "width": 0.3771535947712418,
          "height": 0.011320707070707037,
          "page": 5
        },
        {
          "left": 0.5189918300653594,
          "top": 0.28425252525252526,
          "width": 0.3931062091503268,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2980896464646465,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3119267676767677,
          "width": 0.3460424836601307,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Our primary goal was to examine how people attribute responsibility to human and AI agents in high-stakes scenarios.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8290845959595959,
          "width": 0.3013153594771242,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "The respondents were remunerated US$10 .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.10704671717171718,
          "width": 0.26122222222222213,
          "height": 0.01383459595959595,
          "page": 5
        }
      ]
    },
    {
      "text": "Figure 2 shows how people attributed each notion of responsibility to AI and human agents in Study 1 (on the advisor role) and Study 2 (on the decision-maker role).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.22890404040404042,
          "width": 0.39293464052287597,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.24274116161616163,
          "width": 0.3929411764705881,
          "height": 0.011320707070707065,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2565782828282828,
          "width": 0.18272712418300652,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "Both Study 1 and Study 2 show consistent differences in responsibility attribution between agents, regardless of whether they informed a human judge (Study 1) or decided by themselves (Study 2).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7769734848484849,
          "width": 0.37875490196078443,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.790810606060606,
          "width": 0.39293464052287586,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8046477272727272,
          "width": 0.3929346405228758,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8184848484848485,
          "width": 0.014114379084967321,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Responsibility-as-answerability exhibits a marginal difference with respect to the agent type that assisted human judges in bail decisions; however, the same trend was not observed in Study 2.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7354633838383838,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5189918300653594,
          "top": 0.749300505050505,
          "width": 0.3931013071895425,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7631376262626263,
          "width": 0.3948202614379085,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "The second cluster includes causal responsibility, blame, praise, and liability  all of which were attributed to a similar degree to humans and AI.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6686628787878788,
          "width": 0.3778986928104576,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6825,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6963371212121212,
          "width": 0.09199183006535948,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Our findings indicate that participants who were presented with responsibility statements addressing the violation or protection of a defendants rights (e.g., It is the AI programs task to protect the rights of the defendant) were assigned higher responsibility levels across all notions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6152020202020202,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6290391414141414,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6428762626262626,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6567133838383837,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6705492424242425,
          "width": 0.10564215686274514,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Concerning the phrasing styles, our experiment design addressed responsibility-as-liability as the duty to compensate those harmed by a wrongful action.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8347070707070706,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.848544191919192,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.862381313131313,
          "width": 0.12855718954248369,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Participants perceived human judges and advisors as more responsible for their tasks than their AI counterparts (see the leftmost bars in Figure 3).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.3950424836601307,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8290845959595959,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.104233660130719,
          "height": 0.011320707070706981,
          "page": 7
        }
      ]
    },
    {
      "text": "So far, we have observed two clusters of responsibility concepts by their correlation.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5164558080808082,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5302929292929294,
          "width": 0.11759967320261437,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Judges should base their decisions on facts and be able to explain why they made such decisions.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6215290404040403,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08736437908496732,
          "top": 0.6353661616161616,
          "width": 0.1861258169934641,
          "height": 0.011320707070707203,
          "page": 8
        }
      ]
    },
    {
      "text": "The meanings ofresponsibility addressing the attributionof tasks and their requirements are descriptive in the sense that they should be addressed in the present tense [27], e.g., one is responsible for a task, or is in charge of it.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1372348484848485,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1510719696969697,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1649078282828283,
          "width": 0.39256699346405227,
          "height": 0.01133207070707068,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17874494949494948,
          "width": 0.1434624183006536,
          "height": 0.011332070707070735,
          "page": 8
        }
      ]
    },
    {
      "text": "A model that can explain our blameworthiness results is the Path Model of Blame, which proposes that blame is attributed through nested and sequential judgments of various aspects of the action and its agent [66].",
      "bboxes": [
        {
          "left": 0.8125604575163399,
          "top": 0.19556944444444443,
          "width": 0.09952941176470587,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.20940656565656565,
          "width": 0.39417810457516345,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.22324368686868687,
          "width": 0.395576797385621,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2370808080808081,
          "width": 0.3948169934640522,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Moreover, our results suggest that an AI without a human-inthe-loop, i.e., AI judges in Study 2, could be held at the same level of scrutiny as human decision-makers for their decisions.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.46932196969696965,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.48315909090909087,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4969962121212121,
          "width": 0.3184591503267974,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "Regarding the difference between advisors and decision-makers, we posit that the differences between human agents are caused by the level of control the latter has over its decision outcomes.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6907146464646465,
          "width": 0.3778954248366013,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.7045517676767676,
          "width": 0.3931013071895425,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.718388888888889,
          "width": 0.3948202614379085,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "One of the prominent findings of this work is the need of interpretable AI systems.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.38630050505050506,
          "width": 0.3950294117647059,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4001376262626263,
          "width": 0.11862581699346407,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Participants attributed lower levels of authority and power to AI.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.275604797979798,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.0873921568627451,
          "top": 0.2894419191919192,
          "width": 0.01740196078431372,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Our results from both studies show that AI and human agents are blamed to a similar degree.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.40312499999999996,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4169621212121212,
          "width": 0.18190522875816995,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "However, our results also indicate that AI decision-makers are not praised to the same level as human judges.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7875732323232324,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8014103535353535,
          "width": 0.28056535947712424,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Previous work has found that ones normative and epistemological values influence how explanations are comprehended [64].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7737361111111111,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7875732323232324,
          "width": 0.3948169934640523,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The extent to which praise was assigned to human and AI agents varied depending on whether one was an advisor or a decision-maker.",
      "bboxes": [
        {
          "left": 0.78465522875817,
          "top": 0.5800189393939394,
          "width": 0.12744281045751626,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.593854797979798,
          "width": 0.39255555555555555,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6076919191919191,
          "width": 0.2805833333333333,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The four rightmost bars in Figure 3 suggest that AI and human agents are ascribed similar levels of backward-notions of responsibility, namely blame, liability, praise, and causal responsibility.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.14320959595959595,
          "width": 0.39299673202614394,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.15704671717171717,
          "width": 0.39503594771241823,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1708838383838384,
          "width": 0.3724722222222223,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The results from our initial exploratory analysis in Section 4.1 show that trends found between causality and blame attributions across different phrasing styles do not directly transfer to liability judgments.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4369318181818182,
          "width": 0.3766143790849674,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.45076767676767676,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.464604797979798,
          "width": 0.3929362745098039,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4784419191919192,
          "width": 0.06481209150326796,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Our findings indicating that AI and human agents should be held liable to a similar level goes against previous work, which has found that people attribute punishment to AI systems to a lesser degree than their human counterparts [62].",
      "bboxes": [
        {
          "left": 0.292624183006536,
          "top": 0.28472474747474746,
          "width": 0.18783823529411764,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2985606060606061,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3123977272727273,
          "width": 0.3950326797385621,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.32623484848484846,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3400719696969697,
          "width": 0.060323529411764706,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Nonetheless, our study shows that AIs could also be held responsible for their actions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.1649078282828283,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17874494949494948,
          "width": 0.15754575163398687,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Regardingthestatementsaddressingthepreventionofre-offenses, we posit that the lower attribution of liability to both agents is caused by a variation of the problem of many hands. [102] Preventing defendants from re-offending does not rely solely on a judges decision but encompasses many other factors as discussed above.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.533790404040404,
          "width": 0.3829117647058824,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08736437908496732,
          "top": 0.5476275252525252,
          "width": 0.3931013071895425,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5614646464646464,
          "width": 0.39503431372549025,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08753921568627451,
          "top": 0.5753017676767677,
          "width": 0.3929232026143791,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5891376262626262,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6029747474747474,
          "width": 0.03737418300653596,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Our findings indicate that people believe humans are, and should be, responsible for the assigned tasks, regardless of whether they are advisors or decision-makers.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.75989898989899,
          "width": 0.3925588235294118,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7737361111111111,
          "width": 0.39294281045751633,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7875732323232324,
          "width": 0.18866339869281046,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The same argument could also be applied to the practice of blame [26].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10956060606060607,
          "width": 0.3762745098039215,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12339772727272727,
          "width": 0.06519934640522877,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "This paper discussed the responsibility gap posed by the deployment of autonomous AI systems [68] and conducted a survey study to understand how differently people attribute responsibility to AI and humans.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.7352411616161617,
          "width": 0.3954787581699347,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7490770202020202,
          "width": 0.39294281045751633,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7629141414141414,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7767512626262626,
          "width": 0.0777009803921569,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "A common concern raised by scholarly work is that blaming or punishing an AI system might lead to social disruptions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.46932196969696965,
          "width": 0.37655718954248363,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.48315909090909087,
          "width": 0.3315408496732025,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Study 1 was designed so that the judges decision always followed the advice given to reduce complexity in the vignette design.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.30327777777777776,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.317114898989899,
          "width": 0.3948153594771242,
          "height": 0.011320707070707037,
          "page": 10
        }
      ]
    },
    {
      "text": "The current research considered eight notions of responsibility from related work.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4416489898989899,
          "width": 0.3766617647058824,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.45548484848484855,
          "width": 0.10795751633986926,
          "height": 0.011320707070707037,
          "page": 10
        }
      ]
    },
    {
      "text": "The current study focused on AI systems currently being used to advise bailing decisions, which is an important yet specific application of these algorithms.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1372348484848485,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1510719696969697,
          "width": 0.3950441176470589,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1649078282828283,
          "width": 0.17654901960784314,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Our exploratory analysis identified two clusters of responsibility notions.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5661818181818182,
          "width": 0.37875490196078443,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5800189393939394,
          "width": 0.08516666666666668,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "As our results demonstrate, people may hold AI to a similar level of moral scrutiny as humans for their actions and harms.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6768775252525252,
          "width": 0.3765588235294117,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6907146464646465,
          "width": 0.3660686274509804,
          "height": 0.011320707070706981,
          "page": 10
        }
      ]
    },
    {
      "text": "This work was supported by the Institute for Basic Science (IBSR029-C2).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7692083333333333,
          "width": 0.3954787581699347,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7830454545454546,
          "width": 0.057856209150326784,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Table 2: Statements addressing all responsibility notions presented to participants in Study 1 and Study 2.",
      "bboxes": [
        {
          "left": 0.08742156862745099,
          "top": 0.3579103535353535,
          "width": 0.6905441176470588,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    }
  ],
  "2103.00912": [
    {
      "text": "Designing effective interactions and user interfaces often involves exploring two potentially high-dimensional spaces [65]: 1) The",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8844318181818183,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.783715909090909,
          "width": 0.3927761437908497,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7937790404040405,
          "width": 0.3925588235294118,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8038421717171718,
          "width": 0.39256045751633994,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8139065656565657,
          "width": 0.07863071895424838,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551742424242424,
          "width": 0.19444607843137257,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.5190522875816994,
          "top": 0.7611893939393939,
          "width": 0.1421470588235293,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Central to gesture elicitation studies is an in-depth analysis of the proposed data to find common behavior.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5062209595959596,
          "width": 0.3762859477124183,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5200580808080808,
          "width": 0.28002124183006527,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "The gesture elicitation paradigm was first introduced by Wobbrock et al.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.3678510101010101,
          "width": 0.3933790849673202,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.38168813131313134,
          "width": 0.02899836601307193,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "However, these measures rely on subjectively assessing the similarity of the observed gestures: They require researchers to group proposals into subgroups that they consider identical, which is usually done by manual annotation based on watching videos of the participants in the study [28, 39].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5615694444444445,
          "width": 0.3787565359477123,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5754065656565657,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5892436868686869,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6030795454545455,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6169166666666667,
          "width": 0.22236601307189552,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Several tools have been created for more effective and objective analyses.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.75989898989899,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.052919934640522914,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "The analysis concepts introduced in this work are built on previous work spanning HCI, machine learning and visual analytics.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.2525429292929293,
          "width": 0.3930065359477125,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5189918300653594,
          "top": 0.26638005050505054,
          "width": 0.3623774509803922,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "In this way, elicitation studies inform gestural interaction with user-driven exploration: Most studies focus on the human behaviour space and thus do not rely on a specific sensor; they typically video-record participants for manual gesture analysis (e.g. [14, 28]).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3447891414141414,
          "width": 0.3762777777777778,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3586262626262626,
          "width": 0.392562091503268,
          "height": 0.011332070707070707,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.37246338383838384,
          "width": 0.3929346405228758,
          "height": 0.011332070707070707,
          "page": 1
        },
        {
          "left": 0.08753921568627451,
          "top": 0.38630050505050506,
          "width": 0.39518300653594773,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Researchers then analyse these gesture proposals, compute measures to identify common proposals (e.g. [59, 66]), and decide on a set of gestures to be used in an interactive system, typically composed of the gestures with high agreement among participants (e.g. [56, 67]).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.275604797979798,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2894419191919192,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.30327777777777776,
          "width": 0.3950408496732026,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.317114898989899,
          "width": 0.3925637254901962,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.0874656862745098,
          "top": 0.3309520202020202,
          "width": 0.08011111111111112,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To address this, Vatavu [59] has recently proposed a new, datadriven approach: It employs a distance measure as an objective basis for assessing consensus in elicitation studies.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6584280303030303,
          "width": 0.3787630718954248,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6722651515151514,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6861022727272728,
          "width": 0.27102777777777776,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "These challenges motivate our work on new quantitative methods and tools for analyzing elicitation data.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7506742424242424,
          "width": 0.3787598039215686,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7645113636363637,
          "width": 0.25261437908496737,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "Although central to HCI, the field has developed few dedicated methods and tools for supporting the (joint) exploration of such user-sensor spaces (cf. [65]).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1510719696969697,
          "width": 0.3762761437908496,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1649078282828283,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17874494949494948,
          "width": 0.16877450980392156,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "While the concepts introduced in this paper also enable researchers to better annotate sequences, our focus lies in particular on the exploration of elicited gesture data.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8567588383838384,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.39283660130718945,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8844318181818183,
          "width": 0.24955718954248374,
          "height": 0.011332070707070652,
          "page": 1
        }
      ]
    },
    {
      "text": "Addressing this, we extend the computational toolbox for analyzing gesture elicitation data with these contributions:",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8198598484848484,
          "width": 0.3787565359477124,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8336969696969697,
          "width": 0.33052614379084966,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "While elicitation studies have become a widely used staple in the HCI toolbox, they still present challenges (cf. [51, 63]), including the need for manual data analysis .",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.42781186868686866,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4416489898989899,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.45548484848484855,
          "width": 0.20079738562091504,
          "height": 0.011332070707070652,
          "page": 1
        }
      ]
    },
    {
      "text": "Some researchers created specific visualizations to facilitate interpretation of the axes of a (2D) projection, to judge the variation of the data [27, 60] or the relative importance of the data attributes along an axis [31].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7322260101010101,
          "width": 0.3787516339869281,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7460618686868686,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.75989898989899,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7737361111111111,
          "width": 0.11516503267973856,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The most similar work to ours is GestureAnalyzer by Jang et al.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1925820707070707,
          "width": 0.37853758169934637,
          "height": 0.011332070707070735,
          "page": 2
        }
      ]
    },
    {
      "text": "Nebeling et al.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10956060606060607,
          "width": 0.08581535947712418,
          "height": 0.011320707070707065,
          "page": 2
        }
      ]
    },
    {
      "text": "Also related to our work are tools to analyze and visualize machine learned representations of complex data: Deep learning models are capable of learning human-understandable features of high-dimensional data: For example, Kingma and Welling [30] and Lawrence [33] sample multiple points from the learned space and visualize them to demonstrate that the learned space is continuous and smooth, but without providing interaction functionalities.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6076919191919191,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6215290404040403,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6353661616161616,
          "width": 0.3925653594771242,
          "height": 0.011320707070707203,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6492032828282828,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6630404040404041,
          "width": 0.39256535947712423,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08753921568627451,
          "top": 0.6768775252525252,
          "width": 0.39540359477124176,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6907146464646465,
          "width": 0.39481372549019605,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "A key challenge in visual analytics is the effective visualization of high-dimensional data.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.42781186868686866,
          "width": 0.3930686274509803,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4416489898989899,
          "width": 0.13426143790849676,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To the best of our knowledge, GestureMap is the first tool to use a latent variable model to analyze sensor-based motion data in the context of gesture elicitation studies.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8290845959595959,
          "width": 0.3762794117647058,
          "height": 0.011332070707070763,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8429217171717173,
          "width": 0.3925669934640522,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8567588383838384,
          "width": 0.24564542483660134,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The features in GestureMap were informed by close examination of the literature on gesture elicitation and related concepts and tools: We collected features",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.5919974747474748,
          "width": 0.3930032679738562,
          "height": 0.011332070707070652,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.605834595959596,
          "width": 0.3942908496732026,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5188316993464052,
          "top": 0.6196717171717171,
          "width": 0.12720915032679747,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We introduce a structured analysis approach based on a learned 2D gesture map, as realised in GestureMap .",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.505530303030303,
          "width": 0.39326470588235296,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5193674242424242,
          "width": 0.22743137254901957,
          "height": 0.011332070707070763,
          "page": 2
        }
      ]
    },
    {
      "text": "GestureMap addresses these needs as its 2D map shows observed gesture proposals and gives an idea of past behavior.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8429217171717173,
          "width": 0.3762745098039215,
          "height": 0.01133207070707054,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.3284248366013073,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Furthermore, some researchers indicated that participants may struggle to propose gestures, if they are unfamiliar with the gesture design space [9, 12, 46].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7875732323232324,
          "width": 0.3766666666666666,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8014103535353535,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.14316339869281047,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "GestureMap is fundamentally motivated by providing researchers with a visual overview of the elicited gesture space.",
      "bboxes": [
        {
          "left": 0.7355196078431372,
          "top": 0.7460618686868686,
          "width": 0.17695915032679743,
          "height": 0.011332070707070763,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.75989898989899,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.1304379084967321,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Related tools [24, 41] show a 3D skeleton view with animation.",
      "bboxes": [
        {
          "left": 0.7532826797385621,
          "top": 0.6967032828282829,
          "width": 0.15935620915032667,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7105404040404041,
          "width": 0.21068137254901964,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Exploratory analysis seeks to uncover structural patterns in the dataset, identify anomalies, and single-out outliers [53].",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7115795454545455,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7254166666666666,
          "width": 0.3388480392156864,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Following a cartographic approach [47], and in line with 2D projections in visual analytics (e.g. [27, 64]), we use a map metaphor to visually guide analysts through the elicited gesture space.",
      "bboxes": [
        {
          "left": 0.3033202614379085,
          "top": 0.5275631313131313,
          "width": 0.17962745098039218,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5414002525252525,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.0874656862745098,
          "top": 0.5552373737373737,
          "width": 0.3929934640522876,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5690744949494949,
          "width": 0.2095751633986928,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The two dimensions of the map do not have a direct predefined meaning yet emerge from elicited data.",
      "bboxes": [
        {
          "left": 0.2753316993464052,
          "top": 0.70122601010101,
          "width": 0.20514052287581697,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7150618686868686,
          "width": 0.39481535947712426,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Scatter or density plots can be projected onto the map (e.g. Figure 1b 1  and Figure 1c).",
      "bboxes": [
        {
          "left": 0.6683480392156863,
          "top": 0.3911401515151515,
          "width": 0.24375163398692812,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4045353535353535,
          "width": 0.2848218954248367,
          "height": 0.011762626262626308,
          "page": 3
        }
      ]
    },
    {
      "text": "Here we describe how users can interact with the map.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.2945,
          "width": 0.3285490196078432,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "A fundamentally new capability of GestureMap is that unseen poses or gestures (i.e. not proposed by participants) can be simulated by decoding arbitrary 2D points in the learned space.",
      "bboxes": [
        {
          "left": 0.7086470588235294,
          "top": 0.5569659090909092,
          "width": 0.20345261437908502,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5708030303030304,
          "width": 0.39293627450980395,
          "height": 0.011332070707070652,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5846401515151516,
          "width": 0.39255555555555555,
          "height": 0.011320707070706981,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5984772727272728,
          "width": 0.10775163398692811,
          "height": 0.011320707070706981,
          "page": 3
        }
      ]
    },
    {
      "text": "The first of many analysis steps often involves developing an overview of the data to understand its underlying properties: Researchers here often use statistical plots to summarize the data and to identify broad patterns.",
      "bboxes": [
        {
          "left": 0.6874803921568627,
          "top": 0.8429217171717173,
          "width": 0.2246078431372549,
          "height": 0.011320707070706981,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.39255555555555544,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8844318181818183,
          "width": 0.30276307189542484,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Prior work has extensively used scatter plots to analyze machine learned representations [35, 48].",
      "bboxes": [
        {
          "left": 0.3893316993464052,
          "top": 0.10956060606060607,
          "width": 0.0911290849673202,
          "height": 0.011320707070707065,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.12339772727272727,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1372348484848485,
          "width": 0.09372549019607844,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Villarreal-Narvaez et al.",
      "bboxes": [
        {
          "left": 0.2772614379084967,
          "top": 0.23096969696969696,
          "width": 0.1387745098039216,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The map supports pan and zoom and accordingly recomputes the grid of landmarks (small skeletons).",
      "bboxes": [
        {
          "left": 0.6586748366013072,
          "top": 0.3151464646464647,
          "width": 0.2559003267973856,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3289835858585859,
          "width": 0.36306699346405236,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Here, we describe the map concept in more detail.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5061073232323232,
          "width": 0.2988513071895425,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "For further inspection, one or more gestures can be selected (e.g. Figure 4) from a referents list of gesture proposals (Figure 1 3  ).",
      "bboxes": [
        {
          "left": 0.6888692810457516,
          "top": 0.49480808080808075,
          "width": 0.2232189542483659,
          "height": 0.011320707070707037,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.508645202020202,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5220404040404041,
          "width": 0.1940718954248366,
          "height": 0.011762626262626252,
          "page": 3
        }
      ]
    },
    {
      "text": "Complementary to the feature for postures, GestureMap accounts for the temporal nature of gesture data [24, 41] by offering linked animations of gesture paths (point moving on the path) and 3D skeletons (skeleton moving).",
      "bboxes": [
        {
          "left": 0.31870751633986927,
          "top": 0.3216111111111111,
          "width": 0.16423039215686275,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.33544823232323234,
          "width": 0.39255882352941174,
          "height": 0.011332070707070707,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3492840909090909,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.0874656862745098,
          "top": 0.3631212121212121,
          "width": 0.382171568627451,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Motivatedbysuchinterestsinrelated work[24, 36, 41], we include an export functionality to easily share analyses with other researchers.",
      "bboxes": [
        {
          "left": 0.22350653594771241,
          "top": 0.4337070707070707,
          "width": 0.27282189542483654,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4475441919191919,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08736437908496732,
          "top": 0.46138005050505054,
          "width": 0.13791013071895425,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "As larger data sets are expected in the future [1, 24, 41], we also provide an interactive clustering method to reduce manual workload for identifying similar gesture (sub)groups.",
      "bboxes": [
        {
          "left": 0.24276470588235294,
          "top": 0.38457702020202017,
          "width": 0.24017973856209152,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3984141414141414,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4122512626262626,
          "width": 0.39481535947712426,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Thus,bycomparingmultipleembeddedgesturepathsresearchers can visually assess gestures as similar or not.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7412828282828283,
          "width": 0.37739869281045757,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7551199494949494,
          "width": 0.26411111111111113,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Developing an Overview of the Gesture Space.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10957196969696971,
          "width": 0.27093464052287586,
          "height": 0.011320707070707065,
          "page": 4
        }
      ]
    },
    {
      "text": "This work motivates us to further explore data-driven measures of consensus: We follow a similar approach, but instead of regressing on the DTW distance values, and relying on pairwise comparisons, we directly compute an average sequence from all gesture proposals in a referent group, using DBA.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6177992424242424,
          "width": 0.3762794117647059,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6316363636363636,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6454734848484848,
          "width": 0.39503267973856215,
          "height": 0.011320707070707203,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.659310606060606,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6731477272727273,
          "width": 0.24893464052287584,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Spotting Clusters and Outliers.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.22945075757575756,
          "width": 0.17137581699346402,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The gesture map can serve as a common visual basis for such investigations: By projecting multiple gestures onto the map, researchers can evaluate each participants behavior individually.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6167487373737374,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6305858585858586,
          "width": 0.3950294117647059,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6444229797979798,
          "width": 0.3948202614379085,
          "height": 0.011320707070707203,
          "page": 4
        }
      ]
    },
    {
      "text": "Comparing Referents and Regions.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.32165530303030304,
          "width": 0.2019640522875817,
          "height": 0.011320707070707037,
          "page": 4
        }
      ]
    },
    {
      "text": "We employ the DTW Barycenter Averaging (DBA) algorithm by Petitjean et al.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.33764772727272724,
          "width": 0.3936405228758171,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.35148484848484846,
          "width": 0.08402777777777781,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Vatavu [59] were the first to propose a data-driven consensus measure that does not rely on human judgement of gesture similarity.",
      "bboxes": [
        {
          "left": 0.5190506535947712,
          "top": 0.45175505050505055,
          "width": 0.3955261437908497,
          "height": 0.011320707070707037,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.46559217171717177,
          "width": 0.3948104575163398,
          "height": 0.011320707070707037,
          "page": 4
        }
      ]
    },
    {
      "text": "Judging Densities and Overlap of Referents.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.41385984848484847,
          "width": 0.2436977124183006,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "After the initial data exploration it is often necessary to find concrete example for detected patterns.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5614015151515152,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5752386363636364,
          "width": 0.21201143790849675,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The gesture variance integrates well with GestureMap s visualization concept because this already displays the involved average gestures as visual elements.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8290845959595959,
          "width": 0.3787647058823529,
          "height": 0.011332070707070763,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.39502941176470574,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.19691666666666674,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The key local observation in elicitation data is to examine individual gesture proposals .",
      "bboxes": [
        {
          "left": 0.24758660130718954,
          "top": 0.5198901515151515,
          "width": 0.23287908496732027,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5337272727272727,
          "width": 0.28734150326797386,
          "height": 0.011332070707070763,
          "page": 4
        }
      ]
    },
    {
      "text": "We introduce the concept of an average gesture sequence as a new computational capability in the context of gesture elicitation.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.8567588383838384,
          "width": 0.39380065359477134,
          "height": 0.011332070707070763,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.36275163398692817,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "G  denotes the set of all gestures elicited for referent  .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7850593434343435,
          "width": 0.32715849673202624,
          "height": 0.013834595959596019,
          "page": 4
        }
      ]
    },
    {
      "text": "We then measure the DTW distance of every gesture proposal   for a referent  to the computed average gesture (i.e. barycenter) g  for  .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6869848484848484,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5188022875816993,
          "top": 0.6976085858585859,
          "width": 0.39416830065359487,
          "height": 0.014532828282828203,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7121439393939394,
          "width": 0.06887745098039222,
          "height": 0.013834595959596019,
          "page": 4
        }
      ]
    },
    {
      "text": "We next describe the technical approach in more detail.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.29272474747474747,
          "width": 0.33190359477124187,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We used a server-client architecture.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.20918686868686867,
          "width": 0.22589379084967331,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We consider four existing datasets: One explicit gesture elicitiation study by Vatavu [59], plus three datasets collected for gesture recognition systems [3, 7, 17].",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.477625,
          "width": 0.39325816993464047,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.49146212121212124,
          "width": 0.39503758169934633,
          "height": 0.011320707070707037,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5052979797979799,
          "width": 0.1395767973856209,
          "height": 0.011320707070706981,
          "page": 5
        }
      ]
    },
    {
      "text": "We trained the VAE on the poses (frames) of the mentioned dataset [59] which has 60 dimensions (20 body joints  ,, ).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.646435606060606,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6577588383838384,
          "width": 0.3698153594771243,
          "height": 0.013834595959596019,
          "page": 5
        }
      ]
    },
    {
      "text": "Here demonstrate the use of GestureMap in a walkthrough of an explorative analysis: Examining the gesture map, the center (Figure 2C) reveals start/end poses (standing upright, arms at rest).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.39256045751633994,
          "height": 0.01133207070707054,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.369954248366013,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We experimented with different numbers of hidden neurons  : Overall, reconstruction loss decreases for larger models, regularized by the KL-loss, leading to diminishing returns and a decision for  = 512 here.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7407815656565656,
          "width": 0.3780081699346405,
          "height": 0.013834595959596019,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7571325757575758,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7709684343434343,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5188758169934641,
          "top": 0.7822916666666667,
          "width": 0.08020915032679732,
          "height": 0.013834595959596019,
          "page": 5
        }
      ]
    },
    {
      "text": "Considering the literature, Jang et al.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.34331944444444445,
          "width": 0.22731535947712414,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "This dialog is unfolded with a button in Figure 1b 3  and lets users interactively cluster gesture proposals for a referent.",
      "bboxes": [
        {
          "left": 0.7261830065359477,
          "top": 0.10956060606060607,
          "width": 0.18591830065359483,
          "height": 0.011320707070707065,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.12295580808080808,
          "width": 0.39256209150326793,
          "height": 0.01176262626262628,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1372348484848485,
          "width": 0.14528104575163403,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We used a Variational Autoencoder (VAE) [13] to embed the data as a 2D gesture map.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.5910883838383838,
          "width": 0.39326797385620926,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.604925505050505,
          "width": 0.10685294117647048,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We implemented GestureMap as an analysis tool that integrates the described concepts of both the interactive gesture map (Section 3) and the DBA-based computations (Section 4).",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4997550505050505,
          "width": 0.39326470588235296,
          "height": 0.011332070707070707,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5135921717171718,
          "width": 0.39343790849673205,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.527429292929293,
          "width": 0.26556535947712423,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Being able to compute an average gesture enables the use of clustering methods that require average computations.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.18297348484848483,
          "width": 0.3950424836601307,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.19681060606060605,
          "width": 0.31004248366013076,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Figure 1 shows the UI; the following sections refer to the numbers in the figure.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5870050505050505,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6008421717171717,
          "width": 0.07420261437908494,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "This view shows different metrics, namely variances around the average gesture sequence per selected referent (Section 4.2), the distributions of DTW distances of proposals to their average gesture sequence, and nearest neighbor distances for a selected gesture.",
      "bboxes": [
        {
          "left": 0.29735947712418304,
          "top": 0.8290845959595959,
          "width": 0.18558823529411766,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8429217171717173,
          "width": 0.3928333333333333,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8567588383838384,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.3928398692810458,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8844318181818183,
          "width": 0.18832352941176472,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "This view either shows the raw skeleton recording or a reconstructed skeleton.",
      "bboxes": [
        {
          "left": 0.3861862745098039,
          "top": 0.7512689393939394,
          "width": 0.094562091503268,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7651060606060607,
          "width": 0.3796977124183007,
          "height": 0.011320707070706981,
          "page": 5
        }
      ]
    },
    {
      "text": "This view lists all referents and gesture proposals in a compact way as numbers for quick reference and selection.",
      "bboxes": [
        {
          "left": 0.31597875816993465,
          "top": 0.6872891414141413,
          "width": 0.16448856209150325,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7011262626262627,
          "width": 0.39293790849673205,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7149633838383838,
          "width": 0.13823856209150331,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Researchers can zoom, pan, and hover over the gesture map, and overlay a scatter plot or a density plot (e.g. Figure 1c) to explore individual or multiple gesture poses.",
      "bboxes": [
        {
          "left": 0.2893218954248366,
          "top": 0.6371477272727273,
          "width": 0.19115032679738558,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6509848484848485,
          "width": 0.3929411764705883,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6648219696969697,
          "width": 0.3947140522875817,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "As another such example, for throw ball , behavior can be categorized into four clusters: Most children used their right hand, others used two hands, and some kicked the ball.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7875732323232324,
          "width": 0.3787581699346404,
          "height": 0.011332070707070652,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8014103535353535,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.248,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We defined a consensus measure on this variability (Section 4.2): Comparing this variability between all referents, our results largely agree with Vatavu [59]: In particular, applaud, fly like a bird and hands up show high consensus while climb ladder, crouch, turn around have low consensus.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7416148989898991,
          "width": 0.37801633986928107,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7554520202020202,
          "width": 0.3929346405228758,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7692891414141415,
          "width": 0.3925604575163399,
          "height": 0.01133207070707054,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7831262626262626,
          "width": 0.3925588235294118,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7969633838383839,
          "width": 0.16762091503267978,
          "height": 0.01133207070707054,
          "page": 6
        }
      ]
    },
    {
      "text": "The variance plot in GestureMap (Figure 3 right) indicates that proposals for crouch and draw flower vary more than for draw circle and draw square .",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6862664141414142,
          "width": 0.3762843137254902,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7001035353535353,
          "width": 0.3925604575163399,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7139406565656566,
          "width": 0.1313823529411765,
          "height": 0.011332070707070763,
          "page": 6
        }
      ]
    },
    {
      "text": "Using overlays in GestureMap , we can identify similarity and differences between gestures across referents: For example, Figure 3 (left) shows that crouch, draw circle, draw flower, draw square share common behavior; their scatter points largely overlap in the region that encodes raised arm behavior.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6032449494949494,
          "width": 0.376281045751634,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6170820707070707,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6309191919191919,
          "width": 0.3925571895424837,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6447563131313131,
          "width": 0.39255392156862745,
          "height": 0.011320707070707203,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6585934343434343,
          "width": 0.24852124183006535,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Proposals for crouch form two main clusters (pink points in Figure 3 left), one in the region of starting poses, another in sitting/crouching regions.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8429217171717173,
          "width": 0.3925539215686275,
          "height": 0.01133207070707054,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8567588383838384,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.047060457516339874,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "To motivate a concrete example, citetJain2016 showed that observers can distinguish behavior of children and adults.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.618885101010101,
          "width": 0.3787581699346405,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6327222222222222,
          "width": 0.33888562091503277,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "The interviews lasted 80 minutes and were conducted via screensharing using Skype/Zoom, with GestureMap hosted online such that people could use it on their own computer.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6076919191919191,
          "width": 0.39546895424836603,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6215290404040403,
          "width": 0.39255882352941185,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6353661616161616,
          "width": 0.2973104575163399,
          "height": 0.011320707070707203,
          "page": 7
        }
      ]
    },
    {
      "text": "As a second example, we compared behavior diversity across datasets.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7157449494949495,
          "width": 0.3762777777777778,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.729580808080808,
          "width": 0.05136601307189541,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "The interviews had four parts:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7322260101010101,
          "width": 0.17818300653594765,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Other researchers noted that elicitation findings are spread across multiple venues and need to be consolidated [63].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5497007575757575,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5635378787878788,
          "width": 0.2927794117647059,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "To further evaluate GestureMap , we recruited eight HCI researchers (7 male, 1 female) from three universities via e-mail for remote think-alound and interview sessions.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.8290845959595959,
          "width": 0.39300326797385626,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.0874656862745098,
          "top": 0.8429217171717173,
          "width": 0.3929967320261438,
          "height": 0.011320707070706981,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8567588383838384,
          "width": 0.2256388888888889,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For a typical elicitation study, such as this one by Vatavu [59], it is reasonable to expect clusters induced by the referents.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.1268560606060606,
          "width": 0.39255718954248364,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.14069318181818183,
          "width": 0.3278055555555555,
          "height": 0.011320707070707065,
          "page": 7
        }
      ]
    },
    {
      "text": "Overall, this indicates the potential of automated clustering, for example, when examining data from open elicitation with no given referents.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.3810126262626263,
          "width": 0.3928333333333333,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3948497474747475,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4086868686868687,
          "width": 0.05636274509803922,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In another experiment, we applied clustering to look for patterns within a referent: As mentioned, referents such as throw ball and crouch contained distinct patterns, revealed on the map.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4225227272727272,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08736437908496732,
          "top": 0.43635984848484843,
          "width": 0.3931013071895425,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.45019696969696965,
          "width": 0.3451813725490196,
          "height": 0.011332070707070763,
          "page": 7
        }
      ]
    },
    {
      "text": "Concretely, we ran the clustering with 15 sequences chosen randomly.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.19604166666666664,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20987878787878786,
          "width": 0.05992973856209148,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "However, the resulting computed centroids often deviated from peoples expectations, and thus did not immediately make sense to them.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.33016666666666666,
          "width": 0.3762777777777778,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3440037878787879,
          "width": 0.3925637254901959,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.35783964646464644,
          "width": 0.05133333333333323,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Overall, after being asked to give a final verdict over the interactive clustering feature, all deemed it important.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.44086237373737375,
          "width": 0.3787581699346404,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.45469949494949496,
          "width": 0.3004493464052287,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "When study participants paused their exploration for a longer period, we inquired why that was the case.",
      "bboxes": [
        {
          "left": 0.32972549019607844,
          "top": 0.45095707070707075,
          "width": 0.15074019607843142,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.46479419191919197,
          "width": 0.39255718954248364,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08736437908496732,
          "top": 0.4786313131313132,
          "width": 0.07427450980392157,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "GestureMap builds on and extends functionalities of previous tools for gesture elicitation: It combines",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.593854797979798,
          "width": 0.39255555555555555,
          "height": 0.011332070707070652,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6076919191919191,
          "width": 0.20948529411764716,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Alternatively, Ali et al.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.718388888888889,
          "width": 0.13441503267973853,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "Finally, the toolbox in the literature includes several formalized agreement measures [56, 67].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8429217171717173,
          "width": 0.3787549019607843,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.2058954248366014,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Seeing this and related work as a toolbox, researchers may now consider various options: For example, AGATE 2.0 [61] is a highly specialized tool to compute agreement, which assumes a given labeled dataset.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6492032828282828,
          "width": 0.3766633986928104,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6630404040404041,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6768775252525252,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907146464646465,
          "width": 0.1291928104575164,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "Upon first use, most people immediately animated a few gestures, saying that this was the most natural and familiar way to view the data Since the map visualization was unfamiliar to them, some had initial difficulties to understand the distinction of single poses (points) and entire gestures (paths).",
      "bboxes": [
        {
          "left": 0.20004901960784316,
          "top": 0.16968813131313132,
          "width": 0.282890522875817,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.18352525252525254,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.19736237373737375,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.21119949494949497,
          "width": 0.39255555555555555,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2250366161616162,
          "width": 0.3552303921568628,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "We asked the researchers to analyze the proposals for crouch and throw ball .",
      "bboxes": [
        {
          "left": 0.2714346405228758,
          "top": 0.34491540404040405,
          "width": 0.2090375816993464,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.35875252525252527,
          "width": 0.23421732026143793,
          "height": 0.011332070707070763,
          "page": 8
        }
      ]
    },
    {
      "text": "Next, they were asked to initialize the clustering algorithm using their knowledge from the previous task.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.27481818181818185,
          "width": 0.3787565359477123,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.28865530303030307,
          "width": 0.26421732026143785,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "Some found similar poses encoded in different map regions and noted that these should ideally reside in one area.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.575489898989899,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5893270202020202,
          "width": 0.2861258169934641,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Regardless of their initial analysis strategy, when asked which feature they would use to group the",
      "bboxes": [
        {
          "left": 0.2937924836601307,
          "top": 0.8705959595959595,
          "width": 0.1891437908496732,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8844318181818183,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Looking ahead, new cloud elicitation tools [2, 36] yield large datasets.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8014103535353535,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.05105882352941171,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "We asked people to use the interactive clustering tool based on their observations in the first task.",
      "bboxes": [
        {
          "left": 0.6898872549019608,
          "top": 0.2471439393939394,
          "width": 0.22220424836601316,
          "height": 0.011320707070707065,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.26098106060606063,
          "width": 0.3522238562091503,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "When we asked the participants what the main aspect was that they used to determine interesting behavioral patterns, we observed diverse analysis strategies, but we broadly highlight two main ones:",
      "bboxes": [
        {
          "left": 0.2615457516339869,
          "top": 0.6261830808080808,
          "width": 0.2189150326797385,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.640020202020202,
          "width": 0.39502941176470585,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6538573232323233,
          "width": 0.3925555555555555,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6676944444444444,
          "width": 0.19891666666666669,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "They stopped to examine gestures in more detail that differed largely from the shapes seen so far.",
      "bboxes": [
        {
          "left": 0.11983660130718955,
          "top": 0.7092058080808081,
          "width": 0.3606290849673203,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7230429292929292,
          "width": 0.21556699346405228,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Using expectations about possible behavior for a gesture proposal (e.g. left vs right hand throwing), they examined scatter points in those map regions that based on the landmark skeletons encoded related poses.",
      "bboxes": [
        {
          "left": 0.36933496732026144,
          "top": 0.806064393939394,
          "width": 0.11113071895424836,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8199015151515151,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8337386363636364,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8475757575757575,
          "width": 0.3613660130718954,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "A difficulty with k-means is setting the number of clusters.",
      "bboxes": [
        {
          "left": 0.2490816993464052,
          "top": 0.2978270202020202,
          "width": 0.231390522875817,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3116641414141414,
          "width": 0.1132140522875817,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Expert users especially liked the visual expressiveness of GestureMap , as it quickly summarizes the underlying dataset.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6102083333333334,
          "width": 0.3777450980392155,
          "height": 0.011332070707070652,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6240454545454546,
          "width": 0.3635163398692811,
          "height": 0.011332070707070652,
          "page": 9
        }
      ]
    },
    {
      "text": "Hand-engineered features [4, 24, 58] may help with the interpretation, however, they may be specific to a sensor and interaction setup.",
      "bboxes": [
        {
          "left": 0.26763888888888887,
          "top": 0.5147638888888889,
          "width": 0.21282679738562094,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5286010101010101,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5424381313131313,
          "width": 0.17657352941176468,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "As our key contribution, we presented a set of visualization and analysis concepts for gesture elicitation data and a tool that implements them: GestureMap is the first visual analytics tool for gesture elicitation which directly visualises the space of gestures, using a learned 2D embedding.",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.4995126262626262,
          "width": 0.39307189542483667,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5133497474747475,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.527185606060606,
          "width": 0.39283660130718956,
          "height": 0.011332070707070652,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5410227272727273,
          "width": 0.39417320261437905,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5548598484848485,
          "width": 0.17934477124183013,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "GestureMap and further materials are available on the project website: https://osf.io/dzn5g/",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7485782828282829,
          "width": 0.3762761437908495,
          "height": 0.011332070707070763,
          "page": 9
        },
        {
          "left": 0.5189918300653594,
          "top": 0.762415404040404,
          "width": 0.1733496732026144,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "A smooth latent space facilitates suitable visualization by reducing jumps in gesture paths.",
      "bboxes": [
        {
          "left": 0.3182745098039216,
          "top": 0.15007575757575758,
          "width": 0.1646601307189542,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.16391287878787877,
          "width": 0.3948169934640523,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "GestureMap could be extended to more than post-hoc analysis: For example, we could embed live sensor data and continuously update the underlying mode.",
      "bboxes": [
        {
          "left": 0.840735294117647,
          "top": 0.28945328282828287,
          "width": 0.07135784313725502,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.30327777777777776,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.317114898989899,
          "width": 0.39503921568627465,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3309520202020202,
          "width": 0.07204575163398697,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "This project is funded by the Bavarian State Ministry of Science and the Arts and coordinated by the Bavarian Research Institute for Digital Transformation (bidt).",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.8064419191919192,
          "width": 0.39299673202614394,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8202790404040403,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8341161616161616,
          "width": 0.19828594771241825,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "GestureMap empowers researchers to compare data across studies (cf. Section 6).",
      "bboxes": [
        {
          "left": 0.4091062091503268,
          "top": 0.667506313131313,
          "width": 0.0713578431372549,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6813320707070707,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "GestureMap could be extended to define new gestures: For example, users could draw a gesture as a path on the map.",
      "bboxes": [
        {
          "left": 0.37192320261437906,
          "top": 0.7875732323232324,
          "width": 0.1085424836601308,
          "height": 0.011332070707070652,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8014103535353535,
          "width": 0.3925604575163399,
          "height": 0.011332070707070763,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152474747474748,
          "width": 0.1908169934640523,
          "height": 0.01133207070707054,
          "page": 9
        }
      ]
    },
    {
      "text": "Here, we highlight model and clustering aspects to consider.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.1268560606060606,
          "width": 0.3605016339869282,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "So far, elicitation has focused on observed gestures, yet it might also be relevant to examine why behavior was not observed.",
      "bboxes": [
        {
          "left": 0.7876356209150327,
          "top": 0.15798989898989899,
          "width": 0.12445915032679744,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.17182702020202018,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.1856641414141414,
          "width": 0.2395228758169935,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Here we outline further ideas enabled or supported by GestureMap .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6442765151515152,
          "width": 0.3946633986928105,
          "height": 0.011332070707070652,
          "page": 9
        }
      ]
    }
  ],
  "2102.09087": [
    {
      "text": "In addition to a tap event (presence of a tap) alone, potentially useful tap properties include tap direction [20, 34] (i.e. whether the tap is on the front, back, or side of the phone), tap location [17, 21] (i.e. which region the tap falls on the devices), and tap finger part [9] (i.e. tapping with finger pad vs fingernail).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5661818181818182,
          "width": 0.3766666666666666,
          "height": 0.011332070707070652,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5800189393939394,
          "width": 0.39256209150326793,
          "height": 0.011332070707070652,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.593854797979798,
          "width": 0.39256045751633994,
          "height": 0.011332070707070652,
          "page": 0
        },
        {
          "left": 0.51909477124183,
          "top": 0.6076919191919191,
          "width": 0.393,
          "height": 0.011332070707070763,
          "page": 0
        },
        {
          "left": 0.51909477124183,
          "top": 0.6215290404040403,
          "width": 0.24478921568627465,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "After experimenting with multiple methods and architectures for tap detection, we found that a multi-input, multi-output (MIMO) convolutional neural network (CNN) gave the best results.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7737361111111111,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7875732323232324,
          "width": 0.393436274509804,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8014103535353535,
          "width": 0.34783660130718963,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Touchscreen as the sole method of mobile device input is increasingly challenged by its inherent limitations.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.6838851010101009,
          "width": 0.39547058823529413,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6977222222222222,
          "width": 0.26355228758169935,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Edge [23] of Google Pixel phones and long-press power button [30] of the iPhones for voice command invocation.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5385075757575758,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.552344696969697,
          "width": 0.27474999999999994,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551742424242424,
          "width": 0.19444607843137257,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8038421717171718,
          "width": 0.3927761437908497,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8139065656565657,
          "width": 0.3925588235294118,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8239696969696969,
          "width": 0.39256045751633994,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8340328282828282,
          "width": 0.07573529411764705,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.5623977272727273,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Our technical investigation and evaluation shed lights on two important aspects for machine learning (ML) in HCI development: methods and data.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1925820707070707,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20641919191919192,
          "width": 0.39429575163398695,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22025631313131314,
          "width": 0.11355882352941178,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "Second, we discuss an efficient data strategy for developing a ML based HCI application.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3586262626262626,
          "width": 0.3766666666666667,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.37246338383838384,
          "width": 0.13524019607843135,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To improve tap recognition, we develop a multi-input and multioutput a neural network that can estimate multiple tap properties.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.552344696969697,
          "width": 0.39547875816993483,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5661818181818182,
          "width": 0.3948137254901961,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "We are also the first to exploit the form factor of the phone as auxiliary information, which has been shown to be beneficial for training.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.75989898989899,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.39283986928104586,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7875732323232324,
          "width": 0.050532679738562125,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "More recently, researchers started to explore neural networks for tap location classification for PIN code inference in the field of privacy and security [17, 21].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3850429292929293,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.39888005050505054,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.41271590909090905,
          "width": 0.1955915032679738,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Our contribution is four-fold.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4969962121212121,
          "width": 0.17449509803921567,
          "height": 0.011320707070707037,
          "page": 1
        }
      ]
    },
    {
      "text": "Despite the line of research on detecting tapping from motion signals captured by the built-in IMU sensors on smartphones [8, 26, 39, 40], there is room for improvement.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.20516161616161616,
          "width": 0.39503431372549025,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.21899873737373737,
          "width": 0.39417156862745095,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5191977124183007,
          "top": 0.2328358585858586,
          "width": 0.20672549019607833,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "This study is related to off-screen interaction, in particular, tapbased interaction, as well as multi-task neural networks [3].",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.6561224747474748,
          "width": 0.39547875816993466,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6699583333333333,
          "width": 0.3576454248366014,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Back-of-device(BoD)[5,6,14,16]andedge-of-deviceinteractions[10,16,37,41]haveattractedmuchattention,however,mostofthemre-liedonspecializedsensorsthatarenotreadilyavailableonphones.Forinstance,BackXPressstudiedfingerpressureforBoDinterac-tionusingasandwichedsmartphone[5].",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.718388888888889,
          "width": 0.40365032679738566,
          "height": 0.1773636363636364,
          "page": 1
        }
      ]
    },
    {
      "text": "Moving beyond the prior work in this space, this project aims at developing IMU-based input methods that meet the requirement of practical applications, by means of deep neural network design and training.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.41399368686868687,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42783080808080803,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.44166792929292925,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4555037878787879,
          "width": 0.07841176470588236,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "As shown in Figure 2, the system listens to the six-channel IMU (three-axis accelerometer and three-axis gyroscope) data and maintains a 150-ms data window.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.7737361111111111,
          "width": 0.39307189542483656,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.0874656862745098,
          "top": 0.7875732323232324,
          "width": 0.3954754901960784,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8014103535353535,
          "width": 0.17245424836601309,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "As illustrated in Figure 2, a one-channel CNN is used for tap recognition.",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.8567588383838384,
          "width": 0.39554901960784306,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.03984150326797398,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "TapNet uses a multi-input and multi-output architecture.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.5160315656565656,
          "width": 0.34568300653594775,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The output of TapNet contains multiple branches.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5852171717171717,
          "width": 0.2890114379084967,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Training over an intersection of multiple tap tasks confines the learning in a restrained feature embedding space and thus allows it to converge to a solution for all related tasks [13].",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7374242424242424,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7512613636363636,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7650972222222222,
          "width": 0.3249934640522876,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Although TapNet is rather lightweight compared with vision-based convolutional networks, performing recognition per frame generates unnecessary overheads.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.4624040404040404,
          "width": 0.393078431372549,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4762411616161616,
          "width": 0.3950408496732026,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4900782828282828,
          "width": 0.1704771241830066,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Specifically, we first perform a simple, linear complexity peak detection on the gating signal at the per-frame level (Figure 2 the pink region).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6422853535353535,
          "width": 0.3766633986928104,
          "height": 0.011320707070706981,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6561224747474748,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6699583333333333,
          "width": 0.07692483660130721,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "We used a single researcher training strategy.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.4753042929292929,
          "width": 0.2723415032679739,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "This section describes two datasets: the one-person dataset (135,260 samples) was used for TapNet training only (not testing) and the multi-person dataset (38,545 samples) was for performance testing and user generalizability tuning.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.3062689393939394,
          "width": 0.3930065359477125,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3201060606060606,
          "width": 0.3925669934640522,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.33394318181818183,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.34778030303030305,
          "width": 0.20205718954248364,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Regarding the options between one-channel vs multi-channel network, we see that the one-channel network can be more efficient as it allows for filter reuse across IMU channels.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1925820707070707,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20641919191919192,
          "width": 0.3925604575163399,
          "height": 0.011320707070707037,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22025631313131314,
          "width": 0.3046633986928105,
          "height": 0.011320707070707037,
          "page": 3
        }
      ]
    },
    {
      "text": "All tap feature vectors are temporally aligned.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.17874494949494948,
          "width": 0.27521895424836595,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The advantages of this strategy are three-fold:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6275113636363636,
          "width": 0.2798676470588235,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Sensor system on smartphones provides motion data in a number of formats, including the raw signal, its gravity excluded counterpart, and rotation vector.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8014103535353535,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152474747474748,
          "width": 0.3941748366013072,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8290845959595959,
          "width": 0.11600490196078432,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "We repeated data collection under the same condition to mitigate bias.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7658813131313131,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7797184343434344,
          "width": 0.026289215686274514,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Overall, the multi-person dataset contains 38,545 taps, including 20,615 taps from front, 10,505 back, 1,705 left, 1,705 right, 1,975 top, and 2,040 bottom, among which 58.3% was collected on phones with rubber cases, and the rest without.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7083371212121212,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7221742424242424,
          "width": 0.39416830065359476,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7360113636363637,
          "width": 0.392563725490196,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.5189918300653594,
          "top": 0.7498484848484849,
          "width": 0.23716993464052294,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "This section evaluates the overall performance of TapNet, followed by the comparison between oneand multichannel CNN as well as ablation studies on the MIMO network design.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.7952462121212122,
          "width": 0.3930065359477125,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8090833333333333,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8229204545454546,
          "width": 0.29425,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "To evaluate TapNet performance, we collected a multi-person (n=31) dataset.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.6789924242424241,
          "width": 0.39388235294117646,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6928295454545454,
          "width": 0.04646078431372548,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We recruited 31 participants (13 female, age: 18-54).",
      "bboxes": [
        {
          "left": 0.6403071895424837,
          "top": 0.6253143939393939,
          "width": 0.2735196078431371,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.5191977124183007,
          "top": 0.6391515151515151,
          "width": 0.04034967320261429,
          "height": 0.011320707070706981,
          "page": 4
        }
      ]
    },
    {
      "text": "We used a 5.5\" Phone A and a 6.3\" Phone B throughout the collection.",
      "bboxes": [
        {
          "left": 0.6305179738562091,
          "top": 0.5478396464646464,
          "width": 0.2815751633986928,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5616767676767677,
          "width": 0.16214215686274502,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We measured classification performance by F1 score and regression by mean absolute error (MAE) and r 2 score.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8367575757575757,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.848125,
          "width": 0.3028300653594771,
          "height": 0.013790404040403992,
          "page": 4
        }
      ]
    },
    {
      "text": "The four grip gestures we studied are in a combination conditions of phone, grip gestures, and tapping actions as shown in Table 3.",
      "bboxes": [
        {
          "left": 0.2621470588235294,
          "top": 0.7737361111111111,
          "width": 0.21831209150326797,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7875732323232324,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8014103535353535,
          "width": 0.1729019607843138,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "TapNet: The Design, Training, Implementation, and Applications of a Multi-Task Learning CNN for Off-Screen Mobile Input",
      "bboxes": [
        {
          "left": 0.08759803921568628,
          "top": 0.07831565656565657,
          "width": 0.5804199346405229,
          "height": 0.008805555555555553,
          "page": 4
        }
      ]
    },
    {
      "text": "The MAE of tap location, i.e. [(      )/  ] 2 + [(      )/  ] 2 , is",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.8799696969696971,
          "width": 0.39299346405228763,
          "height": 0.013834595959595908,
          "page": 4
        }
      ]
    },
    {
      "text": "In the implementation, training to recognize the presence of tap event requires tap and non-tap data (e.g. phone shaking and rubbing motions).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.17874494949494948,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1925820707070707,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20641919191919192,
          "width": 0.10419607843137256,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "We applied ReLU and batch normalization after each convolutional layer and used Adam optimizer with a learning rate of 1e-4 and a momentum decay (1e-6).",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2894419191919192,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.30327777777777776,
          "width": 0.3928937908496733,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.317114898989899,
          "width": 0.18358169934640528,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "A close examination of the 35-class tap location classification reveals that TapNet can be usable despite its seemingly limited F1 score (0.34).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4507083333333333,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.46454545454545454,
          "width": 0.39289215686274515,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.47838257575757576,
          "width": 0.0702630718954248,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "The datasets were collected on Phone A and Phone B that ran on Android 9, and the IMU sampling rate was approximately 416Hz.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3586262626262626,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.0873921568627451,
          "top": 0.37246338383838384,
          "width": 0.3953284313725491,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Due to space limitation, we have put some of the implementation evaluations into the supplemental file.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.46932196969696965,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.48315909090909087,
          "width": 0.22496895424836605,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "This section evaluates TapNets improvement over prior art and user generalizability when training on one-person data.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5847361111111111,
          "width": 0.3929967320261438,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5985719696969697,
          "width": 0.33272385620915035,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Overall,MIMOTapNetsignificantlyoutperformsthepriorart[17, 19, 39].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7875732323232324,
          "width": 0.37868954248366016,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08756862745098039,
          "top": 0.8014103535353535,
          "width": 0.04160947712418302,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We implemented and trained four ML algorithms, including TapNet, to compare their relative performance.",
      "bboxes": [
        {
          "left": 0.30689052287581703,
          "top": 0.6215290404040403,
          "width": 0.1735669934640523,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6353661616161616,
          "width": 0.39256372549019614,
          "height": 0.011320707070707203,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6492032828282828,
          "width": 0.07934640522875817,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Table 4: Weighted average F1 score of four classification tasks (no color shading) as well as MAE and r 2 score of the tap location regression task (purple shading).",
      "bboxes": [
        {
          "left": 0.5190506535947712,
          "top": 0.24197979797979796,
          "width": 0.3930424836601307,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2533699494949495,
          "width": 0.392563725490196,
          "height": 0.013766414141414163,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2696527777777778,
          "width": 0.29470424836601306,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "By comparing the one-to-n-participant with the leave-one-out evaluation (see Table 5), we see that training on a one-person data can still be effective.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3980012626262626,
          "width": 0.3762875816993464,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.41183712121212124,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42567424242424245,
          "width": 0.11629901960784313,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Figure 6 gives the performance comparison.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8014103535353535,
          "width": 0.2755816993464052,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Multi-task learning contributes to tap direction classification, especially with a small amount (no more than 3K) of training samples.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.47524368686868684,
          "width": 0.3787630718954248,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.48908080808080806,
          "width": 0.3948153594771242,
          "height": 0.011320707070707037,
          "page": 6
        }
      ]
    },
    {
      "text": "To investigate cross-device model training, we evaluated model performance with incremental training samples from 1K to 15K, as previous experiments suggest that TapNet converges with around 15K training samples.",
      "bboxes": [
        {
          "left": 0.8275294117647058,
          "top": 0.6630404040404041,
          "width": 0.08456699346405228,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6768775252525252,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907146464646465,
          "width": 0.39502941176470585,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7045517676767676,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.718388888888889,
          "width": 0.0499232026143791,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "However, the performance difference on simple tasks (event and finger part classification) among different methods is marginal.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1649078282828283,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17874494949494948,
          "width": 0.36393137254901964,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "This section presents the ablation studies on the TapNet architecture: the use of multi-task learning (i.e. multi-output) and crossdevice training with auxiliary information (i.e. multi-input).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7945530303030303,
          "width": 0.3954771241830065,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8083901515151515,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8222272727272727,
          "width": 0.3684738562091503,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We hypothesized that training on diverse but one-person data can still achieve generalizability for unseen users in some tap recognition tasks.",
      "bboxes": [
        {
          "left": 0.4608888888888889,
          "top": 0.24095075757575757,
          "width": 0.019575163398692752,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2547878787878788,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.268625,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2824621212121212,
          "width": 0.03347712418300654,
          "height": 0.011320707070707037,
          "page": 6
        }
      ]
    },
    {
      "text": "We first present the evaluation on multi-task learning.",
      "bboxes": [
        {
          "left": 0.43372058823529414,
          "top": 0.8567588383838384,
          "width": 0.046750000000000014,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.26507679738562095,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Figure 7 shows the performance comparison of one-channel CNN against its multi-channel counterparts.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6182613636363636,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6320984848484849,
          "width": 0.26331209150326795,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "We also discovered encouraging generalizability across users when the model was trained (or \"taught\") by a one person.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6215290404040403,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6353661616161616,
          "width": 0.33982352941176475,
          "height": 0.011320707070707203,
          "page": 7
        }
      ]
    },
    {
      "text": "The other advantage of our approach is that an expert design could intentionally push the variations of an intentional tap gesture in terms of speed, strength, angle, and hand posture, However, it is possible certain recognition tasks, such as higher resolution tap location classification, could demand more fine-grained information only available in person-specific data.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7737361111111111,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7875732323232324,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8014103535353535,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152474747474748,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8290845959595959,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8429217171717173,
          "width": 0.21977777777777785,
          "height": 0.011320707070706981,
          "page": 7
        }
      ]
    },
    {
      "text": "To verify the efficacy of one-channel CNN for tap recognition, we performed a comparison on tap direction classification, which is a representative task and demonstrated to require subtle signal alignment across channels.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.4937285353535354,
          "width": 0.39299836601307186,
          "height": 0.011320707070707037,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5075656565656566,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5214027777777778,
          "width": 0.39503104575163406,
          "height": 0.011320707070706981,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5352386363636363,
          "width": 0.1299460784313725,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "We designed, developed, and evaluated a set of deep learning methods for on-device IMU signal based off-screen input, in particular TapNet, a multi-task network that allows for cross-device training",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.8567588383838384,
          "width": 0.395733660130719,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.3928398692810458,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.0874656862745098,
          "top": 0.8844318181818183,
          "width": 0.3929983660130719,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "ExplorativeTap is a two-handed interaction method that exploits signals from both the front (touch) and back of the phone tap (see Figure 9b).",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4781426767676768,
          "width": 0.3925669934640523,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.491979797979798,
          "width": 0.39256045751633983,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5058169191919192,
          "width": 0.06488725490196079,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "Without adding new sensor hardware, TapNet enables many new input possibilities on smartphones.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.7281805555555556,
          "width": 0.3938088235294118,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7420176767676767,
          "width": 0.20893790849673205,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Although evaluation results demonstrated that TapNet benefited from cross-device training, we do not expect the current TapNet trained on these two devices would directly apply to unseen devices without further training, i.e. a cross-device model.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5857664141414142,
          "width": 0.3762794117647059,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5996035353535354,
          "width": 0.39256372549019614,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6134406565656566,
          "width": 0.3925604575163399,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08736437908496732,
          "top": 0.6272777777777777,
          "width": 0.30757679738562094,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Inertial Touch estimates tap force from the IMU signals and tap location from the TapNet output.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8567588383838384,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.16966830065359473,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "TapNet opens up new interaction opportunities such as onehanded interaction that uses off-screen tapping or designated tap gestures.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.46123358585858587,
          "width": 0.3787549019607843,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.47507070707070703,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.48890782828282825,
          "width": 0.051759803921568606,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "Off-screen tap recognition makes it possible to interact with objects living in different interface layers, such as background targets that do not react to on-screen touch.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7158800505050504,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7297171717171718,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7435542929292929,
          "width": 0.19419771241830064,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "AssistiveTap allows users to complete a number of system interactions using back tap and tilting.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.8567588383838384,
          "width": 0.39555228758169936,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8705959595959595,
          "width": 0.1910686274509804,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The aforementioned use cases can be particularly useful in challenging situations when one-handed and non-contact interactions are preferable or required.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.20054924242424244,
          "width": 0.39547875816993466,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.21438636363636365,
          "width": 0.392562091503268,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22822348484848484,
          "width": 0.15478267973856208,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "This paper presents the design, training, implementation and application of TapNet for off-screen mobile input.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.37455934343434344,
          "width": 0.39547875816993466,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.38839646464646466,
          "width": 0.28138398692810457,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    }
  ],
  "2102.04174": [
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.7374621212121213,
          "width": 0.6999901960784314,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7500416666666667,
          "width": 0.5711470588235295,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "Previous work on this topic has mainly explored rule-based and model-based approaches (see Related Work).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.48395580808080807,
          "width": 0.6555490196078433,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Predicting the effects of teaching interventions on human learning is challenging, however.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.3628813131313131,
          "width": 0.5414035947712419,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Intelligent tutoring [2] addresses the problem of designing teaching interventions  any materials, practice, and feedback delivered by a teacher  for education objectives such as learning a new language or skill.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.22451136363636362,
          "width": 0.7003741830065358,
          "height": 0.01396969696969702,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.2418080808080808,
          "width": 0.5189248366013072,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "With this paper, we examine a model-based planning approach that holds potential for better adapting to individuals learning characteristics.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7261035353535353,
          "width": 0.6861911764705882,
          "height": 0.013935606060606065,
          "page": 1
        },
        {
          "left": 0.18000163398692812,
          "top": 0.74339898989899,
          "width": 0.17828267973856213,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.17951960784313725,
          "top": 0.12484217171717171,
          "width": 0.14214705882352946,
          "height": 0.010063131313131302,
          "page": 1
        }
      ]
    },
    {
      "text": "Myopic planning.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.49459848484848484,
          "width": 0.10113888888888889,
          "height": 0.011320707070707037,
          "page": 2
        }
      ]
    },
    {
      "text": "Offline optimization.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6282512626262626,
          "width": 0.12334803921568624,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Rule-based approaches define hand-crafted rules for deciding which learning events to trigger on the basis of the response data from the user.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.23329166666666667,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.25058838383838383,
          "width": 0.16536111111111113,
          "height": 0.011320707070707037,
          "page": 2
        }
      ]
    },
    {
      "text": "The problem of intelligent tutoring can also be formulated as that of maximizing learning over a sequence of learning events.",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.3755934343434344,
          "width": 0.7004297385620915,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.1200016339869281,
          "top": 0.3928888888888889,
          "width": 0.04249999999999997,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Planning as a POMDP.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7619040404040404,
          "width": 0.12873366013071894,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We assume that time is discrete.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.45393686868686867,
          "width": 0.1967826797385621,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Aiming to increase the learners knowledge, the teacher sets learning objectives.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.5750113636363636,
          "width": 0.48110620915032687,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Were the learner to have unbounded memory abilities, the optimal sequence of items would be to present each item once.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6269002525252525,
          "width": 0.6837222222222222,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6441957070707071,
          "width": 0.03125326797385622,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "We consider two agents interacting with each other: the learner and the teacher .",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.38475252525252523,
          "width": 0.4954215686274509,
          "height": 0.01393560606060612,
          "page": 3
        }
      ]
    },
    {
      "text": "In this paper, we propose an approach that builds on the literature described above and draws its contributions together in a single system, with",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.2162512626262626,
          "width": 0.7002810457516339,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.18000163398692812,
          "top": 0.2335479797979798,
          "width": 0.14509150326797385,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Memory models with exponential forgetting.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5343851010101011,
          "width": 0.26640686274509795,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "For solving Equation 1, our proposed technique is to model the overall teaching process for the teacher as a POMDP ( ,,,,  , ) , where  is the set of possible states and  the set of actions,  is a payoff function,  is the statetransition probability,  is the set of observations, and  :       [ 0 , 1 ] defines the probability  (  | , ) =  ( ,, ) .",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.1428800505050505,
          "width": 0.6999967320261438,
          "height": 0.011320707070707065,
          "page": 4
        },
        {
          "left": 0.12073366013071894,
          "top": 0.16017676767676767,
          "width": 0.7017385620915033,
          "height": 0.013041666666666646,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.17747222222222223,
          "width": 0.7022532679738562,
          "height": 0.01332449494949492,
          "page": 4
        }
      ]
    },
    {
      "text": "The psychologist is in charge of managing the memory model,   more specifically, with inferring its parameterization    and  (  | , ) , the probability of recall of item  in light of history  .",
      "bboxes": [
        {
          "left": 0.11956209150326796,
          "top": 0.48216414141414143,
          "width": 0.7029068627450981,
          "height": 0.011445707070707078,
          "page": 4
        },
        {
          "left": 0.1200016339869281,
          "top": 0.49946085858585854,
          "width": 0.4796078431372549,
          "height": 0.013041666666666618,
          "page": 4
        }
      ]
    },
    {
      "text": "Memory models with item-specific exponential forgetting.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.778,
          "width": 0.3283660130718954,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "For the item-counting reward (see Equation 4), myopic sampling induces straightforward behavior.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6599785353535353,
          "width": 0.5963398692810458,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "The reward: Counting the items learned.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4445113636363636,
          "width": 0.23627941176470582,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Planning algorithms: Conservative sampling.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7445366161616161,
          "width": 0.26818464052287583,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Inference methods: Bayesian belief updating.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.1712247474747475,
          "width": 0.26007516339869285,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "Planning algorithms: Myopic sampling.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6107386363636363,
          "width": 0.22496895424836602,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Here,   + 1  (  ) is the posterior probability of the parameter    and   (  ) the prior belief about this parameter.",
      "bboxes": [
        {
          "left": 0.18000163398692812,
          "top": 0.3193143939393939,
          "width": 0.6838545751633985,
          "height": 0.017898989898989914,
          "page": 5
        }
      ]
    },
    {
      "text": "The planner is in charge of selecting the optimal items to present with regard to achieving some fixed learning objective.",
      "bboxes": [
        {
          "left": 0.17956209150326796,
          "top": 0.41184343434343434,
          "width": 0.7026928104575164,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "At each interaction point, we assume that the teacher proceeds with Bayesian belief updating for the parameter  .",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.22046464646464647,
          "width": 0.6713235294117648,
          "height": 0.011445707070707078,
          "page": 5
        }
      ]
    },
    {
      "text": "At each iteration  , only one item can be selected, even though it may be time to review several items under the aforementioned criterion.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5691085858585858,
          "width": 0.6837238562091503,
          "height": 0.011445707070707023,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.586405303030303,
          "width": 0.15529575163398696,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "A classic implementation of this principle makes use of a box system: Each item    belongs to a box   N .",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.4826275252525252,
          "width": 0.6573888888888888,
          "height": 0.013041666666666674,
          "page": 6
        }
      ]
    },
    {
      "text": "The intuition behind the conservative-sampling algorithm is that we should avoid presenting a particular item when there is insufficient time for learning that item or when this choice would adversely affect learning of any item introduced earlier.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.12126010101010101,
          "width": 0.683720588235294,
          "height": 0.013969696969696965,
          "page": 6
        },
        {
          "left": 0.11945915032679738,
          "top": 0.13855555555555557,
          "width": 0.7009183006535948,
          "height": 0.011320707070707065,
          "page": 6
        },
        {
          "left": 0.1200016339869281,
          "top": 0.15585227272727273,
          "width": 0.14250653594771245,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Planning constraints: Learning with breaks.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.3067550505050505,
          "width": 0.25340359477124186,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We chose a Leitner system as the baseline, since this affords comparison with a popular adaptive approach.",
      "bboxes": [
        {
          "left": 0.11929738562091505,
          "top": 0.41344318181818185,
          "width": 0.6268545751633986,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "The artificial learners use the exponential forgetting model.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7433068181818181,
          "width": 0.36554575163398695,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "For the artificial learners, we chose a parameterization that is plausible for humans by running 400 exploratory simulations.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.31893055555555555,
          "width": 0.6841013071895424,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.3362272727272727,
          "width": 0.07173856209150323,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Parameterization.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.252395202020202,
          "width": 0.10513235294117648,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For the psychologist component of our system, the parameters are evaluated with a grid of size 100  100 (  : log scale bounded by [ 2e  7 , 2 . 5e  2 ] ;  : linear scale bounded by [ 0 . 0001 , 0 . 9999 ] ).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.4918939393939394,
          "width": 0.6837189542483659,
          "height": 0.013041666666666674,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.509189393939394,
          "width": 0.46491013071895415,
          "height": 0.013041666666666618,
          "page": 7
        }
      ]
    },
    {
      "text": "Each box plot extends from the lowest to the highest quartile of the frequencies observed (the central line denotes the median, and the whiskers refer to an IQR of 1.5).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7896363636363637,
          "width": 0.6837156862745097,
          "height": 0.011320707070706981,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.8069318181818183,
          "width": 0.31266666666666665,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "For the Leitner system,   = 4,   = 2, which means that items in box 0 should be reviewed after four seconds, items in box 1 eight seconds later, then 16 seconds, 32 seconds, etc.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.578375,
          "width": 0.6837205882352942,
          "height": 0.013455808080808151,
          "page": 7
        },
        {
          "left": 0.18000163398692812,
          "top": 0.5956704545454545,
          "width": 0.3633872549019608,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "In the non-item-specific condition with a non-omniscient psychologist (see Figure 2), the number of items learned is significantly greater for each model-based teacher relative to the baseline (M vs. L:  = 5976 . 5,  = 0 . 017,   = 0 . 033,  = 100  2; CS vs. L:  = 7401 . 5,  < 0 . 001,   < 0 . 001,  = 100  2).",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.742574494949495,
          "width": 0.6837140522875818,
          "height": 0.013935606060605954,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7598712121212121,
          "width": 0.7016078431372549,
          "height": 0.013324494949494947,
          "page": 8
        },
        {
          "left": 0.12007516339869281,
          "top": 0.7771666666666667,
          "width": 0.42127287581699346,
          "height": 0.013324494949494947,
          "page": 8
        }
      ]
    },
    {
      "text": "In the non-item-specific condition with an omniscient psychologist (see Figure 2), the simplest scenario under our framework, the number of items learned does not differ between the myopic (M) and Leitner (L) teachers (  = 5650 . 0,  = 0 . 110,   = 0 . 221,  = 100  2), while the conservative-sampling (CS) teacher significantly outperforms the Leitner one (  = 8539 . 0,  < 0 . 001,   < 0 . 001,  = 100  2).",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.6042045454545454,
          "width": 0.7002728758169934,
          "height": 0.013935606060606176,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6215012626262626,
          "width": 0.701609477124183,
          "height": 0.013324494949494947,
          "page": 8
        },
        {
          "left": 0.11970751633986927,
          "top": 0.6387967171717172,
          "width": 0.7002892156862746,
          "height": 0.013324494949494947,
          "page": 8
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6560934343434344,
          "width": 0.389343137254902,
          "height": 0.013324494949494947,
          "page": 8
        }
      ]
    },
    {
      "text": "In the item-specific condition with an omniscient psychologist (see Figure 3), the number of items learned is significantly greater for both model-based teachers as compared with the Leitner teacher (M vs. L:  = 10 , 000,  < 0 . 001,   < 0 . 001,  = 100  2; CS vs. L:  = 10 , 000,  < 0 . 001,   < 0 . 001,  = 100  2).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6560795454545455,
          "width": 0.6837173202614378,
          "height": 0.013935606060606065,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6733762626262626,
          "width": 0.7016078431372548,
          "height": 0.013324494949494947,
          "page": 9
        },
        {
          "left": 0.17970915032679738,
          "top": 0.690671717171717,
          "width": 0.5270473856209151,
          "height": 0.01332449494949517,
          "page": 9
        }
      ]
    },
    {
      "text": "When the framework is evaluated in the maximum-complexity condition  i.e., in the item-specific condition with a non-omniscient psychologist  the number of items learned is significantly greater for both the myopic and the conservative-sampling teacher relative to the Leitner teacher (M vs. L:  = 10 , 000,  < 0 . 001,   < 0 . 001,  = 100  2; CS vs. L:  = 8640,  < 0 . 001,   < 0 . 001,  = 100  2).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.742560606060606,
          "width": 0.6837173202614378,
          "height": 0.013935606060606065,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7598573232323232,
          "width": 0.6999950980392157,
          "height": 0.013935606060606176,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7771527777777778,
          "width": 0.7010375816993464,
          "height": 0.013324494949494947,
          "page": 9
        },
        {
          "left": 0.18000163398692812,
          "top": 0.7944494949494949,
          "width": 0.342468954248366,
          "height": 0.013324494949494947,
          "page": 9
        }
      ]
    },
    {
      "text": "Implementation and execution.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6327070707070707,
          "width": 0.1793660130718954,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "The first time any given kanji was presented, the user was shown the right answer.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.5166717171717172,
          "width": 0.5034640522875816,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Parameterization.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7633888888888889,
          "width": 0.10461601307189541,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "With human learners (see Figure 4), the number of items learned proved to be significantly greater with the myopic teacher than with the Leitner teacher (  = 174 . 5,  = 0 . 019,   = 0 . 038,  = 24  2).",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.6722449494949495,
          "width": 0.6837205882352942,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.6895416666666666,
          "width": 0.5543316993464051,
          "height": 0.013324494949494947,
          "page": 11
        }
      ]
    },
    {
      "text": "To verify that the teacher actually adapted at the level of users and items, we present the final parameter estimates made by the psychologist in Figure 5.",
      "bboxes": [
        {
          "left": 0.196281045751634,
          "top": 0.7933194444444444,
          "width": 0.6837238562091503,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.18000163398692812,
          "top": 0.8106148989898989,
          "width": 0.22322222222222218,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Human (performance)",
      "bboxes": [
        {
          "left": 0.42114379084967324,
          "top": 0.28046085858585856,
          "width": 0.21773366013071893,
          "height": 0.013522727272727297,
          "page": 11
        }
      ]
    },
    {
      "text": "In our simulations with a learner that, by construction, has exact correspondence with the model, the long-termplanning teacher did better than the Leitner and myopic teachers  markedly and consistently.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.6038282828282828,
          "width": 0.6861993464052287,
          "height": 0.011320707070706981,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.6211249999999999,
          "width": 0.5688366013071895,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Our work extends research on model-based approaches for tutoring systems by offering a modular framework to combine online inference specific to each user and each item with online planning that takes the learners time constraints into account.",
      "bboxes": [
        {
          "left": 0.1200016339869281,
          "top": 0.4654583333333333,
          "width": 0.6999918300653596,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.48275505050505046,
          "width": 0.7000032679738563,
          "height": 0.01393560606060612,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.5000505050505051,
          "width": 0.15190522875816997,
          "height": 0.011320707070706981,
          "page": 12
        }
      ]
    },
    {
      "text": "The main contribution represented by this paper has less to do with the performance of an end-to-end method than it does with proposing a modular framework that, in contrast to prior methods, clearly advances our tackling of multiple aspects of learning.",
      "bboxes": [
        {
          "left": 0.1362794117647059,
          "top": 0.7421982323232323,
          "width": 0.6837173202614379,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.7594949494949494,
          "width": 0.7,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.1200016339869281,
          "top": 0.776790404040404,
          "width": 0.16593464052287582,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "We thank all study participants for their time, and our colleagues and the reviewers for their helpful comments.",
      "bboxes": [
        {
          "left": 0.17929901960784314,
          "top": 0.29925378787878787,
          "width": 0.6705751633986929,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    }
  ],
  "2102.00593": [
    {
      "text": "Advances in artificial intelligence (AI) and machine learning (ML) offer opportunities to uncover complex data patterns.",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.508195707070707,
          "width": 0.3939526143790849,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5220328282828283,
          "width": 0.31753267973856203,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "One area of healthcare that researchers have expected to benefit from the implementation of DSTs, but has yet to adopt such technological support, is major depressive disorder (MDD).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6604027777777778,
          "width": 0.3787549019607843,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.674239898989899,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 0
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6880770202020202,
          "width": 0.34659477124183014,
          "height": 0.011320707070707092,
          "page": 0
        }
      ]
    },
    {
      "text": "Harvard University jdhe@college.harvard.edu",
      "bboxes": [
        {
          "left": 0.4365457516339869,
          "top": 0.17693055555555554,
          "width": 0.12896078431372549,
          "height": 0.012579545454545482,
          "page": 0
        },
        {
          "left": 0.414218954248366,
          "top": 0.19202525252525252,
          "width": 0.1731895424836602,
          "height": 0.012579545454545454,
          "page": 0
        }
      ]
    },
    {
      "text": "Melanie F. Pradier",
      "bboxes": [
        {
          "left": 0.6968022875816993,
          "top": 0.15932070707070708,
          "width": 0.14483006535947718,
          "height": 0.01509469696969698,
          "page": 0
        }
      ]
    },
    {
      "text": "Microsoft Research melanief@microsoft.com",
      "bboxes": [
        {
          "left": 0.7052679738562092,
          "top": 0.17693055555555554,
          "width": 0.12752777777777768,
          "height": 0.012579545454545482,
          "page": 0
        },
        {
          "left": 0.6856683006535949,
          "top": 0.19202525252525252,
          "width": 0.16672712418300661,
          "height": 0.012579545454545454,
          "page": 0
        }
      ]
    },
    {
      "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7816641414141414,
          "width": 0.3927761437908497,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7917272727272727,
          "width": 0.3925588235294118,
          "height": 0.008805555555555622,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.801790404040404,
          "width": 0.39256045751633994,
          "height": 0.008805555555555511,
          "page": 0
        },
        {
          "left": 0.08790522875816993,
          "top": 0.811854797979798,
          "width": 0.07863071895424838,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "Andrew C. Ahn Harvard Medical School Beth Israel Deaconess Medical Center aahn@bidmc.harvard.edu",
      "bboxes": [
        {
          "left": 0.43680555555555556,
          "top": 0.2179431818181818,
          "width": 0.12570588235294122,
          "height": 0.01509469696969698,
          "page": 0
        },
        {
          "left": 0.4198513071895425,
          "top": 0.23555429292929292,
          "width": 0.16029738562091506,
          "height": 0.012579545454545454,
          "page": 0
        },
        {
          "left": 0.3756584967320261,
          "top": 0.2506489898989899,
          "width": 0.2489934640522875,
          "height": 0.012579545454545427,
          "page": 0
        },
        {
          "left": 0.4144232026143791,
          "top": 0.2657436868686869,
          "width": 0.17115522875816996,
          "height": 0.012579545454545427,
          "page": 0
        }
      ]
    },
    {
      "text": "Barbara Lam Beth Israel Deaconess Medical Center blam@bidmc.harvard.edu",
      "bboxes": [
        {
          "left": 0.1807875816993464,
          "top": 0.21794444444444444,
          "width": 0.1019901960784314,
          "height": 0.01509469696969698,
          "page": 0
        },
        {
          "left": 0.10743954248366012,
          "top": 0.23555429292929292,
          "width": 0.24899346405228762,
          "height": 0.012579545454545454,
          "page": 0
        },
        {
          "left": 0.14612254901960786,
          "top": 0.2506489898989899,
          "width": 0.17131699346405227,
          "height": 0.012579545454545427,
          "page": 0
        }
      ]
    },
    {
      "text": "Thomas H. McCoy Massachusetts General Hospital Harvard Medical School tmccoy@mgh.harvard.edu Krzysztof Z. Gajos Harvard University kgajos@g.harvard.edu",
      "bboxes": [
        {
          "left": 0.6934493464052288,
          "top": 0.2179431818181818,
          "width": 0.14945915032679735,
          "height": 0.01509469696969698,
          "page": 0
        },
        {
          "left": 0.6619656862745098,
          "top": 0.23555429292929292,
          "width": 0.2125032679738561,
          "height": 0.012579545454545454,
          "page": 0
        },
        {
          "left": 0.6880686274509804,
          "top": 0.2506489898989899,
          "width": 0.1602973856209151,
          "height": 0.012579545454545427,
          "page": 0
        },
        {
          "left": 0.6800359477124184,
          "top": 0.2657436868686869,
          "width": 0.17636437908496727,
          "height": 0.012579545454545427,
          "page": 0
        },
        {
          "left": 0.6947287581699346,
          "top": 0.29166287878787883,
          "width": 0.14697875816993466,
          "height": 0.015094696969696952,
          "page": 0
        },
        {
          "left": 0.7039493464052288,
          "top": 0.30927272727272725,
          "width": 0.12896078431372537,
          "height": 0.012579545454545482,
          "page": 0
        },
        {
          "left": 0.6936045751633987,
          "top": 0.32436742424242426,
          "width": 0.14922712418300654,
          "height": 0.012579545454545482,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8551742424242424,
          "width": 0.19444607843137257,
          "height": 0.008805555555555622,
          "page": 0
        }
      ]
    },
    {
      "text": "Harvard Medical School",
      "bboxes": [
        {
          "left": 0.15163398692810456,
          "top": 0.32436742424242426,
          "width": 0.16029738562091503,
          "height": 0.012579545454545482,
          "page": 0
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.5190522875816994,
          "top": 0.36953661616161615,
          "width": 0.1421470588235293,
          "height": 0.010063131313131302,
          "page": 0
        }
      ]
    },
    {
      "text": "Massachusetts General Hospital",
      "bboxes": [
        {
          "left": 0.12553104575163399,
          "top": 0.30927272727272725,
          "width": 0.2125032679738562,
          "height": 0.012579545454545482,
          "page": 0
        }
      ]
    },
    {
      "text": "Using an iterative design process and two qualitative studies with PCPs, our findings raise many challenges to integrating ML-enabled tools into real clinical workflows.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.24529292929292928,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2591300505050505,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2729671717171717,
          "width": 0.19272712418300658,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Decision support tools are computational systems created to facilitate medical decision-making [47].",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5635441919191919,
          "width": 0.39503594771241834,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5773813131313131,
          "width": 0.20634150326797385,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Based on these findings, we discuss how using a sociotechnical lens challenges current trends in the design of explainable AI.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4251742424242424,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4390113636363636,
          "width": 0.3695473856209151,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "In the past few years, we have seen an upswing in CHI research that uses co-design methods to consider the real-world challenges, beyond accuracy, that must be considered in the design and development of these tools.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.18994444444444444,
          "width": 0.3762794117647059,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.20378156565656566,
          "width": 0.39416503267973846,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.21761868686868688,
          "width": 0.39502941176470585,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.23145580808080807,
          "width": 0.12902124183006536,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "We assert that another problem is the lack of context awareness of the broader sociotechnical systems in which these tools are being embedded.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.34215151515151515,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.35598863636363637,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3698257575757576,
          "width": 0.06528758169934645,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "While ML models for antidepressant treatment selection exist, these systems are rarely integrated into clinical practice due to low user acceptance and a failure to account for user expectations in the system design [19, 33].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.13459722222222223,
          "width": 0.3778954248366013,
          "height": 0.011320707070707065,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.14843434343434345,
          "width": 0.39310620915032685,
          "height": 0.011320707070707065,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.162270202020202,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.17610732323232323,
          "width": 0.133859477124183,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Despitemanyyearsofenthusiasmtowardsthesetechnologies[41, 47], the vast majority of these tools fail once they are deployed in real-world health systems.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6880770202020202,
          "width": 0.3806633986928104,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5191977124183007,
          "top": 0.7019141414141414,
          "width": 0.3928921568627449,
          "height": 0.011320707070706981,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7157512626262627,
          "width": 0.1615898692810458,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "In recent years, we have seen increased interest in embedding AI tools in a variety of contexts, such as the justice system [2, 62], the U.S. child welfare system [54], and medicine [22, 59, 68].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7849356060606061,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7987727272727273,
          "width": 0.394171568627451,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8126098484848485,
          "width": 0.36348856209150326,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "While we have seen many recent advances related to the use of HCI methods for designing AI tools, we have seen few studies that discuss what it will take to make these tools work within complex sociotechnical systems.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5497070707070707,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5635441919191919,
          "width": 0.39256699346405227,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5773813131313131,
          "width": 0.39291176470588235,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5912171717171718,
          "width": 0.13933006535947717,
          "height": 0.011320707070706981,
          "page": 1
        }
      ]
    },
    {
      "text": "Finding an effective antidepressant medication for someone diagnosed with MDD is an important but difficult task.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5358699494949495,
          "width": 0.3787516339869281,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5497070707070707,
          "width": 0.3156584967320261,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "To support treatment selection, the Canadian Network for Mood and Anxiety Treatments provides widely followed treatment guidelines for 25 antidepressants, organized as first-, second-, and (a small number of) third-line treatments [31].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6880770202020202,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7019141414141414,
          "width": 0.39503104575163406,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7157512626262627,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7295883838383838,
          "width": 0.26522712418300654,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "This study was approved by the Harvard Institutional Review Board.",
      "bboxes": [
        {
          "left": 0.6469101307189542,
          "top": 0.34577020202020203,
          "width": 0.26765522875817016,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.35960732323232325,
          "width": 0.14971241830065363,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "We also wished to include clinicians in co-design activities to discuss their expectations for future DSTs.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.511814393939394,
          "width": 0.3787630718954248,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5256515151515151,
          "width": 0.22738725490196077,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Within HCI, recent work has helped to establish clinical expectations for DSTs and develop guidelines for improving clinician-AI interactions.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10692297979797981,
          "width": 0.3787549019607843,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.120760101010101,
          "width": 0.39256699346405227,
          "height": 0.011320707070707078,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.13459722222222223,
          "width": 0.0758562091503268,
          "height": 0.011320707070707065,
          "page": 2
        }
      ]
    },
    {
      "text": "Major depressive disorder (MDD) is a brain disorder characterized by depressed mood, loss of interest in daily activities, as well as change in associated symptoms such as sleep, energy, eating, concentration, and thoughts of death or suicide.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.4113371212121212,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4251742424242424,
          "width": 0.3925539215686275,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4390113636363636,
          "width": 0.39417810457516345,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4528472222222222,
          "width": 0.29645915032679737,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "The trial and error involved in identifying effective treatment for a given individual has prompted calls for more integration of evidence-based medicine in the treatment of mental health disorders [40, 48, 58].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.840284090909091,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8541212121212122,
          "width": 0.39256372549019614,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679583333333334,
          "width": 0.39504084967320263,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8817941919191918,
          "width": 0.09560130718954248,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We worked with primary care physicians who currently prescribe antidepressant treatments.",
      "bboxes": [
        {
          "left": 0.7348316993464052,
          "top": 0.24096969696969697,
          "width": 0.17726633986928098,
          "height": 0.011320707070707065,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.25480681818181816,
          "width": 0.3697581699346405,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Patient-level prognostic predictions:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6389621212121211,
          "width": 0.24074509803921562,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Treatment selection support:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8118181818181819,
          "width": 0.1919281045751634,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Through the interviews participants affirmed many established treatment selection challenges.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6050542929292929,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6188914141414141,
          "width": 0.180781045751634,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Ten PCPs volunteered to participate in this study (six physicians, three resident physicians, and one nurse practitioner).",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.508195707070707,
          "width": 0.39461274509803923,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5220328282828283,
          "width": 0.3184542483660131,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "The prototype includes a fabricated patient scenario, as seen in figure 1A.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2105252525252525,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22436237373737372,
          "width": 0.07463235294117647,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "All interviews were audio recorded and transcribed.",
      "bboxes": [
        {
          "left": 0.21648529411764705,
          "top": 0.3187929292929293,
          "width": 0.2664493464052287,
          "height": 0.011320707070707037,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3326300505050505,
          "width": 0.0451421568627451,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Engaging patients also means providing ways to integrate patient treatment preferences into the interactive system design.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7234532828282828,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.737290404040404,
          "width": 0.33077941176470604,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Overall, clinicians responded positively to the treatment recommendation feature.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8679583333333334,
          "width": 0.3787549019607842,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8817941919191918,
          "width": 0.134187908496732,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "While participants were interested in using technology to help in their decision-making, they would not have the time in these encounters to determine if they thought a tool was trust-worthy.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7534078282828283,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7672449494949495,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7810820707070707,
          "width": 0.3948202614379086,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We also found that while some predictions helped clinicians to identify appropriate actions and next steps, other model predictions were viewed less favorably.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7849356060606061,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7987727272727273,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08736437908496732,
          "top": 0.8126098484848485,
          "width": 0.16345915032679736,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "In the case of dropout prediction, participants discussed three ways in which PCPs could respond to a high dropout risk prediction: including behavioral therapy with patient counseling in the care plan, lowering the drug titration, and reducing follow-up times.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6880770202020202,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08736437908496732,
          "top": 0.7019141414141414,
          "width": 0.3948300653594772,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7157512626262627,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7295883838383838,
          "width": 0.3948202614379085,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "As in these examples, clinicians raised important concerns about DST recommendations.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.2668371212121212,
          "width": 0.3762794117647059,
          "height": 0.011320707070707037,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.28067424242424244,
          "width": 0.13611274509803917,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "In this case, while the participant indicated general interest in the DST recommendations, the conversation did not result in any specific conclusions on how to use the DST output to identify possible next steps.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3790656565656566,
          "width": 0.3762826797385621,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.39290277777777777,
          "width": 0.3929460784313726,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.406739898989899,
          "width": 0.395031045751634,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4205757575757576,
          "width": 0.08275980392156863,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "In the interviews, we were surprised that discussions of trust in the technology were rarely initiated by participants.",
      "bboxes": [
        {
          "left": 0.8748218954248366,
          "top": 0.6288750000000001,
          "width": 0.037269607843137376,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6427121212121213,
          "width": 0.39503594771241834,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6565492424242424,
          "width": 0.2759705882352941,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Participants frequently commented that DST predictions should be paired with recommendations for appropriate next steps in the clinical workflow, often involving other healthcare providers.",
      "bboxes": [
        {
          "left": 0.38540196078431377,
          "top": 0.17305808080808083,
          "width": 0.09753758169934645,
          "height": 0.011320707070707037,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.18689520202020202,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2007323232323232,
          "width": 0.3950408496732026,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2145681818181818,
          "width": 0.298625816993464,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "As shown in the above examples, we found that clinicians expected DSTs to integrate with their existing processes and use the DST predictions to show a path forward .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.48209848484848483,
          "width": 0.3787549019607842,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.49593560606060605,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5097727272727273,
          "width": 0.2728578431372549,
          "height": 0.013935606060606065,
          "page": 5
        }
      ]
    },
    {
      "text": "Our second goal was to connect the DST predictions with appropriate clinical processes.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8126098484848485,
          "width": 0.37875490196078443,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8264469696969697,
          "width": 0.1623316993464053,
          "height": 0.011320707070706981,
          "page": 6
        }
      ]
    },
    {
      "text": "This study was approved by the Harvard Institutional Review Board.",
      "bboxes": [
        {
          "left": 0.6469101307189542,
          "top": 0.7471464646464646,
          "width": 0.26765522875817016,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7609835858585858,
          "width": 0.14790196078431372,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We redesigned the DST prototype to operationalize the guidelines established in study 1.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.4666843434343434,
          "width": 0.39326470588235296,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4805214646464646,
          "width": 0.13401633986928108,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "For this study we again worked with PCPs who currently prescribe antidepressant treatments.",
      "bboxes": [
        {
          "left": 0.7295294117647059,
          "top": 0.6353762626262627,
          "width": 0.18256209150326808,
          "height": 0.011320707070706981,
          "page": 6
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6492133838383839,
          "width": 0.37412091503267986,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Thus, we found that conversations of trust were not typically initiated by participants because participants expected that trust in the technology will not be decided at each decision point.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.311625,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.32546212121212126,
          "width": 0.39256372549019614,
          "height": 0.01393560606060601,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3419141414141414,
          "width": 0.3950637254901961,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "When looking at the feature importance charts, participants overall found the information unnecessary in determining how they will care for a patient, and ill-fitted for their short patient appointments:",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.1954368686868687,
          "width": 0.37627450980392163,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2092739898989899,
          "width": 0.39310130718954245,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.22311111111111112,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.23694823232323234,
          "width": 0.08579575163398694,
          "height": 0.011320707070707037,
          "page": 6
        }
      ]
    },
    {
      "text": "I dont know if you necessarily need to get into super",
      "bboxes": [
        {
          "left": 0.1277892156862745,
          "top": 0.10957196969696971,
          "width": 0.31279248366013074,
          "height": 0.011320707070707065,
          "page": 6
        }
      ]
    },
    {
      "text": "Similar to study 1, all sessions were audio recorded and transcribed.",
      "bboxes": [
        {
          "left": 0.22087418300653597,
          "top": 0.6263106060606061,
          "width": 0.25959150326797387,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6401477272727273,
          "width": 0.15764379084967323,
          "height": 0.011320707070706981,
          "page": 8
        }
      ]
    },
    {
      "text": "Eight PCPs enrolled in this user study (six physicians, two residents, and one nurse practitioner), four of whom also participated in the first study.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8541212121212122,
          "width": 0.39416830065359476,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8679583333333334,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8817941919191918,
          "width": 0.06463235294117646,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Due to our focus on walking through a decision process that replicates real-world decision-making we worked with experts in clinical psychology and psychopharmacology to create a realistic patient scenario.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5324684343434343,
          "width": 0.3950424836601308,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5463055555555555,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5601426767676767,
          "width": 0.3925555555555555,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5739797979797979,
          "width": 0.051990196078431375,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Participants positively responded to the ways in which we integrated clinical processes by displaying relevant actions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6440277777777778,
          "width": 0.3787532679738562,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.657864898989899,
          "width": 0.3197238562091502,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Much of the prototype feedback re-emphasized the lessons we learned in the first user study.",
      "bboxes": [
        {
          "left": 0.7491797385620915,
          "top": 0.5748421717171717,
          "width": 0.16538888888888892,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5886792929292929,
          "width": 0.394812091503268,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "The examples we presented in this section describe reactions to scenarios in which the output of the machine learning model contrasts from clinical experiences or standards of care.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8126098484848485,
          "width": 0.3762745098039214,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8264469696969697,
          "width": 0.3925637254901959,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.840284090909091,
          "width": 0.3477924836601307,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Clinicians also suggested additional conditions that should be included, such as pregnancy and suicidality, as these will influence their treatment decision.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3698257575757576,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3836628787878788,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.39749999999999996,
          "width": 0.1483872549019608,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "These discussions reemphasized the type of validation methods that would help clinicians to establish trust.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.840284090909091,
          "width": 0.3762777777777778,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8541212121212122,
          "width": 0.27661274509803924,
          "height": 0.011320707070706981,
          "page": 9
        }
      ]
    },
    {
      "text": "Here, we see that when faced with unexpected model output that contrasted with participants expectations or mental model, participants found it challenging to identify appropriate next steps.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5292575757575758,
          "width": 0.3762745098039214,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5430946969696969,
          "width": 0.39417810457516333,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5569318181818181,
          "width": 0.3948153594771242,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "While participants responded positively to the overall prototype design, we found that when the recommendations diverged from clinical knowledge or guidelines participants became confused and would often abandon the recommendation.",
      "bboxes": [
        {
          "left": 0.7776127450980392,
          "top": 0.17010858585858585,
          "width": 0.1369624183006536,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.18394570707070707,
          "width": 0.39256209150326793,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5189918300653594,
          "top": 0.19778282828282828,
          "width": 0.39337581699346413,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2116199494949495,
          "width": 0.39502941176470574,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2254558080808081,
          "width": 0.15555392156862746,
          "height": 0.011320707070707037,
          "page": 9
        }
      ]
    },
    {
      "text": "In addition to the positive feedback, some participants mentioned opportunities to continue to integrate the DST with existing clinical processes.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10692297979797981,
          "width": 0.3762794117647058,
          "height": 0.011320707070707065,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.120760101010101,
          "width": 0.3925604575163399,
          "height": 0.011320707070707078,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.13459722222222223,
          "width": 0.06135947712418298,
          "height": 0.011320707070707065,
          "page": 9
        }
      ]
    },
    {
      "text": "Finally, a goal with this prototype was to allow clinicians to establish trust within the tool while being more mindful of their time constraints.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.625810606060606,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6396477272727272,
          "width": 0.39283333333333337,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6534848484848484,
          "width": 0.1006045751633987,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Surprising predictions, such as this one, led to greater interest in the depression score and how it was calculated.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.41194949494949495,
          "width": 0.376282679738562,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.42578661616161617,
          "width": 0.29693954248366006,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Clinicians also responded positively to the ability to edit patient to",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2245378787878788,
          "width": 0.37875490196078443,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.23837373737373738,
          "width": 0.02827450980392157,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.46862908496732025,
          "top": 0.25221085858585857,
          "width": 0.011833333333333362,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "We also found that clinicians were thoughtful in considering the possible adverse effects of DST predictions.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.4195126262626263,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4333497474747475,
          "width": 0.26307026143790846,
          "height": 0.011320707070706981,
          "page": 10
        }
      ]
    },
    {
      "text": "These empirical implications provide concrete implications to the specific context of MDD.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3201388888888889,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3339747474747474,
          "width": 0.17208006535947712,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Through conversations on their expectations for AI support, clinicians revealed a number of critical aspects of the sociotechnical healthcare system that need to be considered in the design of novel decision support tools.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.1817689393939394,
          "width": 0.3954771241830065,
          "height": 0.011320707070707037,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.195604797979798,
          "width": 0.39256372549019614,
          "height": 0.011320707070707037,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.20944191919191918,
          "width": 0.3925604575163399,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.2232790404040404,
          "width": 0.139890522875817,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "We see a clear need for DSTs to explicitly draw the connections between the model output and actionable next steps.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.22579545454545455,
          "width": 0.39326633986928095,
          "height": 0.011320707070707037,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.23963257575757574,
          "width": 0.33144281045751633,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "While explaining black box models is a consistent theme in AI work, we need best practices for adapting the design of DSTs for timeconstrained environments.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.6188914141414141,
          "width": 0.394872549019608,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5189918300653594,
          "top": 0.6327285353535353,
          "width": 0.3955833333333334,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6465656565656566,
          "width": 0.1614820261437908,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Designing for fast-paced, time-constrained work environments has important design implications, particularly in the context of current explainable AI research.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7157512626262627,
          "width": 0.3762859477124184,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7295883838383838,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7434242424242424,
          "width": 0.1661650326797386,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "The clinicians who participated in this study encouraged us to use DSTs to foster greater collaboration with patients.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5220328282828283,
          "width": 0.39299673202614377,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5358699494949495,
          "width": 0.33245915032679735,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Recent literature in explainable AI has made important progress towards improving transparency of AI models by creating interpretable explanations for the models output [67].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.10692297979797981,
          "width": 0.3762794117647058,
          "height": 0.011320707070707065,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.120760101010101,
          "width": 0.3950294117647059,
          "height": 0.011320707070707078,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.13459722222222223,
          "width": 0.2998055555555556,
          "height": 0.011320707070707065,
          "page": 11
        }
      ]
    },
    {
      "text": "We found that when the DST output did not align with clinical knowledge or guidelines, clinicians were left confused, with most opting to abandon the recommendation.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.3698257575757576,
          "width": 0.39326633986928106,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3836628787878788,
          "width": 0.39255392156862745,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.39749999999999996,
          "width": 0.23448039215686278,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "We do not yet have established best practices for dealing with contrasting information, but helping clinicians identify the best way to proceed is critical.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.5358699494949495,
          "width": 0.3762794117647058,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5497070707070707,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08736437908496732,
          "top": 0.5635441919191919,
          "width": 0.15011274509803924,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "In this paper, we report on aspects of the healthcare sociotechnical system that should be considered in the design of machine learning decision support tools.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.47611868686868686,
          "width": 0.39255718954248375,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4899558080808081,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5037929292929293,
          "width": 0.138531045751634,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "The application of machine learning in healthcare brings numerous practical, ethical, and legal issues.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.2776843434343434,
          "width": 0.3930065359477125,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.2915214646464646,
          "width": 0.19548366013071905,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Based on our results, we see an opportunity to present ondemand explanations as differentials from existing clinical guidelines.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7157512626262627,
          "width": 0.3789101307189543,
          "height": 0.013935606060606065,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7322032828282828,
          "width": 0.39255882352941174,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7460391414141415,
          "width": 0.07199509803921568,
          "height": 0.011320707070706981,
          "page": 11
        }
      ]
    },
    {
      "text": "This research was supported in part by the Harvard Data Science Initiative.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.7714128787878787,
          "width": 0.3930016339869281,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.78525,
          "width": 0.056720588235294134,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    }
  ],
  "2104.04842": [
    {
      "text": "Xu Han University of Colorado Boulder Boulder, CO, USA xuha2442@colorado.edu",
      "bboxes": [
        {
          "left": 0.26836601307189545,
          "top": 0.19301641414141413,
          "width": 0.061924836601307154,
          "height": 0.01509595959595958,
          "page": 0
        },
        {
          "left": 0.19556372549019607,
          "top": 0.21004166666666668,
          "width": 0.20848202614379086,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.2401846405228758,
          "top": 0.22513636363636363,
          "width": 0.11950163398692809,
          "height": 0.012578282828282855,
          "page": 0
        },
        {
          "left": 0.21797222222222223,
          "top": 0.24023106060606061,
          "width": 0.1629673202614379,
          "height": 0.0125782828282828,
          "page": 0
        }
      ]
    },
    {
      "text": "CHI 21, May 813, 2021, Yokohama, Japan",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8249848484848485,
          "width": 0.19444607843137257,
          "height": 0.008805555555555511,
          "page": 0
        }
      ]
    },
    {
      "text": "Matthew J. Turner University of Colorado Boulder Boulder, CO, USA matthew.turner@colorado.edu",
      "bboxes": [
        {
          "left": 0.2256013071895425,
          "top": 0.26673484848484846,
          "width": 0.14684150326797382,
          "height": 0.015095959595959607,
          "page": 0
        },
        {
          "left": 0.19475,
          "top": 0.283760101010101,
          "width": 0.20848202614379083,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.23936928104575164,
          "top": 0.29885479797979797,
          "width": 0.11950163398692806,
          "height": 0.012578282828282827,
          "page": 0
        },
        {
          "left": 0.19725653594771242,
          "top": 0.3139494949494949,
          "width": 0.20315849673202613,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "University of Colorado Boulder",
      "bboxes": [
        {
          "left": 0.5970767973856209,
          "top": 0.283760101010101,
          "width": 0.20848202614379086,
          "height": 0.012578282828282827,
          "page": 0
        }
      ]
    },
    {
      "text": "During the past few years, chatbots have been used to conduct interviews by engaging users in one-on-one text-based conversations [67].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.30327777777777776,
          "width": 0.39503431372549025,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.317114898989899,
          "width": 0.39256045751633994,
          "height": 0.011320707070707037,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3309520202020202,
          "width": 0.027006535947712407,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To address the above two challenges, we have been developing a tool, called iChatProfile , which can aid chatbot designers in building, evaluating, and improving interview chatbots iteratively.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7875732323232324,
          "width": 0.3762843137254902,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8014103535353535,
          "width": 0.39502941176470585,
          "height": 0.011332070707070763,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8152474747474748,
          "width": 0.3758562091503268,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To achieve above goals, designers often conduct pilot studies prior to a formal study [49].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.552344696969697,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5661818181818182,
          "width": 0.1650392156862745,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "Despite their promises, it is challenging and time consuming to build effective interview chatbots due to the limitations in todays technologies and the complexity involved in interview conversations [18, 65].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.37246338383838384,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.38630050505050506,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4001376262626263,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4139747474747475,
          "width": 0.08124999999999998,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "In this paper, we present the key steps taken to build iChatProfile .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.10956060606060607,
          "width": 0.3785359477124183,
          "height": 0.011332070707070707,
          "page": 1
        }
      ]
    },
    {
      "text": "Researchers have developed various chatbots to elicit information from users through text-based conversations.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8567588383838384,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8705959595959595,
          "width": 0.3099379084967321,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "AI-powered conversational user interfaces, also known as AI chatbots or chatbots for short, allow users to communicate with computers in natural language, providing more flexible [5] and personalized user experience [69].",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.7460618686868686,
          "width": 0.39554738562091496,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.75989898989899,
          "width": 0.39503104575163406,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7737361111111111,
          "width": 0.39255555555555555,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7875732323232324,
          "width": 0.12599183006535952,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "To the best of our knowledge, our work is the first on building an assistive design tool for creating interview chatbots.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3447891414141414,
          "width": 0.3762859477124183,
          "height": 0.011320707070707092,
          "page": 1
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3586262626262626,
          "width": 0.32472058823529404,
          "height": 0.011320707070707092,
          "page": 1
        }
      ]
    },
    {
      "text": "ACM Reference Format:",
      "bboxes": [
        {
          "left": 0.08742320261437908,
          "top": 0.18126262626262626,
          "width": 0.14214705882352943,
          "height": 0.010063131313131302,
          "page": 1
        }
      ]
    },
    {
      "text": "Our work is directly related to the efforts of creating interview chatbots.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4866300505050505,
          "width": 0.3768218954248366,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5004671717171717,
          "width": 0.053259803921568635,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Our work on generating design suggestions is also related to various efforts on guiding the design of human-computer interfaces, such as chatbot systems [21] and graphical user interfaces (GUI) [36, 68].",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6768775252525252,
          "width": 0.39503267973856215,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6907146464646465,
          "width": 0.39417810457516333,
          "height": 0.011320707070706981,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7045517676767676,
          "width": 0.3934395424836602,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.718388888888889,
          "width": 0.04813235294117646,
          "height": 0.011320707070706981,
          "page": 2
        }
      ]
    },
    {
      "text": "There are a number of chatbot platforms and these platforms can be broadly divided into three categories.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.6630404040404041,
          "width": 0.3930065359477124,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6768775252525252,
          "width": 0.24593300653594768,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "Researchers have developed a number of approaches to evaluating conversational AI systems.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3655568181818182,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 2
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3793939393939394,
          "width": 0.18617973856209147,
          "height": 0.011320707070707092,
          "page": 2
        }
      ]
    },
    {
      "text": "We selected this set of interview questions for three reasons.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8738977272727272,
          "width": 0.3458398692810457,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "For non-IT chatbot designers, Juji relieves them from implementing many needed AI skills of interview chatbots while providing them with much freedom to customize a conversational experience.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5962424242424242,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6100795454545455,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6239166666666667,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6377525252525252,
          "width": 0.03099346405228759,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "First, recent studies show that other researchers have used Juji to build various interview chatbots, which matches our focus on aiding the design of effective interview chatbots [37, 61, 65, 66].",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.4153459595959596,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4291830808080808,
          "width": 0.3925637254901962,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.44302020202020204,
          "width": 0.3948169934640523,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Lastly, the extensibility of Juji makes it easy for us to build and integrate iChatProfile .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5040151515151515,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5178522727272727,
          "width": 0.12687254901960787,
          "height": 0.011332070707070652,
          "page": 3
        }
      ]
    },
    {
      "text": "Access interviewee responses .",
      "bboxes": [
        {
          "left": 0.5189918300653594,
          "top": 0.313989898989899,
          "width": 0.19711437908496732,
          "height": 0.011343434343434322,
          "page": 3
        }
      ]
    },
    {
      "text": "Customize chatbot questions/messages .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.7073737373737374,
          "width": 0.25841176470588234,
          "height": 0.011343434343434322,
          "page": 3
        }
      ]
    },
    {
      "text": "As mentioned in Section 2.2, there are three types of chatbot platforms.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.33130934343434343,
          "width": 0.3955424836601307,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.08790522875816993,
          "top": 0.34514646464646465,
          "width": 0.03758496732026144,
          "height": 0.011320707070707092,
          "page": 3
        }
      ]
    },
    {
      "text": "Customize chatbot responses and persona .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8046906565656566,
          "width": 0.2805179738562092,
          "height": 0.011343434343434211,
          "page": 3
        }
      ]
    },
    {
      "text": "To guide the development of iChatProfile , we conducted a study to first identify the types of design assistance desired by chatbot designers.Fromapublic",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6386691919191919,
          "width": 0.39337418300653604,
          "height": 0.011332070707070874,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6525063131313131,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 3
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6663434343434343,
          "width": 0.09638235294117647,
          "height": 0.0251578282828282,
          "page": 3
        }
      ]
    },
    {
      "text": "In this study, we intentionally did not set any specific design requirements because we wished to observe what the participants would do and the challenges they would face.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.3170972222222222,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.33093434343434347,
          "width": 0.39256372549019614,
          "height": 0.011320707070706981,
          "page": 4
        },
        {
          "left": 0.08736437908496732,
          "top": 0.3447714646464647,
          "width": 0.2668856209150327,
          "height": 0.011320707070706981,
          "page": 4
        }
      ]
    },
    {
      "text": "During the participant interviews, all participants expressed the importance of receiving design assistance.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5971578282828283,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6109949494949495,
          "width": 0.26132516339869283,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "The second type (T2) is design suggestions for improving a chatbot.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.7493648989898989,
          "width": 0.3787630718954249,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7632020202020202,
          "width": 0.023058823529411757,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Since our formative study indicated that chatbot designers wish to obtain certain quantitative feedback on the performance of their existing chatbot (T1), we first formulated a computational framework that quantitatively measures the effectiveness of such an interview chatbot from multiple aspects.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7493648989898989,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7632020202020202,
          "width": 0.39503104575163417,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7770391414141413,
          "width": 0.39293464052287597,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7908762626262626,
          "width": 0.3930996732026145,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8047133838383838,
          "width": 0.18448366013071893,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "We followed qualitative analysis methods and the grounded theory [40, 68] to code the participant interview data.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4554671717171717,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.46930429292929293,
          "width": 0.32283823529411765,
          "height": 0.011320707070707037,
          "page": 4
        }
      ]
    },
    {
      "text": "In addition to obtaining design guidance, the participants also expressed the need of viewing relevant conversation examples in",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8738977272727272,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8877348484848485,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Based on the previous work on assessing human interviews [3, 7, 15, 20, 24, 50], communication theories for conducting effective interviews [47, 67], and evaluating chatbot effectiveness [12, 19, 55,",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8600606060606061,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8738977272727272,
          "width": 0.39255882352941185,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8877348484848485,
          "width": 0.39417156862745095,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "Based on the desired design assistance, we derived three design goals of iChatProfile so it can fulfill designers needs:",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.2827777777777778,
          "width": 0.392563725490196,
          "height": 0.011320707070707037,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.296614898989899,
          "width": 0.3149738562091503,
          "height": 0.011332070707070707,
          "page": 4
        }
      ]
    },
    {
      "text": "We derived C1 as iChatProfile is intended to help chatbot designers especially those with no AI/NLP expertise to design, evaluate, and improve interview chatbots.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.5744191919191919,
          "width": 0.3957369281045753,
          "height": 0.011332070707070763,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5882563131313131,
          "width": 0.39416993464052297,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6020934343434343,
          "width": 0.19890522875816996,
          "height": 0.011320707070707092,
          "page": 4
        }
      ]
    },
    {
      "text": "In addition to the three goals directly determined from the findings of our formative study (G1 from T1, G2+G3 from T2), we derived another two criteria to guide the implementation of iChatProfile for practical purposes:",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.44243560606060606,
          "width": 0.3787499999999999,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4562727272727273,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4701085858585859,
          "width": 0.39402614379084977,
          "height": 0.011332070707070652,
          "page": 4
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4839457070707071,
          "width": 0.17452941176470593,
          "height": 0.011332070707070652,
          "page": 4
        }
      ]
    },
    {
      "text": "To ensure both the coverage and practicality of chatbot evaluation, we used four criteria to choose our metrics.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.15437373737373736,
          "width": 0.3787614379084967,
          "height": 0.011320707070707065,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1682108585858586,
          "width": 0.28754738562091503,
          "height": 0.011320707070707037,
          "page": 5
        }
      ]
    },
    {
      "text": "The primary task of interview chatbots is to elicit high-quality responses from participants.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.5335530303030304,
          "width": 0.3933856209150327,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5473901515151516,
          "width": 0.1667238562091503,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Here min_surprisal and max_surprisal are the minimum and maximum of surprisal, computed among all words in the vocabulary.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8738977272727272,
          "width": 0.39503431372549025,
          "height": 0.011332070707070763,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8877348484848485,
          "width": 0.3792254901960785,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "User Satisfaction Rating .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8462007575757576,
          "width": 0.16336928104575166,
          "height": 0.011343434343434211,
          "page": 5
        }
      ]
    },
    {
      "text": "Completion Rate .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.49425757575757573,
          "width": 0.11700980392156857,
          "height": 0.011343434343434378,
          "page": 5
        }
      ]
    },
    {
      "text": "This metric (e.g., a low informativeness score) can signal designers that there are potential issues with an interview question.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.14053661616161617,
          "width": 0.3787598039215686,
          "height": 0.011332070707070707,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.15437373737373736,
          "width": 0.3691045751633987,
          "height": 0.011320707070707065,
          "page": 5
        }
      ]
    },
    {
      "text": "Engagement Duration .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.3835618686868687,
          "width": 0.1496846405228759,
          "height": 0.011343434343434322,
          "page": 5
        }
      ]
    },
    {
      "text": "Response Length .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.2728661616161616,
          "width": 0.11655882352941171,
          "height": 0.011343434343434322,
          "page": 5
        }
      ]
    },
    {
      "text": "Informed by literature in interaction design [54] and interview design [7, 20], we proposed five metrics to measure a users experience with an interview chatbot.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.8014255050505051,
          "width": 0.39503921568627454,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8152626262626262,
          "width": 0.39256535947712423,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5189918300653594,
          "top": 0.8290997474747476,
          "width": 0.1585375816993465,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "Informativeness .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.723395202020202,
          "width": 0.11182516339869282,
          "height": 0.011343434343434322,
          "page": 5
        }
      ]
    },
    {
      "text": "In the context of interviews, the level of user engagement measures a users behavior during an interview [15].",
      "bboxes": [
        {
          "left": 0.7195114379084967,
          "top": 0.20370328282828282,
          "width": 0.19257843137254904,
          "height": 0.011320707070707092,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.21754040404040403,
          "width": 0.39256535947712423,
          "height": 0.011332070707070707,
          "page": 5
        },
        {
          "left": 0.5195343137254902,
          "top": 0.23137752525252525,
          "width": 0.09103758169934639,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "For the first interview question (when n = 1), we directly use the",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6319646464646465,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "We developed a metric to evaluate the quality of user interview responses.",
      "bboxes": [
        {
          "left": 0.24150326797385624,
          "top": 0.6819065656565657,
          "width": 0.23896895424836595,
          "height": 0.011320707070706981,
          "page": 5
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6957436868686868,
          "width": 0.21315686274509804,
          "height": 0.011320707070707092,
          "page": 5
        }
      ]
    },
    {
      "text": "An interview chatbot may engage participants in a conversation on private or sensitive topics or the participants may voluntarily offer private and sensitive information [14, 23, 37, 70].",
      "bboxes": [
        {
          "left": 0.5190212418300654,
          "top": 0.5896729797979798,
          "width": 0.39307189542483656,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6035088383838384,
          "width": 0.3929411764705881,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6173459595959596,
          "width": 0.3337483660130718,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Repetition Rate .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.8738750000000001,
          "width": 0.10658986928104576,
          "height": 0.011343434343434211,
          "page": 6
        }
      ]
    },
    {
      "text": "We include this metric for two reasons.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.40088005050505054,
          "width": 0.24790522875817,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "We extracted the empathetic words from EmpatheticDialogues by identifying top 15 content words from each of its 32 emotion categories [53].",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.7632020202020202,
          "width": 0.39364379084967327,
          "height": 0.011332070707070763,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7770391414141413,
          "width": 0.3950441176470588,
          "height": 0.011320707070707092,
          "page": 6
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7908762626262626,
          "width": 0.07598692810457518,
          "height": 0.011320707070707092,
          "page": 6
        }
      ]
    },
    {
      "text": "Privacy Intrusion Rate .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7908535353535353,
          "width": 0.1536683006535947,
          "height": 0.011343434343434433,
          "page": 6
        }
      ]
    },
    {
      "text": "User Sentiment .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5115530303030302,
          "width": 0.10701633986928104,
          "height": 0.011343434343434433,
          "page": 6
        }
      ]
    },
    {
      "text": "Hate Speech Rate .",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.6801578282828282,
          "width": 0.11899183006535952,
          "height": 0.011343434343434433,
          "page": 6
        }
      ]
    },
    {
      "text": "Level of Empathy .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6222487373737374,
          "width": 0.12008823529411765,
          "height": 0.011343434343434322,
          "page": 6
        }
      ]
    },
    {
      "text": "User Trust Rating .",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.42853156565656564,
          "width": 0.12130555555555557,
          "height": 0.011343434343434378,
          "page": 6
        }
      ]
    },
    {
      "text": "To help chatbot designers evaluate and improve an interview chatbot iteratively, we have developed a tool called iChatProfile , following the design goals and design criteria summarized in Sec 4.2.",
      "bboxes": [
        {
          "left": 0.0874656862745098,
          "top": 0.7317196969696971,
          "width": 0.3954705882352942,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7455568181818182,
          "width": 0.3950294117647059,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7593939393939395,
          "width": 0.3948137254901961,
          "height": 0.011320707070706981,
          "page": 7
        }
      ]
    },
    {
      "text": "In our current implementation, the default thresholds are determined by the corresponding metric scores of the opening question (Q1).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.7493648989898989,
          "width": 0.3787532679738561,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7632020202020202,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.51909477124183,
          "top": 0.7770391414141413,
          "width": 0.02948529411764711,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Once a rule is triggered, iChatProfile automatically generates actionable design suggestions in two steps.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8600606060606061,
          "width": 0.3762761437908495,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8738977272727272,
          "width": 0.25150816993464054,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Given a set of chat transcripts, iChatProfile automatically computes all the metrics mentioned in Section 5 to assess the performance of an interview chatbot.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.31092929292929294,
          "width": 0.3925637254901959,
          "height": 0.011332070707070707,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3247651515151515,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3386022727272727,
          "width": 0.14894607843137253,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Given the computed performance metrics, iChatProfile automatically generates a set of design suggestions using a rule-based approach.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.4674835858585859,
          "width": 0.39503594771241834,
          "height": 0.011332070707070652,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.48132070707070707,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4951578282828283,
          "width": 0.04448202614379082,
          "height": 0.011320707070706981,
          "page": 7
        }
      ]
    },
    {
      "text": "As shown in Fig 4(a), iChatProfile consists of three key components: chatbot profile generator, design suggestion generator, and profile presenter.",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.8600606060606061,
          "width": 0.3947973856209151,
          "height": 0.011332070707070763,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8738977272727272,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 7
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8877348484848485,
          "width": 0.057488562091503256,
          "height": 0.011320707070707092,
          "page": 7
        }
      ]
    },
    {
      "text": "Here   is the count of sensitive words appearing in the user re",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.6147020202020202,
          "width": 0.3950441176470588,
          "height": 0.013834595959595908,
          "page": 7
        },
        {
          "left": 0.16283006535947714,
          "top": 0.6285391414141414,
          "width": 0.007970588235294118,
          "height": 0.011321969696969636,
          "page": 7
        }
      ]
    },
    {
      "text": "Given an interview question (e.g., where are you located ) and a performance metric (e.g., repetition rate ), iChatProfile first selects all conversation segments (Fig 4(b)) that produced a metric score worse than the threshold.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8047133838383838,
          "width": 0.376281045751634,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8185505050505051,
          "width": 0.3925555555555555,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8323876262626262,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08736437908496732,
          "top": 0.8462234848484848,
          "width": 0.14721241830065362,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "To present a generated chatbot profile, design suggestions, and relevant conversation evidence, we used Tableau [57] to implement a web-based, interactive visual dashboard (Fig 1).",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.41979797979797984,
          "width": 0.3954803921568628,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.43363510101010105,
          "width": 0.39256209150326793,
          "height": 0.011320707070706981,
          "page": 8
        },
        {
          "left": 0.5189918300653594,
          "top": 0.44747095959595956,
          "width": 0.27446732026143794,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Since we wished to compare chatbot performance with and without using iChatProfile , we recruited 10 chatbot designers, who were",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8738977272727272,
          "width": 0.3787630718954248,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8877348484848485,
          "width": 0.39255882352941185,
          "height": 0.011332070707070763,
          "page": 8
        }
      ]
    },
    {
      "text": "Using the same set of interview questions about COVID-19 shown in Table 1, we first built an interview chatbot on Juji using only Jujis built-in features without making any customization.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.7216906565656565,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7355277777777778,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7493648989898989,
          "width": 0.31425000000000003,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Thus, iChatProfile automatically extracts relevant conversation fragments from chat transcripts to give designers more concrete ideas on how to improve a chatbot.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.694016414141414,
          "width": 0.3762826797385621,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7078535353535353,
          "width": 0.39256372549019614,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7216906565656565,
          "width": 0.2092990196078432,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Given a template, it takes two steps to generate design suggestions in natural language: document planning and surface realization [41].",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2996628787878788,
          "width": 0.3787614379084967,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3135,
          "width": 0.39502941176470585,
          "height": 0.011320707070707037,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.32733712121212116,
          "width": 0.07368464052287581,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "To evaluate the effectiveness of iChatProfile , we designed and conducted a between-subject user study that compared the performance of 10 chatbots designed with or without using iChatProfile .",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6468472222222222,
          "width": 0.3954771241830065,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6606843434343433,
          "width": 0.39502941176470585,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6745214646464647,
          "width": 0.3938316993464053,
          "height": 0.011332070707070763,
          "page": 8
        }
      ]
    },
    {
      "text": "Using the example rule mentioned above, assume that the computed repetition rate for the interview question \"Where are you located?\" exceeds the threshold, signaling potential issues around this interview question.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.4795429292929293,
          "width": 0.3787598039215686,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4933800505050505,
          "width": 0.3925588235294118,
          "height": 0.011332070707070763,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5072171717171717,
          "width": 0.39256699346405227,
          "height": 0.011332070707070652,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.521054292929293,
          "width": 0.13990196078431372,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "To act on design suggestions, chatbot designers may need more information to understand the conversation situations.",
      "bboxes": [
        {
          "left": 0.33418137254901964,
          "top": 0.5556464646464646,
          "width": 0.14875653594771238,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5694835858585858,
          "width": 0.39256045751633994,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.583320707070707,
          "width": 0.16019117647058828,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "For each metric, we have defined a template that contains one or more design guidelines for improving a chatbot (Table 3).",
      "bboxes": [
        {
          "left": 0.40138562091503266,
          "top": 0.14745580808080808,
          "width": 0.08154901960784311,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1612929292929293,
          "width": 0.3925571895424837,
          "height": 0.011320707070707092,
          "page": 8
        },
        {
          "left": 0.08790522875816993,
          "top": 0.1751300505050505,
          "width": 0.26971732026143797,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Using the above example on the interview question of Where are you located , two clusters are formed, one with the coverage of 75.0% and the other 25.0%.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.20972222222222223,
          "width": 0.3762777777777778,
          "height": 0.01133207070707068,
          "page": 8
        },
        {
          "left": 0.5195343137254902,
          "top": 0.22355934343434344,
          "width": 0.39255392156862734,
          "height": 0.01133207070707068,
          "page": 8
        },
        {
          "left": 0.5191977124183007,
          "top": 0.23739646464646466,
          "width": 0.15611274509803919,
          "height": 0.011320707070707092,
          "page": 8
        }
      ]
    },
    {
      "text": "Table 4: Conversation SegTable 5: Conversation Seg-",
      "bboxes": [
        {
          "left": 0.5410343137254902,
          "top": 0.2702714646464647,
          "width": 0.3680539215686275,
          "height": 0.011320707070707037,
          "page": 8
        }
      ]
    },
    {
      "text": "Each designer was allotted about 30 minutes to improve their chatbot.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.6547373737373737,
          "width": 0.3765588235294117,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.668574494949495,
          "width": 0.048181372549019594,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "All chatbot respondents, including the ones in the pilot study, were recruited on Amazon Mechanical Turk (MTurk) with an approval",
      "bboxes": [
        {
          "left": 0.0873921568627451,
          "top": 0.8738977272727272,
          "width": 0.39307843137254905,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8877348484848485,
          "width": 0.3925555555555555,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "We compared the chatbot performance between Group w/o iChatProfile (702 transcripts) and Group w/ iChatProfile (647 transcripts).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8185505050505051,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8323876262626262,
          "width": 0.39503921568627454,
          "height": 0.011332070707070763,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8462234848484848,
          "width": 0.04788071895424839,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Specifically, we performed a series of ANCOVA analyses, which blend analysis of variance (ANOVA) and regression [30], to examine the effect of with or without using iChatProfile (independent variable) on various chatbot performance metrics (dependent variables).",
      "bboxes": [
        {
          "left": 0.6933235294117648,
          "top": 0.6801805555555556,
          "width": 0.21877287581699334,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5190212418300654,
          "top": 0.694016414141414,
          "width": 0.39307843137254905,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7078535353535353,
          "width": 0.3925669934640523,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7216906565656565,
          "width": 0.39256209150326793,
          "height": 0.011332070707070763,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7355277777777778,
          "width": 0.17656045751633986,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "The 10 chatbot designers (6 males, 4 females, ages 20 to 35) were students recruited from a public university majoring in diverse disciplines, including Computer Science, Information Science, Psychology, and Environmental Studies.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.3641603535353536,
          "width": 0.3762794117647059,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3779974747474748,
          "width": 0.3925637254901959,
          "height": 0.011320707070706981,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.39183459595959597,
          "width": 0.39503594771241834,
          "height": 0.011320707070707037,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.40567045454545453,
          "width": 0.2159820261437908,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "From the 10 deployed interview chatbots, we collected a total of 1349 interview transcripts including the transcripts of incomplete interviews.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.5199684343434343,
          "width": 0.3925637254901959,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5191977124183007,
          "top": 0.5338055555555555,
          "width": 0.3929035947712418,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5476426767676768,
          "width": 0.06766666666666676,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "Ten (10) designers from the two groups built a total of 10 chatbots based on the baseline chatbot provided to them.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.779270202020202,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 9
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7931073232323231,
          "width": 0.3028398692810458,
          "height": 0.011320707070707092,
          "page": 9
        }
      ]
    },
    {
      "text": "In all the analyses, the use of iChatProfile was a significant factor impacting the chatbot performance differences.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.6663434343434343,
          "width": 0.3765588235294117,
          "height": 0.011332070707070763,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.6801805555555556,
          "width": 0.2791601307189543,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "At the question level, the chatbots in Group w/ iChatProfile also performed better than those in Group w/o iChatProfile and the baseline on almost all dimensions, including response quality ( informativeness ), user engagement ( response length and engagement duration ), and user experience ( level of empathy and repetition rate ).",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.36192929292929293,
          "width": 0.3762810457516339,
          "height": 0.011332070707070707,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.37576641414141415,
          "width": 0.39255718954248375,
          "height": 0.011332070707070707,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.3895808080808081,
          "width": 0.39402450980392145,
          "height": 0.011354797979797993,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.40341666666666665,
          "width": 0.39256045751633983,
          "height": 0.011354797979798048,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.41725378787878786,
          "width": 0.39256045751633983,
          "height": 0.011354797979798048,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.43111363636363637,
          "width": 0.031081699346405256,
          "height": 0.011332070707070707,
          "page": 10
        }
      ]
    },
    {
      "text": "Before running ANCOVA analyses, we also examined the correlations among all dependent variables.",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.11286363636363637,
          "width": 0.39502941176470574,
          "height": 0.011320707070707065,
          "page": 10
        },
        {
          "left": 0.5195343137254902,
          "top": 0.12669949494949495,
          "width": 0.21324509803921565,
          "height": 0.011320707070707065,
          "page": 10
        }
      ]
    },
    {
      "text": "Similarly, we ran ANCOVA analyses to compare each chatbots performance metrics between Group w/o iChatProfile and the baseline (128 transcripts), and between Group w/ iChatProfile and the baseline, respectively.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.729260101010101,
          "width": 0.376281045751634,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7430972222222222,
          "width": 0.3950424836601308,
          "height": 0.011332070707070763,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7569343434343434,
          "width": 0.39255392156862745,
          "height": 0.011332070707070763,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7707714646464646,
          "width": 0.12929901960784312,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Since all the designers were given the same goal to improve a chatbot along three dimensions, our analyses were to answer two questions:",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.8015795454545455,
          "width": 0.3762745098039215,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8154166666666666,
          "width": 0.3925555555555555,
          "height": 0.011320707070707092,
          "page": 10
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8292537878787879,
          "width": 0.06050816993464052,
          "height": 0.011320707070707092,
          "page": 10
        }
      ]
    },
    {
      "text": "Specifically, the designers in Group w/ iChatProfile appreciated the design suggestions and evidential conversation examples.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.671544191919192,
          "width": 0.376281045751634,
          "height": 0.01133207070707054,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6853813131313131,
          "width": 0.3694411764705883,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "In comparison, the chatbot customizations made by designers in Group w/o iChatProfile were fewer and with a higher percentage of unmatched chatbot customizations (43% vs. 33% in Group w/ iChatProfile )  customizations that were not suggested by iChatProfile .",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.5193371212121212,
          "width": 0.3762794117647059,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5331742424242424,
          "width": 0.39256209150326793,
          "height": 0.011332070707070763,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5470113636363636,
          "width": 0.39402614379084977,
          "height": 0.011332070707070763,
          "page": 11
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5608484848484848,
          "width": 0.3948169934640522,
          "height": 0.011332070707070652,
          "page": 11
        }
      ]
    },
    {
      "text": "Recall that at the beginning of their task, all designers were asked to comment on the baseline chatbot and their plan to improve it.",
      "bboxes": [
        {
          "left": 0.08790522875816993,
          "top": 0.5608484848484848,
          "width": 0.392562091503268,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.574685606060606,
          "width": 0.37197222222222226,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "During the post-task interviews, all participants from Group w/ iChatProfile confirmed the helpfulness of iChatProfile and benefited from the displayed chatbot profile, design suggestions, and evidential conversation examples.",
      "bboxes": [
        {
          "left": 0.2008529411764706,
          "top": 0.40864141414141414,
          "width": 0.27960620915032675,
          "height": 0.011320707070707092,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.42247853535353536,
          "width": 0.3940261437908497,
          "height": 0.011332070707070707,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4363156565656566,
          "width": 0.39256372549019614,
          "height": 0.011332070707070707,
          "page": 11
        },
        {
          "left": 0.08790522875816993,
          "top": 0.4501527777777778,
          "width": 0.30732026143790847,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Inspiring Designers to Make Creative Chatbot Improvements",
      "bboxes": [
        {
          "left": 0.5195343137254902,
          "top": 0.86527398989899,
          "width": 0.34892810457516343,
          "height": 0.011320707070707092,
          "page": 11
        }
      ]
    },
    {
      "text": "Additionally, iChatProfile currently produces evidential conversation examples along with design suggestions, which proved to be helpful for designers in our study.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.389020202020202,
          "width": 0.3787565359477123,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4028573232323232,
          "width": 0.39256045751633983,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.4166944444444444,
          "width": 0.19760784313725488,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "While our results should be widely applicable for building a class of interview chatbots, the scope and the participants of our study present its limitations.",
      "bboxes": [
        {
          "left": 0.3112009803921569,
          "top": 0.5877941919191919,
          "width": 0.1692712418300653,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08736437908496732,
          "top": 0.6016313131313131,
          "width": 0.39310130718954256,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.6154684343434343,
          "width": 0.3659852941176471,
          "height": 0.011320707070706981,
          "page": 12
        }
      ]
    },
    {
      "text": "Although our ultimate goal is to help designers build effective interview chatbots, we have not yet evaluated the usability of iChatProfile for two reasons.",
      "bboxes": [
        {
          "left": 0.7540898692810457,
          "top": 0.5257070707070707,
          "width": 0.15800980392156883,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5395441919191919,
          "width": 0.392563725490196,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.5533813131313131,
          "width": 0.3589950980392157,
          "height": 0.011332070707070763,
          "page": 12
        }
      ]
    },
    {
      "text": "One possible direction of future work is to construct a multi-layer framework for evaluating the performance of interview chatbots.",
      "bboxes": [
        {
          "left": 0.5358137254901961,
          "top": 0.8600606060606061,
          "width": 0.3765669934640522,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.8738977272727272,
          "width": 0.3948153594771241,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "As mentioned in Section 6.3.1, iChatProfile provides explanations on why certain design suggestions are given.",
      "bboxes": [
        {
          "left": 0.6934313725490197,
          "top": 0.7355277777777778,
          "width": 0.2201274509803921,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7493648989898989,
          "width": 0.3925669934640523,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7632020202020202,
          "width": 0.035955882352941115,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "In addition to guiding designers to make practical chatbot improvements, iChatProfile also inspired designers to make creative chatbot improvements beyond what was suggested by the tool.",
      "bboxes": [
        {
          "left": 0.10418464052287582,
          "top": 0.2921616161616162,
          "width": 0.37875490196078443,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3059987373737374,
          "width": 0.392562091503268,
          "height": 0.011332070707070652,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.31983459595959596,
          "width": 0.3948202614379085,
          "height": 0.011320707070707037,
          "page": 12
        }
      ]
    },
    {
      "text": "While our study results are encouraging, the study also revealed several limitations.",
      "bboxes": [
        {
          "left": 0.08720261437908497,
          "top": 0.5022436868686868,
          "width": 0.39326633986928106,
          "height": 0.011320707070707092,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.516080808080808,
          "width": 0.11572712418300656,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "Currently, iChatProfile often offers multiple design suggestions per performance metric.",
      "bboxes": [
        {
          "left": 0.38161764705882356,
          "top": 0.7770391414141413,
          "width": 0.10031372549019607,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7908762626262626,
          "width": 0.39255555555555555,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.08790522875816993,
          "top": 0.8047133838383838,
          "width": 0.04083333333333332,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "There are several directions that we can extend iChatProfile to refine its functions and expand its uses.",
      "bboxes": [
        {
          "left": 0.51909477124183,
          "top": 0.6957007575757576,
          "width": 0.393,
          "height": 0.011332070707070763,
          "page": 12
        },
        {
          "left": 0.5195343137254902,
          "top": 0.7095378787878788,
          "width": 0.19742156862745097,
          "height": 0.011320707070707092,
          "page": 12
        }
      ]
    },
    {
      "text": "We described a computational framework for evaluating interview chatbots and presented iChatProfile , a tool that helps designers to evaluate and improve interview chatbots iteratively.",
      "bboxes": [
        {
          "left": 0.5188316993464052,
          "top": 0.13015909090909092,
          "width": 0.3938120915032681,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.5195343137254902,
          "top": 0.14399621212121214,
          "width": 0.39256535947712423,
          "height": 0.01133207070707068,
          "page": 13
        },
        {
          "left": 0.5195343137254902,
          "top": 0.15783333333333335,
          "width": 0.3397516339869282,
          "height": 0.011320707070707065,
          "page": 13
        }
      ]
    },
    {
      "text": "As our studies show, it is difficult for designers to evaluate chatbot performance without any guidance.",
      "bboxes": [
        {
          "left": 0.39495098039215687,
          "top": 0.2862638888888889,
          "width": 0.08551470588235294,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.3001010101010101,
          "width": 0.3925539215686275,
          "height": 0.011320707070707037,
          "page": 13
        },
        {
          "left": 0.08736437908496732,
          "top": 0.3139381313131313,
          "width": 0.1302418300653595,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "Our work demonstrates the effectiveness of iChatProfile for helping designers to evaluate and improve an interview chatbot iteratively.",
      "bboxes": [
        {
          "left": 0.45753431372549025,
          "top": 0.7493648989898989,
          "width": 0.023209150326797323,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08736437908496732,
          "top": 0.7632020202020202,
          "width": 0.39557679738562096,
          "height": 0.011332070707070763,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.7770391414141413,
          "width": 0.3948202614379085,
          "height": 0.011320707070707092,
          "page": 13
        }
      ]
    },
    {
      "text": "Although we showed how iChatProfile was able to help improve chatbot performance significantly within just one iteration of design, building an effective interview chatbot often takes multiple iterations.",
      "bboxes": [
        {
          "left": 0.40095588235294116,
          "top": 0.5011767676767677,
          "width": 0.07950163398692817,
          "height": 0.011320707070707092,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5150138888888889,
          "width": 0.395031045751634,
          "height": 0.011332070707070652,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5288510101010101,
          "width": 0.39502941176470585,
          "height": 0.011320707070706981,
          "page": 13
        },
        {
          "left": 0.08790522875816993,
          "top": 0.5426881313131313,
          "width": 0.39482189542483653,
          "height": 0.011320707070706981,
          "page": 13
        }
      ]
    }
  ]
}