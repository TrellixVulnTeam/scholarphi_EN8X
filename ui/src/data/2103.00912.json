[
  {
    "text": "we outline existing analysis concepts",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8460457516339869,
        "top": 0.3078901515151515,
        "width": 0.06605228758169934,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3217272727272727,
        "width": 0.1550081699346405,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our work builds on this idea",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.7942140522875818,
        "top": 0.6861022727272728,
        "width": 0.11787908496732014,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6999393939393939,
        "width": 0.05234967320261441,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our work on new quantitative methods and tools for analyzing elicitation data",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2653872549019608,
        "top": 0.7506742424242424,
        "width": 0.21755718954248365,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7645113636363637,
        "width": 0.25261437908496737,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our focus lies in particular on the exploration",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.7558872549019608,
        "top": 0.8705959595959595,
        "width": 0.1564836601307188,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.10708333333333342,
        "height": 0.011332070707070652,
        "page": 1
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we extend the computational toolbox",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.20559313725490194,
        "top": 0.8198598484848484,
        "width": 0.22576797385620914,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we adapt similar visualization concepts",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08736437908496732,
        "top": 0.8014103535353535,
        "width": 0.23594117647058827,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we propose in this work facilitates a richer exploration",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08736437908496732,
        "top": 0.275604797979798,
        "width": 0.3337450980392157,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we refer to section",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.46343790849673205,
        "top": 0.3309520202020202,
        "width": 0.017027777777777753,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3447891414141414,
        "width": 0.0903235294117647,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our work are tools",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.18558496732026145,
        "top": 0.6076919191919191,
        "width": 0.15528267973856205,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we use a variational autoencoder",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08736437908496732,
        "top": 0.4969962121212121,
        "width": 0.1987173202614379,
        "height": 0.011320707070707037,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we therefore combine an abstract 2d mapping",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.3312614379084967,
        "top": 0.5661818181818182,
        "width": 0.14920751633986934,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5800189393939394,
        "width": 0.12394771241830065,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our knowledge , gesturemap is the first tool",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.19493954248366013,
        "top": 0.8290845959595959,
        "width": 0.2855245098039215,
        "height": 0.011332070707070763,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we combine interactive k - means clustering",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.3372205882352941,
        "top": 0.8567588383838384,
        "width": 0.1432418300653595,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8705959595959595,
        "width": 0.11925980392156861,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we included further ideas",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6629983660130719,
        "top": 0.647344696969697,
        "width": 0.1493382352941176,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we introduce a structured analysis approach based",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.505530303030303,
        "width": 0.29742483660130725,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we motivate the conceptual features",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.7500245098039215,
        "top": 0.5193674242424242,
        "width": 0.16207189542483658,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5332045454545454,
        "width": 0.04836437908496727,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we focus on researchers",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8943741830065359,
        "top": 0.8567588383838384,
        "width": 0.01772385620915029,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.11984640522875811,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we thus conceptualized the gesture map",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8621176470588235,
        "top": 0.7254166666666666,
        "width": 0.0499738562091504,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7392537878787879,
        "width": 0.1848725490196078,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we use a map metaphor",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.17359967320261438,
        "top": 0.5552373737373737,
        "width": 0.14689869281045753,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we describe how users can interact",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5523235294117647,
        "top": 0.2945,
        "width": 0.20933333333333348,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our prototype users can thus hover over the map",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6470065359477124,
        "top": 0.5984772727272728,
        "width": 0.26508660130718953,
        "height": 0.011320707070706981,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6123131313131314,
        "width": 0.04060457516339866,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our map view affords different plots",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.18536601307189543,
        "top": 0.1372348484848485,
        "width": 0.22188888888888886,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we describe the map concept",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.12377124183006537,
        "top": 0.5061073232323232,
        "width": 0.1728954248366013,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we include an export functionality",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.13400326797385623,
        "top": 0.4475441919191919,
        "width": 0.2041143790849673,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we also provide an interactive clustering method",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.1795343137254902,
        "top": 0.3984141414141414,
        "width": 0.2856372549019608,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "us to further explore data - driven measures",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6607941176470589,
        "top": 0.6177992424242424,
        "width": 0.2512990196078432,
        "height": 0.011320707070706981,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we employ the dtw barycenter averaging ( dba ) algorithm by petitjean et al",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.33764772727272724,
        "width": 0.3936405228758171,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.35148484848484846,
        "width": 0.08402777777777781,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we refer the reader",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8624656862745097,
        "top": 0.3929962121212121,
        "width": 0.04991176470588243,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4068320707070707,
        "width": 0.060714052287581755,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we might be interested in comparing the behavior",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.13939705882352943,
        "top": 0.5890757575757576,
        "width": 0.30020261437908496,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we see this approach",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5991862745098039,
        "top": 0.8844318181818183,
        "width": 0.12868300653594777,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we introduce the concept",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08720261437908497,
        "top": 0.8567588383838384,
        "width": 0.15442483660130718,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we then measure the dtw distance",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6869848484848484,
        "width": 0.21891176470588225,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we report the variance",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.637687908496732,
        "top": 0.7146578282828283,
        "width": 0.1320506535947713,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we next describe the technical approach",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.29272474747474747,
        "width": 0.24181372549019609,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we used a server - client architecture",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.20918686868686867,
        "width": 0.22589379084967331,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we use the plotlyjs library",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8700849673202614,
        "top": 0.2506982323232323,
        "width": 0.04200653594771253,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2645353535353535,
        "width": 0.1122303921568627,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we used the flask framework",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.7656045751633987,
        "top": 0.2645353535353535,
        "width": 0.14895915032679719,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5189918300653594,
        "top": 0.27837121212121213,
        "width": 0.03097549019607837,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we cached expensive computations",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5694150326797386,
        "top": 0.29220833333333335,
        "width": 0.2106078431372549,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we follow their perspective",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5878431372549019,
        "top": 0.37799873737373735,
        "width": 0.17257352941176485,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we consider four existing datasets",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.477625,
        "width": 0.2051699346405229,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we first focus on the dataset",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6618676470588235,
        "top": 0.5052979797979799,
        "width": 0.16253267973856222,
        "height": 0.011320707070706981,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we followed the original authors",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8400571895424837,
        "top": 0.5329722222222222,
        "width": 0.07204411764705887,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5468093434343434,
        "width": 0.11852614379084969,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we trained the vae",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.646435606060606,
        "width": 0.12479738562091491,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we adapted the architecture",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8930147058823529,
        "top": 0.6602727272727273,
        "width": 0.01908333333333334,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6741098484848485,
        "width": 0.14464052287581697,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we used a weight term",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6565114379084968,
        "top": 0.7017840909090909,
        "width": 0.1334852941176471,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we trained for 2000 epochs",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8267401960784313,
        "top": 0.7156212121212122,
        "width": 0.08563562091503274,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7294583333333333,
        "width": 0.07252287581699346,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we further see , for example",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.893156862745098,
        "top": 0.8705959595959595,
        "width": 0.018934640522875967,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.14740522875816986,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we experimented with different numbers",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.7432954545454546,
        "width": 0.24949019607843126,
        "height": 0.011320707070706981,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we provide the training scripts",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6980294117647059,
        "top": 0.7848055555555556,
        "width": 0.18777124183006533,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we experimented with the k - means algorithm",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08736437908496732,
        "top": 0.3709936868686869,
        "width": 0.2730359477124183,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we motivate this choice",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.1947140522875817,
        "top": 0.3848308080808081,
        "width": 0.1394297385620915,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we used a variational autoencoder ( vae",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.5910883838383838,
        "width": 0.2434395424836603,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we reflect on other possible choices",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.6325984848484848,
        "width": 0.21435784313725492,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we implemented gesturemap",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08720261437908497,
        "top": 0.4997550505050505,
        "width": 0.17130065359477128,
        "height": 0.011332070707070707,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we describe the key implementation aspects",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.38923529411764707,
        "top": 0.527429292929293,
        "width": 0.0912303921568628,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5412664141414142,
        "width": 0.17030228758169935,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we use k - means",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.43846078431372554,
        "top": 0.19681060606060605,
        "width": 0.042008169934640516,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.21064772727272726,
        "width": 0.049908496732026145,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we implemented all ui views",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2147581699346405,
        "top": 0.6008421717171717,
        "width": 0.168031045751634,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we defined a consensus measure",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7416148989898991,
        "width": 0.21047385620915035,
        "height": 0.011320707070707092,
        "page": 6
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we can identify similarity",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2875392156862745,
        "top": 0.6032449494949494,
        "width": 0.16602777777777783,
        "height": 0.011320707070707092,
        "page": 6
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "their referents included crouch , draw a flower",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.41687581699346404,
        "top": 0.5617335858585858,
        "width": 0.06606372549019612,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.575570707070707,
        "width": 0.2637745098039216,
        "height": 0.011332070707070763,
        "page": 6
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our variance measure also reflects this ( aloba adults",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.25297875816993465,
        "top": 0.688070707070707,
        "width": 0.22748692810457521,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.0874656862745098,
        "top": 0.7019078282828282,
        "width": 0.0877450980392157,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we again used the dataset",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8215669934640523,
        "top": 0.6353661616161616,
        "width": 0.09053104575163395,
        "height": 0.011320707070707203,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6492032828282828,
        "width": 0.0643137254901961,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we recorded the interviews",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8169477124183007,
        "top": 0.6492032828282828,
        "width": 0.09514542483660138,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6630404040404041,
        "width": 0.06501307189542482,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we encouraged them",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5877483660130719,
        "top": 0.6630404040404041,
        "width": 0.12336437908496733,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we took notes",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.798359477124183,
        "top": 0.6768775252525252,
        "width": 0.08754248366013073,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we compared behavior diversity",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2423562091503268,
        "top": 0.7157449494949495,
        "width": 0.1948169934640523,
        "height": 0.011332070707070763,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we introduced gesturemap ( 20 minutes",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.7322303921568627,
        "top": 0.7322260101010101,
        "width": 0.17986437908496744,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7460618686868686,
        "width": 0.055970588235294105,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we asked them",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5645441176470588,
        "top": 0.8290845959595959,
        "width": 0.08733986928104565,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we demonstrate this by creating a gesture map using four datasets",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.13633169934640524,
        "top": 0.5912108585858585,
        "width": 0.3441323529411764,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6050479797979798,
        "width": 0.048040849673202615,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we recruited eight hci researchers ( 7 male",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.27084313725490194,
        "top": 0.8290845959595959,
        "width": 0.2096258169934641,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.0874656862745098,
        "top": 0.8429217171717173,
        "width": 0.048612745098039215,
        "height": 0.011320707070706981,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our proposed clustering analysis we removed the referent labels",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.18295424836601307,
        "top": 0.15453030303030305,
        "width": 0.2975081699346406,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.16836742424242426,
        "width": 0.08746732026143793,
        "height": 0.011320707070707037,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we return to ideas",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.14792973856209152,
        "top": 0.4086868686868687,
        "width": 0.11033660130718953,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we applied clustering",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.24090032679738563,
        "top": 0.4225227272727272,
        "width": 0.12445588235294122,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we ran the clustering",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.17876960784313725,
        "top": 0.19604166666666664,
        "width": 0.13427287581699346,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we then inspected the mix",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.15150816993464053,
        "top": 0.20987878787878786,
        "width": 0.1590277777777778,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we repeated this ten times and made these observations",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.36004575163398694,
        "top": 0.22371590909090908,
        "width": 0.12041993464052286,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.2375530303030303,
        "width": 0.21230718954248368,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our zoom was implemented to always keep an 11   11 grid",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2900669934640523,
        "top": 0.5478156565656566,
        "width": 0.19040196078431376,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5616527777777778,
        "width": 0.10901797385620914,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our interactive clustering , for example , by plugging in the cluster cardinalities",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.39283986928104575,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.07302124183006542,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we asked the researchers",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2714346405228758,
        "top": 0.34491540404040405,
        "width": 0.14662418300653596,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we noticed that all participants preferred the scatter plot over the density plot",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.08736437908496732,
        "top": 0.3725896464646465,
        "width": 0.39310130718954256,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3864267676767677,
        "width": 0.07540849673202614,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we discuss further in section",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.27665359477124185,
        "top": 0.6031641414141414,
        "width": 0.17275000000000007,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we asked people",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6898872549019608,
        "top": 0.2471439393939394,
        "width": 0.09730392156862744,
        "height": 0.011320707070707065,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we asked the participants what the main aspect was that they used to determine interesting behavioral patterns",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.300125816993464,
        "top": 0.6261830808080808,
        "width": 0.18033496732026139,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.640020202020202,
        "width": 0.39502941176470585,
        "height": 0.011320707070706981,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6538573232323233,
        "width": 0.12704901960784315,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we quickly skimmed through the gestures using the map",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.3055032679738562,
        "top": 0.32550126262626267,
        "width": 0.17496241830065362,
        "height": 0.011320707070706981,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.33933838383838383,
        "width": 0.16173039215686275,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we chose k - means",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.2985098039215686,
        "top": 0.35317550505050505,
        "width": 0.11732516339869287,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we can imagine that average gestures calculated with the dba - algorithm can be used",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.22212418300653594,
        "top": 0.4361969696969697,
        "width": 0.260812091503268,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4500340909090909,
        "width": 0.24764542483660135,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we contribute to the vision",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.6201372549019608,
        "top": 0.6655568181818181,
        "width": 0.16622222222222216,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we expect computational methods",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5189918300653594,
        "top": 0.7209040404040404,
        "width": 0.20068137254901963,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our learned representation supports gesture simulation",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.41180065359477125,
        "top": 0.5701123737373738,
        "width": 0.0686683006535948,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.583949494949495,
        "width": 0.26234150326797384,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our key contribution , we presented a set",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.5391650326797386,
        "top": 0.4995126262626262,
        "width": 0.24831045751633984,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we used a vae",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.34698529411764706,
        "top": 0.2054229797979798,
        "width": 0.08759477124183013,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we could embed live sensor data",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8950669934640522,
        "top": 0.30327777777777776,
        "width": 0.017027777777777864,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.317114898989899,
        "width": 0.17436928104575156,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we could consolidate our findings",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.19106209150326797,
        "top": 0.6951691919191919,
        "width": 0.22595588235294117,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we highlight model",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.12377124183006537,
        "top": 0.1268560606060606,
        "width": 0.11632843137254902,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "we outline further ideas enabled",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.12014379084967321,
        "top": 0.6442765151515152,
        "width": 0.18971732026143795,
        "height": 0.011320707070706981,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "our clustering tool , to train a classifier",
    "label": "Author",
    "bboxes": [
      {
        "left": 0.8623496732026145,
        "top": 0.10956060606060607,
        "width": 0.05221732026143788,
        "height": 0.011320707070707065,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.12339772727272727,
        "width": 0.185545751633987,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": null,
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Addressing this, we extend the computational toolbox for analyzing gesture elicitation data with these contributions:",
    "label": "Contribution",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.8198598484848484,
        "width": 0.3787565359477124,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8336969696969697,
        "width": 0.33052614379084966,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "[34] identified four evaluation strategies for toolkit contributions.",
    "label": "Contribution",
    "bboxes": [
      {
        "left": 0.583875816993464,
        "top": 0.36416161616161613,
        "width": 0.3306895424836602,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.37799873737373735,
        "width": 0.06315359477124183,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "With this work, we contribute to the vision of more widespread use of applicable computational methods in HCI, also to support more extensive and cost-efficient large-scale, data-driven HCI work.",
    "label": "Contribution",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.6655568181818181,
        "width": 0.39326633986928106,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6793926767676767,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.693229797979798,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "As our key contribution, we presented a set of visualization and analysis concepts for gesture elicitation data and a tool that implements them: GestureMap is the first visual analytics tool for gesture elicitation which directly visualises the space of gestures, using a learned 2D embedding.",
    "label": "Contribution",
    "bboxes": [
      {
        "left": 0.5190212418300654,
        "top": 0.4995126262626262,
        "width": 0.39307189542483667,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5133497474747475,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.527185606060606,
        "width": 0.39283660130718956,
        "height": 0.011332070707070652,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5410227272727273,
        "width": 0.39417320261437905,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5548598484848485,
        "width": 0.17934477124183013,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, these measures rely on subjectively assessing the similarity of the observed gestures: They require researchers to group proposals into subgroups that they consider identical, which is usually done by manual annotation based on watching videos of the participants in the study [28, 39].",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.5615694444444445,
        "width": 0.3787565359477123,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5754065656565657,
        "width": 0.39255392156862745,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5892436868686869,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6030795454545455,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6169166666666667,
        "width": 0.22236601307189552,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Video analysis has been the preferred evaluation method, but the annotation of individual video sequences can be timeconsuming [51].",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5761339869281046,
        "top": 0.7737361111111111,
        "width": 0.3375686274509805,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7875732323232324,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8014103535353535,
        "width": 0.094326797385621,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Thus, researchers devised different ways to distribute the work among people [1, 36].",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7561699346405228,
        "top": 0.8290845959595959,
        "width": 0.1559248366013073,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8429217171717173,
        "width": 0.35234150326797387,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "This section briefly describes gesture elicitation studies, followed by an overview of tools that support researchers across different tasks involved in analyzing elicitation data.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.8852549019607843,
        "top": 0.26638005050505054,
        "width": 0.026838235294117774,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2802171717171717,
        "width": 0.39255718954248375,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2940542929292929,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3078901515151515,
        "width": 0.23586111111111108,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Our work builds on this idea, extends its data-driven perspective with a visual analytics tool, and introduces a new measure fitting this visualization.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7942140522875818,
        "top": 0.6861022727272728,
        "width": 0.11787908496732014,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6999393939393939,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7137765151515152,
        "width": 0.361483660130719,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Although central to HCI, the field has developed few dedicated methods and tools for supporting the (joint) exploration of such user-sensor spaces (cf. [65]).",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.1510719696969697,
        "width": 0.3762761437908496,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1649078282828283,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.17874494949494948,
        "width": 0.16877450980392156,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Addressing this, we extend the computational toolbox for analyzing gesture elicitation data with these contributions:",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.8198598484848484,
        "width": 0.3787565359477124,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8336969696969697,
        "width": 0.33052614379084966,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "The third visualization is similar to the second, but additionally employs a heat-map to emphasize the time domain.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.16168300653594772,
        "top": 0.1649078282828283,
        "width": 0.3187859477124183,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.17874494949494948,
        "width": 0.38285947712418306,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Also related to our work are tools to analyze and visualize machine learned representations of complex data: Deep learning models are capable of learning human-understandable features of high-dimensional data: For example, Kingma and Welling [30] and Lawrence [33] sample multiple points from the learned space and visualize them to demonstrate that the learned space is continuous and smooth, but without providing interaction functionalities.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.6076919191919191,
        "width": 0.3762745098039215,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6215290404040403,
        "width": 0.39256699346405227,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6353661616161616,
        "width": 0.3925653594771242,
        "height": 0.011320707070707203,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6492032828282828,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6630404040404041,
        "width": 0.39256535947712423,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08753921568627451,
        "top": 0.6768775252525252,
        "width": 0.39540359477124176,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6907146464646465,
        "width": 0.39481372549019605,
        "height": 0.011320707070706981,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "However, these highly abstract visualizations may occlude the nature of the underlying data.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.11820098039215686,
        "top": 0.5385075757575758,
        "width": 0.362264705882353,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.552344696969697,
        "width": 0.18206372549019612,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Our map view affords different plots on top of it, such as:",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.18536601307189543,
        "top": 0.1372348484848485,
        "width": 0.29671405228758174,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1510719696969697,
        "width": 0.047176470588235306,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "This work motivates us to further explore data-driven measures of consensus: We follow a similar approach, but instead of regressing on the DTW distance values, and relying on pairwise comparisons, we directly compute an average sequence from all gesture proposals in a referent group, using DBA.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6177992424242424,
        "width": 0.3762794117647059,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6316363636363636,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6454734848484848,
        "width": 0.39503267973856215,
        "height": 0.011320707070707203,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.659310606060606,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6731477272727273,
        "width": 0.24893464052287584,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, a complex gesture may be represented as an intricate path that may meander across the map.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.148,
        "top": 0.7136085858585859,
        "width": 0.3324591503267974,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.727445707070707,
        "width": 0.28950326797385617,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Additionally, color codes facilitate the comparison of behavior across different referents.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.3118415032679739,
        "top": 0.32164393939393937,
        "width": 0.1711045751633986,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.33548106060606064,
        "width": 0.3689509803921569,
        "height": 0.011320707070706981,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Regions in the gesture map that contain multiple embedded data points from different referents may indicate that this region encodes shared generic behavior.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.31061601307189546,
        "top": 0.3631553030303031,
        "width": 0.1698529411764706,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3769924242424242,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3908282828282828,
        "width": 0.37370261437908503,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Researchers can use it to detect overlapping or distinctive behavior across different referents.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.41058660130718955,
        "top": 0.44152272727272723,
        "width": 0.06987908496732026,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.45535984848484845,
        "width": 0.39503431372549025,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.46919696969696967,
        "width": 0.098390522875817,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "For example, in the elicitation context, we might be interested in comparing the behavior across different participants and experimental trials.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.3035866013071895,
        "top": 0.5752386363636364,
        "width": 0.17688235294117655,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5890757575757576,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6029128787878788,
        "width": 0.27089705882352944,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "For preprocessing, we followed the original authors [59] but left out the resampling step.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.7274705882352941,
        "top": 0.5329722222222222,
        "width": 0.18463071895424843,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5468093434343434,
        "width": 0.34044444444444444,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS 6.1 Datasets",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We experimented with different numbers of hidden neurons  : Overall, reconstruction loss decreases for larger models, regularized by the KL-loss, leading to diminishing returns and a decision for  = 512 here.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.7407815656565656,
        "width": 0.3780081699346405,
        "height": 0.013834595959596019,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7571325757575758,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7709684343434343,
        "width": 0.39283333333333337,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5188758169934641,
        "top": 0.7822916666666667,
        "width": 0.08020915032679732,
        "height": 0.013834595959596019,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS 6.2 Model Training",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, we experimented with the k-means algorithm, using DBA to calculate the centroids.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.41611437908496735,
        "top": 0.35715656565656567,
        "width": 0.06595915032679739,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08736437908496732,
        "top": 0.3709936868686869,
        "width": 0.39557679738562096,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3848308080808081,
        "width": 0.10362091503267974,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.3 Clustering Gestures with DBA & K-Means",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, a hierarchical treemap does not directly fit the map metaphor well.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.2810490196078432,
        "top": 0.4401792929292929,
        "width": 0.19941666666666663,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.45401641414141414,
        "width": 0.2623104575163399,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.3 Clustering Gestures with DBA & K-Means",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "This view shows different metrics, namely variances around the average gesture sequence per selected referent (Section 4.2), the distributions of DTW distances of proposals to their average gesture sequence, and nearest neighbor distances for a selected gesture.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.29735947712418304,
        "top": 0.8290845959595959,
        "width": 0.18558823529411766,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8429217171717173,
        "width": 0.3928333333333333,
        "height": 0.011320707070706981,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8567588383838384,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8705959595959595,
        "width": 0.3928398692810458,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8844318181818183,
        "width": 0.18832352941176472,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "5 IMPLEMENTATION OF GESTUREMAP 5.1 User Interface and Functionality",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, for instance, gestures proposed for crouch cover a different region (pink).",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.33991666666666664,
        "top": 0.6585934343434343,
        "width": 0.1421568627450981,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6724305555555556,
        "width": 0.3576960784313726,
        "height": 0.01133207070707054,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, GestureMap visually reveals that people interpreted crouch in different ways, matching the high variance (Figure 3",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.13862745098039217,
        "top": 0.8705959595959595,
        "width": 0.3418316993464052,
        "height": 0.011332070707070763,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8844318181818183,
        "width": 0.3925604575163399,
        "height": 0.011332070707070652,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.4 Local Observations",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, it did not separately find left hand and kicking, presumably since those were proposed only a few times.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.16477777777777777,
        "top": 0.4917083333333333,
        "width": 0.3156911764705883,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5055454545454545,
        "width": 0.38863235294117654,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.5 Interactive Clustering",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, the resulting computed centroids often deviated from peoples expectations, and thus did not immediately make sense to them.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.33016666666666666,
        "width": 0.3762777777777778,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3440037878787879,
        "width": 0.3925637254901959,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.35783964646464644,
        "width": 0.05133333333333323,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "These reassignments, however, were not yet considered when rerunning the clustering algorithm in the current implementation.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.8773627450980392,
        "top": 0.3993510101010101,
        "width": 0.034732026143790784,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4131881313131313,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.42702525252525253,
        "width": 0.33234313725490205,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, they noted that it should be more accurate and manually refined assignments need to be respected when rerunning the clustering algorithm, thus enabling iterative, interactive use.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.82375,
        "top": 0.45469949494949496,
        "width": 0.08872222222222226,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4685366161616162,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4823737373737374,
        "width": 0.392563725490196,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.49620959595959596,
        "width": 0.2933006535947712,
        "height": 0.011320707070707037,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, there were some complex paths (e.g. crossing over many poses on the map) that people were unable to assign to a group.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5685212418300654,
        "top": 0.1925820707070707,
        "width": 0.34357679738562075,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.20641919191919192,
        "width": 0.392563725490196,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.22025631313131314,
        "width": 0.0482549019607843,
        "height": 0.011320707070707037,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "GestureMap builds on and extends functionalities of previous tools for gesture elicitation: It combines",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.593854797979798,
        "width": 0.39255555555555555,
        "height": 0.011332070707070652,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6076919191919191,
        "width": 0.20948529411764716,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Summarising their initial experience, one person said: Although, the learning curve [...] is steep, once you understand the core concepts, this tool offers a great overview of the entire behavior that is captured in the dataset.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.22783823529411767,
        "top": 0.2803838383838384,
        "width": 0.25262745098039213,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.29422095959595956,
        "width": 0.39255392156862745,
        "height": 0.011332070707070707,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.30806944444444445,
        "width": 0.39255882352941174,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.32190656565656567,
        "width": 0.27039869281045753,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Some found similar poses encoded in different map regions and noted that these should ideally reside in one area.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.575489898989899,
        "width": 0.3762745098039215,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5893270202020202,
        "width": 0.2861258169934641,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "When we asked the participants what the main aspect was that they used to determine interesting behavioral patterns, we observed diverse analysis strategies, but we broadly highlight two main ones:",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.2615457516339869,
        "top": 0.6261830808080808,
        "width": 0.2189150326797385,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.640020202020202,
        "width": 0.39502941176470585,
        "height": 0.011320707070706981,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6538573232323233,
        "width": 0.3925555555555555,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6676944444444444,
        "width": 0.19891666666666669,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "1) Shape driven analysis: Some started by skimming through gestures to get an overview of their different path shapes on the map.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.6815315656565657,
        "width": 0.376281045751634,
        "height": 0.011332070707070763,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6953686868686868,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7092058080808081,
        "width": 0.02837091503267973,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "2) Position driven analysis: In contrast, other participants focused entirely on the scatter points as template poses.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7922272727272727,
        "width": 0.3762826797385621,
        "height": 0.011332070707070763,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.806064393939394,
        "width": 0.27795588235294116,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Hand-engineered features [4, 24, 58] may help with the interpretation, however, they may be specific to a sensor and interaction setup.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.26763888888888887,
        "top": 0.5147638888888889,
        "width": 0.21282679738562094,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5286010101010101,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5424381313131313,
        "width": 0.17657352941176468,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Separate maps could also compare gesture spaces for different contexts, devices, etc., for example, to better understand the influences of such factors.",
    "label": "Novelty",
    "bboxes": [
      {
        "left": 0.39225490196078433,
        "top": 0.7366805555555556,
        "width": 0.08821405228758178,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7505176767676768,
        "width": 0.39416503267973857,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.764354797979798,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Several tools have been created for more effective and objective analyses.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.75989898989899,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7737361111111111,
        "width": 0.052919934640522914,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To address this, Vatavu [59] has recently proposed a new, datadriven approach: It employs a distance measure as an objective basis for assessing consensus in elicitation studies.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6584280303030303,
        "width": 0.3787630718954248,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6722651515151514,
        "width": 0.39256045751633983,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6861022727272728,
        "width": 0.27102777777777776,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Fittingly, recent related work highlighted the need and feasibility of more objective, computational measures [59], and called for further computational models and measures, based on a survey of 216 elicitation studies [63].",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.344109477124183,
        "top": 0.7645113636363637,
        "width": 0.1363562091503268,
        "height": 0.011320707070706981,
        "page": 1
      },
      {
        "left": 0.08736437908496732,
        "top": 0.7783484848484848,
        "width": 0.39557679738562096,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.792185606060606,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8060227272727273,
        "width": 0.37513888888888886,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "In this work, we adapt similar visualization concepts with the goal to create an interpretable gesture space.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.4041045751633987,
        "top": 0.7875732323232324,
        "width": 0.07797875816993471,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08736437908496732,
        "top": 0.8014103535353535,
        "width": 0.3931078431372549,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8152474747474748,
        "width": 0.1641062091503268,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "2) Suitably visualising the projected data, considering the analysts tasks and goals.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.3462875816993464,
        "top": 0.45548484848484855,
        "width": 0.13418137254901963,
        "height": 0.011320707070707037,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.46932196969696965,
        "width": 0.35353594771241825,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The former targets questions that may span multiple referents or the entire dataset, while the latter focuses on a few gestures to identify specific behavioral idiosyncrasies.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.6013333333333334,
        "top": 0.79460101010101,
        "width": 0.3107647058823527,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8084381313131314,
        "width": 0.3931013071895425,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8222752525252525,
        "width": 0.3219411764705882,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We encouraged them to think out loud and occasionally asked questions to better understand actions.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5877483660130719,
        "top": 0.6630404040404041,
        "width": 0.32472058823529415,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6768775252525252,
        "width": 0.27511928104575156,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "7 USER STUDY 7.1 Procedure",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "1) We introduced GestureMap (20 minutes), with a concept presentation, a guided walk through the tool and UI, and opportunities for questions.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.7176421568627451,
        "top": 0.7322260101010101,
        "width": 0.194452614379085,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7460618686868686,
        "width": 0.39255392156862745,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.75989898989899,
        "width": 0.27017320261437905,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "7 USER STUDY 7.1 Procedure",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Central to gesture elicitation studies is an in-depth analysis of the proposed data to find common behavior.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.5062209595959596,
        "width": 0.3762859477124183,
        "height": 0.011320707070706981,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5200580808080808,
        "width": 0.28002124183006527,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To find behavioral patterns, it employs a variation of the smallmultiples plot [52] and an interactive hierarchical clustering interface visualized in a tree layout.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.0874656862745098,
        "top": 0.22025631313131314,
        "width": 0.39547875816993466,
        "height": 0.011320707070707037,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.23409343434343433,
        "width": 0.3950424836601308,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24793055555555554,
        "width": 0.20140686274509806,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Related tools [24, 41] show a 3D skeleton view with animation.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.7532826797385621,
        "top": 0.6967032828282829,
        "width": 0.15935620915032667,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7105404040404041,
        "width": 0.21068137254901964,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Using details on demand, users can hover over points to see the corresponding pose skeleton (Figure1b 2  ), and referent, participant and trial number in the detail view (Figure1b 6  ).",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.8083316993464053,
        "top": 0.40497727272727274,
        "width": 0.1037549019607843,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.41881439393939396,
        "width": 0.392563725490196,
        "height": 0.011332070707070707,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.43220959595959596,
        "width": 0.39255392156862745,
        "height": 0.011762626262626252,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4460467171717172,
        "width": 0.1718251633986928,
        "height": 0.011762626262626252,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Analysts can examine if empty regions are anatomically not feasible (cf. 8.3.3) or if people did not show such behaviour.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.836888888888889,
        "top": 0.6123131313131314,
        "width": 0.07520588235294112,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6261502525252526,
        "width": 0.3934460784313726,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6399873737373737,
        "width": 0.24943464052287578,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "After the initial data exploration it is often necessary to find concrete example for detected patterns.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.5614015151515152,
        "width": 0.3787630718954249,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5752386363636364,
        "width": 0.21201143790849675,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Overall, we see this approach as an additional measure, not",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5468366013071895,
        "top": 0.8844318181818183,
        "width": 0.36526143790849674,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We further see, for example, sitting (Figure 2B), clapping (Figure 2D),",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.893156862745098,
        "top": 0.8705959595959595,
        "width": 0.018934640522875967,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.39417320261437894,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We defined a consensus measure on this variability (Section 4.2): Comparing this variability between all referents, our results largely agree with Vatavu [59]: In particular, applaud, fly like a bird and hands up show high consensus while climb ladder, crouch, turn around have low consensus.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7416148989898991,
        "width": 0.37801633986928107,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7554520202020202,
        "width": 0.3929346405228758,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7692891414141415,
        "width": 0.3925604575163399,
        "height": 0.01133207070707054,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7831262626262626,
        "width": 0.3925588235294118,
        "height": 0.011332070707070763,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7969633838383839,
        "width": 0.16762091503267978,
        "height": 0.01133207070707054,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The gesture paths visit roughly similar main parts of the gesture space, yet the children do not find consensus.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.377171568627451,
        "top": 0.6603964646464646,
        "width": 0.10329084967320262,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08753921568627451,
        "top": 0.674233585858586,
        "width": 0.3954003267973857,
        "height": 0.011320707070706981,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.688070707070707,
        "width": 0.16141176470588237,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.6 Comparison Between Datasets",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, it did not separately find left hand and kicking, presumably since those were proposed only a few times.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.16477777777777777,
        "top": 0.4917083333333333,
        "width": 0.3156911764705883,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5055454545454545,
        "width": 0.38863235294117654,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.5 Interactive Clustering",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Some people noted that they struggled to find a specific pose on the map.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.16413562091503267,
        "top": 0.4786313131313132,
        "width": 0.31633496732026145,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4924684343434344,
        "width": 0.10396568627450979,
        "height": 0.011320707070707037,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Another researcher felt that the map should show more detail so it would be easier to judge differences and transitions of poses.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.3662908496732026,
        "top": 0.5063042929292929,
        "width": 0.11445588235294119,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5201414141414141,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5339785353535353,
        "width": 0.25072385620915033,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "This live embedding provides a monitoring tool, for example, for participants to see their currently performed gesture (e.g. shown as a cursor/point on the map), possibly to nudge them towards exploring new regions of the behavior space (cf. [65]).",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5955392156862745,
        "top": 0.3309520202020202,
        "width": 0.316828431372549,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3447891414141414,
        "width": 0.39255555555555544,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.51909477124183,
        "top": 0.3586262626262626,
        "width": 0.3930065359477125,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.37246338383838384,
        "width": 0.36488888888888904,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Instead, GestureMap could be used to show gestures to users, allowing them to reenact and explore them with live monitoring via the map.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.7108513071895425,
        "top": 0.42781186868686866,
        "width": 0.20124019607843135,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4416489898989899,
        "width": 0.39255555555555555,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.45548484848484855,
        "width": 0.23511928104575175,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "CHI 21, May 813, 2021, Yokohama, Japan",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.8551742424242424,
        "width": 0.19444607843137257,
        "height": 0.008805555555555622,
        "page": 0
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Researchers have therefore developed various measures to formalize the consensus among participants [56, 57, 61, 62, 67].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8050245098039216,
        "top": 0.5200580808080808,
        "width": 0.10707352941176462,
        "height": 0.011320707070706981,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.533895202020202,
        "width": 0.39255392156862745,
        "height": 0.011320707070706981,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5477323232323232,
        "width": 0.22874509803921572,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, while these measures set standards on how to compute consensus from gesture proposal, they cannot avoid subjectivity per se.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7455751633986928,
        "top": 0.6169166666666667,
        "width": 0.16651797385620926,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6307537878787879,
        "width": 0.39416830065359487,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6445909090909091,
        "width": 0.22300326797385617,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, researchers devised different ways to distribute the work among people [1, 36].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7561699346405228,
        "top": 0.8290845959595959,
        "width": 0.1559248366013073,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8429217171717173,
        "width": 0.35234150326797387,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "This section briefly describes gesture elicitation studies, followed by an overview of tools that support researchers across different tasks involved in analyzing elicitation data.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8852549019607843,
        "top": 0.26638005050505054,
        "width": 0.026838235294117774,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2802171717171717,
        "width": 0.39255718954248375,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.2940542929292929,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3078901515151515,
        "width": 0.23586111111111108,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In this way, elicitation studies inform gestural interaction with user-driven exploration: Most studies focus on the human behaviour space and thus do not rely on a specific sensor; they typically video-record participants for manual gesture analysis (e.g. [14, 28]).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.3447891414141414,
        "width": 0.3762777777777778,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3586262626262626,
        "width": 0.392562091503268,
        "height": 0.011332070707070707,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.37246338383838384,
        "width": 0.3929346405228758,
        "height": 0.011332070707070707,
        "page": 1
      },
      {
        "left": 0.08753921568627451,
        "top": 0.38630050505050506,
        "width": 0.39518300653594773,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Some additionally employ a sensor in elicitation (e.g. Leap [62], Kinect [56]), thus also potentially considering the senseable space .",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.4001376262626263,
        "width": 0.394171568627451,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4139747474747475,
        "width": 0.3910196078431373,
        "height": 0.011332070707070707,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "One successful method that has seen widespread use is the elicitation study paradigm [66], which helps HCI researchers and practitioners to explore the space of possible and intuitive or guessable (gesture) commands: Participants are shown a referent (often a system action, e.g. volume up ) and are asked to propose and perform a gesture they would use for it (e.g. turn wrist right ).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.2603202614379085,
        "top": 0.17874494949494948,
        "width": 0.22014542483660132,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08736437908496732,
        "top": 0.1925820707070707,
        "width": 0.3931062091503268,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.20641919191919192,
        "width": 0.39255555555555555,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.22025631313131314,
        "width": 0.39256045751633994,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.23409343434343433,
        "width": 0.39256372549019614,
        "height": 0.011332070707070735,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24793055555555554,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.26176767676767676,
        "width": 0.09808169934640522,
        "height": 0.011332070707070707,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Also related to our work are tools to analyze and visualize machine learned representations of complex data: Deep learning models are capable of learning human-understandable features of high-dimensional data: For example, Kingma and Welling [30] and Lawrence [33] sample multiple points from the learned space and visualize them to demonstrate that the learned space is continuous and smooth, but without providing interaction functionalities.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.6076919191919191,
        "width": 0.3762745098039215,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6215290404040403,
        "width": 0.39256699346405227,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6353661616161616,
        "width": 0.3925653594771242,
        "height": 0.011320707070707203,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6492032828282828,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6630404040404041,
        "width": 0.39256535947712423,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08753921568627451,
        "top": 0.6768775252525252,
        "width": 0.39540359477124176,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6907146464646465,
        "width": 0.39481372549019605,
        "height": 0.011320707070706981,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, these highly abstract visualizations may occlude the nature of the underlying data.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.11820098039215686,
        "top": 0.5385075757575758,
        "width": 0.362264705882353,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.552344696969697,
        "width": 0.18206372549019612,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "For example, these plots may hide the structure of a 3D skeleton recording.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.27362581699346405,
        "top": 0.552344696969697,
        "width": 0.20684640522875813,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5661818181818182,
        "width": 0.23968627450980395,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We therefore combine an abstract 2D mapping with a grid of representative 3D skeletons to give analysts a visual overview of the proposed gestures.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3312614379084967,
        "top": 0.5661818181818182,
        "width": 0.14920751633986934,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5800189393939394,
        "width": 0.3925637254901962,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.593854797979798,
        "width": 0.33941993464052295,
        "height": 0.011320707070706981,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "While we focus on researchers as users of this map in this paper, it could also be shown to participants as we described in Section 8.3.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8527107843137256,
        "top": 0.8567588383838384,
        "width": 0.05938725490196062,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.39256045751633983,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.3323578431372548,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Furthermore, some researchers indicated that participants may struggle to propose gestures, if they are unfamiliar with the gesture design space [9, 12, 46].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.7875732323232324,
        "width": 0.3766666666666666,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8014103535353535,
        "width": 0.39256045751633983,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8152474747474748,
        "width": 0.14316339869281047,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "They therefore modified elicitation such that people could choose from a predefined list of gesture proposals.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6665539215686275,
        "top": 0.8152474747474748,
        "width": 0.24554411764705864,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8290845959595959,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We thus conceptualized the gesture map to enable researchers to seamlessly cycle between the detection of new observations and the assessment of supporting evidence.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8621176470588235,
        "top": 0.7254166666666666,
        "width": 0.0499738562091504,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7392537878787879,
        "width": 0.39293464052287586,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7530896464646465,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7669267676767676,
        "width": 0.17910457516339862,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The former targets questions that may span multiple referents or the entire dataset, while the latter focuses on a few gestures to identify specific behavioral idiosyncrasies.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6013333333333334,
        "top": 0.79460101010101,
        "width": 0.3107647058823527,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8084381313131314,
        "width": 0.3931013071895425,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8222752525252525,
        "width": 0.3219411764705882,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, since gestures are sequences of poses, they are paths connecting multiple points on the map.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.0874656862745098,
        "top": 0.6382588383838383,
        "width": 0.3954787581699347,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6520959595959597,
        "width": 0.21705392156862746,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3.2 The Learned 2D Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The scatterplot may help researchers to detect outlier body poses, while the density plot reveals regions with recorded data.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6950245098039216,
        "top": 0.4464886363636364,
        "width": 0.21707026143790853,
        "height": 0.011320707070707037,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.46032575757575755,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5189918300653594,
        "top": 0.47416287878787877,
        "width": 0.11585947712418299,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In our prototype users can thus hover over the map to visualize 3D skeletons for any cursor location.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6309526143790849,
        "top": 0.5984772727272728,
        "width": 0.28114052287581703,
        "height": 0.011320707070706981,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6123131313131314,
        "width": 0.3138790849673203,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The first of many analysis steps often involves developing an overview of the data to understand its underlying properties: Researchers here often use statistical plots to summarize the data and to identify broad patterns.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6874803921568627,
        "top": 0.8429217171717173,
        "width": 0.2246078431372549,
        "height": 0.011320707070706981,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8567588383838384,
        "width": 0.39503104575163406,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.39255555555555544,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.30276307189542484,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 1,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "This feature helps to adjust the viewport to support exploration of datadense areas, and deal with the fact that landmark representations are discrete indicators for the continuous space.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.886281045751634,
        "top": 0.3289835858585859,
        "width": 0.02581209150326802,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3428207070707071,
        "width": 0.39504084967320263,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3566578282828283,
        "width": 0.39256209150326793,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.37049368686868683,
        "width": 0.28556209150326795,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus,bycomparingmultipleembeddedgesturepathsresearchers can visually assess gestures as similar or not.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7412828282828283,
        "width": 0.37739869281045757,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7551199494949494,
        "width": 0.26411111111111113,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Considering research interests in the elicitation context from the literature, for example, this might support researchers to examine if a participant can remember and repeat the same gesture proposal across multiple trials [40], or if behavior was influenced by a priming effect [6].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3556960784313726,
        "top": 0.7551199494949494,
        "width": 0.12476797385620908,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7689558080808081,
        "width": 0.3941666666666667,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7827929292929293,
        "width": 0.3950441176470589,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7966300505050505,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8104671717171718,
        "width": 0.3460114379084968,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Each scatter point corresponds to a pose from the dataset, whereas empty patches in the gesture map may indicate behavior that has not been observed (e.g. poses/gestures not proposed by participants during elicitation).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.21287745098039218,
        "top": 0.1649078282828283,
        "width": 0.2675882352941177,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.17874494949494948,
        "width": 0.3950294117647059,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1925820707070707,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.20641919191919192,
        "width": 0.26313235294117654,
        "height": 0.011320707070707037,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Scatter points may visually cluster near gesture poses that are characteristic for a particular referent.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.2812549019607843,
        "top": 0.22943939393939394,
        "width": 0.19949019607843144,
        "height": 0.011320707070707037,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24327651515151516,
        "width": 0.3948104575163399,
        "height": 0.011320707070707037,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In contrast, a complex gesture may be represented as an intricate path that may meander across the map.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.148,
        "top": 0.7136085858585859,
        "width": 0.3324591503267974,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.727445707070707,
        "width": 0.28950326797385617,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Regions in the gesture map that contain multiple embedded data points from different referents may indicate that this region encodes shared generic behavior.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.31061601307189546,
        "top": 0.3631553030303031,
        "width": 0.1698529411764706,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3769924242424242,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3908282828282828,
        "width": 0.37370261437908503,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Scatter plots may contain too much detail and clutter the visualization.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3535800653594771,
        "top": 0.4138484848484848,
        "width": 0.12936601307189538,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.08790522875816993,
        "top": 0.427685606060606,
        "width": 0.28333986928104576,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The gesture variance integrates well with GestureMap s visualization concept because this already displays the involved average gestures as visual elements.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.8290845959595959,
        "width": 0.3787647058823529,
        "height": 0.011332070707070763,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8429217171717173,
        "width": 0.39502941176470574,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8567588383838384,
        "width": 0.19691666666666674,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Moreover, this approach yields a one-number summary without a logistic regression model on top.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.721204248366013,
        "top": 0.8567588383838384,
        "width": 0.19089379084967317,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.023148692810457616,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 1,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Intuitively, for example, a high value VAR  may inform an analyst that referent  contains quite varied gesture proposals (i.e. low consensus).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8502679738562092,
        "top": 0.7875732323232324,
        "width": 0.06343300653594752,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8014103535353535,
        "width": 0.39255392156862734,
        "height": 0.011332070707070763,
        "page": 4
      },
      {
        "left": 0.5192418300653595,
        "top": 0.8127335858585858,
        "width": 0.369563725490196,
        "height": 0.01383459595959613,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Here demonstrate the use of GestureMap in a walkthrough of an explorative analysis: Examining the gesture map, the center (Figure 2C) reveals start/end poses (standing upright, arms at rest).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.8429217171717173,
        "width": 0.39256045751633994,
        "height": 0.01133207070707054,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8567588383838384,
        "width": 0.39503104575163406,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.369954248366013,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We motivate this choice by interpretability of the resulting centroids, versus the abstract representations in the hierarchical approach: In particular, the centroids (i.e. average/barycenter gestures) are more compatible with our 2D gesture map, on which they could be displayed as paths.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.1947140522875817,
        "top": 0.3848308080808081,
        "width": 0.28575163398692816,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3986679292929293,
        "width": 0.395031045751634,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.41250505050505054,
        "width": 0.39283333333333337,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.42634217171717176,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4401792929292929,
        "width": 0.1900277777777778,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.3 Clustering Gestures with DBA & K-Means",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We reflect on other possible choices in our discussion.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.6325984848484848,
        "width": 0.32296568627450983,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "a replacement of others: As a flexible tool, GestureMap can be extended to additionally display further such measures (e.g. the one by Vatavu [59]) to support researchers with the analysis.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.10956060606060607,
        "width": 0.395031045751634,
        "height": 0.011332070707070707,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.12339772727272727,
        "width": 0.392562091503268,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1372348484848485,
        "width": 0.3384232026143791,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, GestureMap visually reveals that people interpreted crouch in different ways, matching the high variance (Figure 3",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.13862745098039217,
        "top": 0.8705959595959595,
        "width": 0.3418316993464052,
        "height": 0.011332070707070763,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8844318181818183,
        "width": 0.3925604575163399,
        "height": 0.011332070707070652,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.4 Local Observations",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, the map reveals the space of poses elicited by Vatavu [59] at a glance: For example, their referents included crouch , draw a flower , draw a circle , draw a square , applaud or raise your hands , which all match the poses in our map.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.2764771241830066,
        "top": 0.5478964646464647,
        "width": 0.20399183006535948,
        "height": 0.011320707070706981,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5617335858585858,
        "width": 0.39503431372549025,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.575570707070707,
        "width": 0.394171568627451,
        "height": 0.011332070707070763,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5894078282828282,
        "width": 0.3946617647058824,
        "height": 0.011332070707070763,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The interviews lasted 80 minutes and were conducted via screensharing using Skype/Zoom, with GestureMap hosted online such that people could use it on their own computer.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.51909477124183,
        "top": 0.6076919191919191,
        "width": 0.39546895424836603,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6215290404040403,
        "width": 0.39255882352941185,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6353661616161616,
        "width": 0.2973104575163399,
        "height": 0.011320707070707203,
        "page": 7
      }
    ],
    "section": "7 USER STUDY 7.1 Procedure",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Thus, it seems to contain a more diverse set of body poses.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.23282679738562093,
        "top": 0.7572550505050505,
        "width": 0.2476356209150327,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7710921717171718,
        "width": 0.1044967320261438,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.6 Comparison Between Datasets",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We demonstrate this by creating a gesture map using four datasets [3, 8, 17, 59].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.13633169934640524,
        "top": 0.5912108585858585,
        "width": 0.3441323529411764,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6050479797979798,
        "width": 0.12689215686274508,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.6 Comparison Between Datasets",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Therefore, to demonstrate our proposed clustering analysis we removed the referent labels and then evaluated if k-means finds clusters that match the original referents.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.4193872549019608,
        "top": 0.14069318181818183,
        "width": 0.06268790849673195,
        "height": 0.011320707070707065,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.15453030303030305,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.16836742424242426,
        "width": 0.39256372549019614,
        "height": 0.011320707070707037,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.18220454545454548,
        "width": 0.1700686274509804,
        "height": 0.011320707070707037,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.5 Interactive Clustering",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, the resulting computed centroids often deviated from peoples expectations, and thus did not immediately make sense to them.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.33016666666666666,
        "width": 0.3762777777777778,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3440037878787879,
        "width": 0.3925637254901959,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.35783964646464644,
        "width": 0.05133333333333323,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "On the positive side, the researchers liked the refinement step, where they could reassign proposals to another cluster.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5831977124183007,
        "top": 0.3855138888888889,
        "width": 0.3288970588235294,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3993510101010101,
        "width": 0.3541960784313726,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "However, they noted that it should be more accurate and manually refined assignments need to be respected when rerunning the clustering algorithm, thus enabling iterative, interactive use.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.82375,
        "top": 0.45469949494949496,
        "width": 0.08872222222222226,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4685366161616162,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4823737373737374,
        "width": 0.392563725490196,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.49620959595959596,
        "width": 0.2933006535947712,
        "height": 0.011320707070707037,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "[1] proposed a crowd platform for annotation, yet without computational support for the workers, such as alternative gesture representations or similarity measures.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.673890522875817,
        "top": 0.718388888888889,
        "width": 0.24068300653594776,
        "height": 0.011320707070706981,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7322260101010101,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7460618686868686,
        "width": 0.36019934640522877,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Such support as shown in GestureMap could be combined with a crowd approach in the future.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.8834117647058823,
        "top": 0.7460618686868686,
        "width": 0.02868954248366007,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.75989898989899,
        "width": 0.39255882352941185,
        "height": 0.011332070707070763,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7737361111111111,
        "width": 0.14132516339869294,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "These could be used also with our interactive clustering, for example, by plugging in the cluster cardinalities instead of subjective gesture group counts.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7292254901960784,
        "top": 0.8567588383838384,
        "width": 0.18286928104575162,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8705959595959595,
        "width": 0.39283986928104575,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.33202124183006543,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Seeing this and related work as a toolbox, researchers may now consider various options: For example, AGATE 2.0 [61] is a highly specialized tool to compute agreement, which assumes a given labeled dataset.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6492032828282828,
        "width": 0.3766633986928104,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6630404040404041,
        "width": 0.39256209150326793,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6768775252525252,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6907146464646465,
        "width": 0.1291928104575164,
        "height": 0.011320707070706981,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "GestureMap could be used to label data and export it for analysis in tools like this.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.6523774509803921,
        "top": 0.6907146464646465,
        "width": 0.2597107843137254,
        "height": 0.011332070707070652,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7045517676767676,
        "width": 0.2268562091503269,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "These people found the animation particularly important: Seeing the 3D skeleton and the 2D path animated in sync highlighted that a gesture was a path on the map and thus helped them to get familiar with the map concept.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.4457336601307189,
        "top": 0.2250366161616162,
        "width": 0.034732026143790895,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.23887373737373735,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.25271085858585857,
        "width": 0.395031045751634,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.2665479797979798,
        "width": 0.3928333333333333,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08736437908496732,
        "top": 0.2803838383838384,
        "width": 0.13652777777777775,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "GestureMap s concepts support handling large data, visually summarised and explored via our map view.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5742303921568627,
        "top": 0.8152474747474748,
        "width": 0.34034640522875825,
        "height": 0.01133207070707054,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8290845959595959,
        "width": 0.28951797385620914,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Using expectations about possible behavior for a gesture proposal (e.g. left vs right hand throwing), they examined scatter points in those map regions that based on the landmark skeletons encoded related poses.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.36933496732026144,
        "top": 0.806064393939394,
        "width": 0.11113071895424836,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8199015151515151,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8337386363636364,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8475757575757575,
        "width": 0.3613660130718954,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "We chose k-means, because it readily integrates with the gesture map and the \"variance around mean gesture\" that we introduced in section 4.2.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.2985098039215686,
        "top": 0.35317550505050505,
        "width": 0.18195751633986929,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.36701262626262626,
        "width": 0.3925588235294118,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3808497474747474,
        "width": 0.2882712418300654,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "With this work, we contribute to the vision of more widespread use of applicable computational methods in HCI, also to support more extensive and cost-efficient large-scale, data-driven HCI work.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.6655568181818181,
        "width": 0.39326633986928106,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6793926767676767,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.693229797979798,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Hand-engineered features [4, 24, 58] may help with the interpretation, however, they may be specific to a sensor and interaction setup.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.26763888888888887,
        "top": 0.5147638888888889,
        "width": 0.21282679738562094,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5286010101010101,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5424381313131313,
        "width": 0.17657352941176468,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "While some models address this (e.g. we used a VAE instead of AE), there is no universal natural 2D layout of body poses and some artifacts are likely to exist for most models and datasets.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.12690196078431373,
        "top": 0.2054229797979798,
        "width": 0.3535669934640523,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.21926010101010102,
        "width": 0.39256699346405227,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.23309722222222223,
        "width": 0.37123039215686277,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "Besides technical model improvements, visualization concepts could be explored to address this as well (e.g. visually mark jumps along the gesture path).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.4628022875816994,
        "top": 0.23309722222222223,
        "width": 0.020135620915032626,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24693434343434345,
        "width": 0.39255882352941174,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.26077146464646467,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.2746085858585859,
        "width": 0.10466666666666667,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "GestureMap could be extended to more than post-hoc analysis: For example, we could embed live sensor data and continuously update the underlying mode.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.840735294117647,
        "top": 0.28945328282828287,
        "width": 0.07135784313725502,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.30327777777777776,
        "width": 0.39256045751633983,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.317114898989899,
        "width": 0.39503921568627465,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3309520202020202,
        "width": 0.07204575163398697,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "This live embedding provides a monitoring tool, for example, for participants to see their currently performed gesture (e.g. shown as a cursor/point on the map), possibly to nudge them towards exploring new regions of the behavior space (cf. [65]).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.5955392156862745,
        "top": 0.3309520202020202,
        "width": 0.316828431372549,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3447891414141414,
        "width": 0.39255555555555544,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.51909477124183,
        "top": 0.3586262626262626,
        "width": 0.3930065359477125,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.37246338383838384,
        "width": 0.36488888888888904,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "One could also predefine a gesture path to monitor live performances and to judge deviation from this template, possibly to learn/teach a movement sequence.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.887812091503268,
        "top": 0.37246338383838384,
        "width": 0.024279411764705938,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.38630050505050506,
        "width": 0.39255718954248364,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4001376262626263,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4139747474747475,
        "width": 0.13150490196078435,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Instead, GestureMap could be used to show gestures to users, allowing them to reenact and explore them with live monitoring via the map.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7108513071895425,
        "top": 0.42781186868686866,
        "width": 0.20124019607843135,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4416489898989899,
        "width": 0.39255555555555555,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.45548484848484855,
        "width": 0.23511928104575175,
        "height": 0.011320707070707037,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "As a community, we could consolidate our findings in a meta-map of many studies, as a sensor data-driven complement to literature surveys [63].",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.0873921568627451,
        "top": 0.6951691919191919,
        "width": 0.3930800653594771,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7090063131313131,
        "width": 0.3925653594771242,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7228434343434343,
        "width": 0.07565359477124182,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "For instance, such a map might reveal which gestures and poses are most common or intensely studied.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.16709150326797387,
        "top": 0.7228434343434343,
        "width": 0.31337745098039227,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7366805555555556,
        "width": 0.30065849673202616,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Separate maps could also compare gesture spaces for different contexts, devices, etc., for example, to better understand the influences of such factors.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.39225490196078433,
        "top": 0.7366805555555556,
        "width": 0.08821405228758178,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7505176767676768,
        "width": 0.39416503267973857,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.764354797979798,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "GestureMap could be extended to define new gestures: For example, users could draw a gesture as a path on the map.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.37192320261437906,
        "top": 0.7875732323232324,
        "width": 0.1085424836601308,
        "height": 0.011332070707070652,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8014103535353535,
        "width": 0.3925604575163399,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8152474747474748,
        "width": 0.1908169934640523,
        "height": 0.01133207070707054,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Since the underlying latent variable model can simulate new behavior (decoding), such a drawn path implicitly defines a pose sequence that could be exported as a template-based gesture recogniser.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.28298202614379087,
        "top": 0.8152474747474748,
        "width": 0.19996568627450978,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8290845959595959,
        "width": 0.39256372549019614,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8429217171717173,
        "width": 0.3925571895424837,
        "height": 0.011320707070706981,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8567588383838384,
        "width": 0.21679575163398696,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "As an alternative to drawing, users could demonstrate the gesture in front of the sensor, with a cursor moving on the map live.",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.3083415032679739,
        "top": 0.8567588383838384,
        "width": 0.17373529411764704,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8705959595959595,
        "width": 0.392562091503268,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.08625,
        "top": 0.8844318181818183,
        "width": 0.19968137254901963,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Users could also select recorded",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.28958496732026145,
        "top": 0.8844318181818183,
        "width": 0.19088071895424835,
        "height": 0.011332070707070652,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "GestureMap enables this: Researchers can explore map areas without data, which may reveal unlikely behavior, or indicate issues with interaction (e.g. anatomically difficult or tiring gestures) or the sensor (e.g. gestures leading to self-occlusion of body parts).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7628937908496732,
        "top": 0.1856641414141414,
        "width": 0.15092647058823538,
        "height": 0.011332070707070707,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1995012626262626,
        "width": 0.39255882352941185,
        "height": 0.011332070707070707,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.21333838383838383,
        "width": 0.39503267973856215,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.22717550505050504,
        "width": 0.39255882352941174,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.24101136363636363,
        "width": 0.1891650326797385,
        "height": 0.011320707070707065,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Such a recognizer then also could be used in other tools to support sensor feed annotation (e.g. [41]).",
    "label": "Conclusion",
    "bboxes": [
      {
        "left": 0.7087271241830065,
        "top": 0.12339772727272727,
        "width": 0.2033643790849674,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.1372348484848485,
        "width": 0.39465522875817005,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": 0.5,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Fittingly, recent related work highlighted the need and feasibility of more objective, computational measures [59], and called for further computational models and measures, based on a survey of 216 elicitation studies [63].",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.344109477124183,
        "top": 0.7645113636363637,
        "width": 0.1363562091503268,
        "height": 0.011320707070706981,
        "page": 1
      },
      {
        "left": 0.08736437908496732,
        "top": 0.7783484848484848,
        "width": 0.39557679738562096,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.792185606060606,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8060227272727273,
        "width": 0.37513888888888886,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "While elicitation studies have become a widely used staple in the HCI toolbox, they still present challenges (cf. [51, 63]), including the need for manual data analysis .",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.42781186868686866,
        "width": 0.3762794117647058,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4416489898989899,
        "width": 0.39255555555555555,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.45548484848484855,
        "width": 0.20079738562091504,
        "height": 0.011332070707070652,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "For further discussions on the comparison of these two systems we refer to section 8.2.2.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.3309520202020202,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3447891414141414,
        "width": 0.12409313725490194,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.2 Gesture Analysis Tools",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "2) motivated in calls for further improvements, and",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.8215882352941176,
        "top": 0.6196717171717171,
        "width": 0.0905081699346405,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6335088383838383,
        "width": 0.21861601307189538,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "3) explicitly requested from future work.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.7424983660130718,
        "top": 0.6335088383838383,
        "width": 0.16959967320261438,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.647344696969697,
        "width": 0.07213398692810458,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "In addition, we included further ideas.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5942385620915033,
        "top": 0.647344696969697,
        "width": 0.21809803921568627,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "The following paragraphs further introduce and motivate the features.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.7604460784313725,
        "top": 0.6611818181818181,
        "width": 0.15164869281045756,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6750189393939394,
        "width": 0.2628088235294117,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "The analysis concept is structured further by differentiating between global observations and local observations.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.7027173202614378,
        "top": 0.7669267676767676,
        "width": 0.20938071895424826,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7807638888888889,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.79460101010101,
        "width": 0.07810947712418304,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.4 Analysis Concepts Using the Gesture Map",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "[63] called for future work to include multiple representations of gestures.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.4191846405228758,
        "top": 0.23096969696969696,
        "width": 0.061279411764705916,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24480681818181818,
        "width": 0.39482026143790855,
        "height": 0.011320707070707065,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "For further inspection, one or more gestures can be selected (e.g. Figure 4) from a referents list of gesture proposals (Figure 1 3  ).",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.6888692810457516,
        "top": 0.49480808080808075,
        "width": 0.2232189542483659,
        "height": 0.011320707070707037,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.508645202020202,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5220404040404041,
        "width": 0.1940718954248366,
        "height": 0.011762626262626252,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "As larger data sets are expected in the future [1, 24, 41], we also provide an interactive clustering method to reduce manual workload for identifying similar gesture (sub)groups.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.24276470588235294,
        "top": 0.38457702020202017,
        "width": 0.24017973856209152,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3984141414141414,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4122512626262626,
        "width": 0.39481535947712426,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "This work motivates us to further explore data-driven measures of consensus: We follow a similar approach, but instead of regressing on the DTW distance values, and relying on pairwise comparisons, we directly compute an average sequence from all gesture proposals in a referent group, using DBA.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6177992424242424,
        "width": 0.3762794117647059,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6316363636363636,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6454734848484848,
        "width": 0.39503267973856215,
        "height": 0.011320707070707203,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.659310606060606,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6731477272727273,
        "width": 0.24893464052287584,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "For further technical details we refer the reader to the related work [43].",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.6910816993464053,
        "top": 0.3929962121212121,
        "width": 0.22129575163398685,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4068320707070707,
        "width": 0.20968464052287572,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.1 Computing an Average Gesture with DBA",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We further see, for example, sitting (Figure 2B), clapping (Figure 2D),",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.893156862745098,
        "top": 0.8705959595959595,
        "width": 0.018934640522875967,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.5195343137254902,
        "top": 0.8844318181818183,
        "width": 0.39417320261437894,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "a replacement of others: As a flexible tool, GestureMap can be extended to additionally display further such measures (e.g. the one by Vatavu [59]) to support researchers with the analysis.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.10956060606060607,
        "width": 0.395031045751634,
        "height": 0.011332070707070707,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.12339772727272727,
        "width": 0.392562091503268,
        "height": 0.011320707070707092,
        "page": 5
      },
      {
        "left": 0.08790522875816993,
        "top": 0.1372348484848485,
        "width": 0.3384232026143791,
        "height": 0.011320707070707092,
        "page": 5
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Other researchers noted that elicitation findings are spread across multiple venues and need to be consolidated [63].",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.5497007575757575,
        "width": 0.392562091503268,
        "height": 0.011320707070707092,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.5635378787878788,
        "width": 0.2927794117647059,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.6 Comparison Between Datasets",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "To further evaluate GestureMap , we recruited eight HCI researchers (7 male, 1 female) from three universities via e-mail for remote think-alound and interview sessions.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.0874656862745098,
        "top": 0.8290845959595959,
        "width": 0.39300326797385626,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.0874656862745098,
        "top": 0.8429217171717173,
        "width": 0.3929967320261438,
        "height": 0.011320707070706981,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8567588383838384,
        "width": 0.2256388888888889,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "7 USER STUDY",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "However, they noted that it should be more accurate and manually refined assignments need to be respected when rerunning the clustering algorithm, thus enabling iterative, interactive use.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.82375,
        "top": 0.45469949494949496,
        "width": 0.08872222222222226,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4685366161616162,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.4823737373737374,
        "width": 0.392563725490196,
        "height": 0.011320707070707037,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.49620959595959596,
        "width": 0.2933006535947712,
        "height": 0.011320707070707037,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Such support as shown in GestureMap could be combined with a crowd approach in the future.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.8834117647058823,
        "top": 0.7460618686868686,
        "width": 0.02868954248366007,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.75989898989899,
        "width": 0.39255882352941185,
        "height": 0.011332070707070763,
        "page": 8
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7737361111111111,
        "width": 0.14132516339869294,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "8 DISCUSSION 8.1 Extending the Gesture Elicitation Toolbox",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "This is an artefact of dimensionality reduction, as we discuss further in Section 8.2",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.3770882352941176,
        "top": 0.5893270202020202,
        "width": 0.1033774509803922,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6031641414141414,
        "width": 0.3820098039215687,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Integrating such a tree-like layout into the gesture map adds complexity and might be material for future endeavours.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.3190049019607843,
        "top": 0.40852398989898986,
        "width": 0.1614640522875817,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4223598484848485,
        "width": 0.3925604575163399,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4361969696969697,
        "width": 0.13058496732026148,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "In addition, interactive hierarchical clustering would eliminate the need for choosing the number of clusters beforehand.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.26962745098039215,
        "top": 0.46387121212121213,
        "width": 0.21083333333333326,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.47770833333333335,
        "width": 0.39256372549019614,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4915454545454545,
        "width": 0.12051960784313724,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.2 Reflection on Model & Clustering Choices",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "The extensibility of GestureMap further encourages future work to employ machine learning as a tool for analysis of human behavior.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.8884591503267973,
        "top": 0.6240454545454546,
        "width": 0.02364215686274518,
        "height": 0.011320707070706981,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6378825757575757,
        "width": 0.39503431372549025,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.651719696969697,
        "width": 0.3948202614379085,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Given the proliferation of crowd platforms to collect large datasets, we expect computational methods and visual analytics as proposed here to become indispensable tools for many future HCI studies.",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5195343137254902,
        "top": 0.7070669191919191,
        "width": 0.39416830065359476,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5189918300653594,
        "top": 0.7209040404040404,
        "width": 0.3931062091503268,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7347411616161615,
        "width": 0.3846764705882353,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "It further leverages the computation of average gestures to enable researchers to",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.701952614379085,
        "top": 0.5548598484848485,
        "width": 0.21014215686274518,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5686969696969697,
        "width": 0.2672581699346406,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "GestureMap and further materials are available on the project website: https://osf.io/dzn5g/",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.7485782828282829,
        "width": 0.3762761437908495,
        "height": 0.011332070707070763,
        "page": 9
      },
      {
        "left": 0.5189918300653594,
        "top": 0.762415404040404,
        "width": 0.1733496732026144,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": null,
    "is_author_statement": false,
    "is_in_expected_section": true
  },
  {
    "text": "Here we outline further ideas enabled or supported by GestureMap .",
    "label": "Future Work",
    "bboxes": [
      {
        "left": 0.08790522875816993,
        "top": 0.6442765151515152,
        "width": 0.3946633986928105,
        "height": 0.011332070707070652,
        "page": 9
      }
    ],
    "section": "8 DISCUSSION 8.3 Opportunities for Research & Applications",
    "prob": null,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "One successful method that has seen widespread use is the elicitation study paradigm [66], which helps HCI researchers and practitioners to explore the space of possible and intuitive or guessable (gesture) commands: Participants are shown a referent (often a system action, e.g. volume up ) and are asked to propose and perform a gesture they would use for it (e.g. turn wrist right ).",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.2603202614379085,
        "top": 0.17874494949494948,
        "width": 0.22014542483660132,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08736437908496732,
        "top": 0.1925820707070707,
        "width": 0.3931062091503268,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.20641919191919192,
        "width": 0.39255555555555555,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.22025631313131314,
        "width": 0.39256045751633994,
        "height": 0.011320707070707037,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.23409343434343433,
        "width": 0.39256372549019614,
        "height": 0.011332070707070735,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.24793055555555554,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.26176767676767676,
        "width": 0.09808169934640522,
        "height": 0.011332070707070707,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": 0.7143219113349915,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "As larger data sets are expected in the future [1, 24, 41], we also provide an interactive clustering method to reduce manual workload for identifying similar gesture (sub)groups.",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.24276470588235294,
        "top": 0.38457702020202017,
        "width": 0.24017973856209152,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3984141414141414,
        "width": 0.3925571895424837,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.08790522875816993,
        "top": 0.4122512626262626,
        "width": 0.39481535947712426,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.1 Feature Requirements and Overview",
    "prob": 0.7028299570083618,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "[43] to compute an average gesture: Intuitively, this algorithm first aligns an initial sequence with every sequence in the set of gesture proposals, before computing a centroid (barycenter) for each aligned coordinate.",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.6072091503267975,
        "top": 0.35148484848484846,
        "width": 0.3048807189542483,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3653219696969697,
        "width": 0.39256045751633983,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3791590909090909,
        "width": 0.3934395424836601,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3929962121212121,
        "width": 0.16789215686274506,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.1 Computing an Average Gesture with DBA",
    "prob": 0.6533504724502563,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "As our key contribution, we presented a set of visualization and analysis concepts for gesture elicitation data and a tool that implements them: GestureMap is the first visual analytics tool for gesture elicitation which directly visualises the space of gestures, using a learned 2D embedding.",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.5190212418300654,
        "top": 0.4995126262626262,
        "width": 0.39307189542483667,
        "height": 0.011320707070707037,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5133497474747475,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.527185606060606,
        "width": 0.39283660130718956,
        "height": 0.011332070707070652,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5410227272727273,
        "width": 0.39417320261437905,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.5548598484848485,
        "width": 0.17934477124183013,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": 0.6468658447265625,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "This work motivates us to further explore data-driven measures of consensus: We follow a similar approach, but instead of regressing on the DTW distance values, and relying on pairwise comparisons, we directly compute an average sequence from all gesture proposals in a referent group, using DBA.",
    "label": "Method",
    "bboxes": [
      {
        "left": 0.5358137254901961,
        "top": 0.6177992424242424,
        "width": 0.3762794117647059,
        "height": 0.011320707070706981,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6316363636363636,
        "width": 0.39502941176470585,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6454734848484848,
        "width": 0.39503267973856215,
        "height": 0.011320707070707203,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.659310606060606,
        "width": 0.392563725490196,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6731477272727273,
        "width": 0.24893464052287584,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 0.6436030268669128,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "We defined a consensus measure on this variability (Section 4.2): Comparing this variability between all referents, our results largely agree with Vatavu [59]: In particular, applaud, fly like a bird and hands up show high consensus while climb ladder, crouch, turn around have low consensus.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7416148989898991,
        "width": 0.37801633986928107,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7554520202020202,
        "width": 0.3929346405228758,
        "height": 0.011320707070707092,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7692891414141415,
        "width": 0.3925604575163399,
        "height": 0.01133207070707054,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7831262626262626,
        "width": 0.3925588235294118,
        "height": 0.011332070707070763,
        "page": 6
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7969633838383839,
        "width": 0.16762091503267978,
        "height": 0.01133207070707054,
        "page": 6
      }
    ],
    "section": "6 EXPERIMENTS 6.3 Global Observations",
    "prob": 0.7923374176025391,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Throughout the interview we noticed that all participants preferred the scatter plot over the density plot.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.32579575163398694,
        "top": 0.35875252525252527,
        "width": 0.15520915032679738,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08736437908496732,
        "top": 0.3725896464646465,
        "width": 0.39310130718954256,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.3864267676767677,
        "width": 0.07540849673202614,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.7654393315315247,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "As a second example, we compared behavior diversity across datasets.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7157449494949495,
        "width": 0.3762777777777778,
        "height": 0.011332070707070763,
        "page": 7
      },
      {
        "left": 0.08790522875816993,
        "top": 0.729580808080808,
        "width": 0.05136601307189541,
        "height": 0.011320707070707092,
        "page": 7
      }
    ],
    "section": "6 EXPERIMENTS 6.6 Comparison Between Datasets",
    "prob": 0.5776397585868835,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "Finally, we report the variance of these DTW distances as a measure of consensus.",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.5918153594771242,
        "top": 0.7146578282828283,
        "width": 0.32028267973856206,
        "height": 0.011320707070707092,
        "page": 4
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7284949494949494,
        "width": 0.1601062091503268,
        "height": 0.011320707070707092,
        "page": 4
      }
    ],
    "section": "4 CONSENSUS AND CLUSTERINGWITH DBA 4.2 Consensus as Variation Around Barycenter",
    "prob": 0.5378255248069763,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "When we asked the participants what the main aspect was that they used to determine interesting behavioral patterns, we observed diverse analysis strategies, but we broadly highlight two main ones:",
    "label": "Result",
    "bboxes": [
      {
        "left": 0.2615457516339869,
        "top": 0.6261830808080808,
        "width": 0.2189150326797385,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.640020202020202,
        "width": 0.39502941176470585,
        "height": 0.011320707070706981,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6538573232323233,
        "width": 0.3925555555555555,
        "height": 0.011320707070707092,
        "page": 8
      },
      {
        "left": 0.08790522875816993,
        "top": 0.6676944444444444,
        "width": 0.19891666666666669,
        "height": 0.011320707070707092,
        "page": 8
      }
    ],
    "section": "7 USER STUDY 7.2 Findings",
    "prob": 0.5193062424659729,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "With this work, we contribute to the vision of more widespread use of applicable computational methods in HCI, also to support more extensive and cost-efficient large-scale, data-driven HCI work.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.5188316993464052,
        "top": 0.6655568181818181,
        "width": 0.39326633986928106,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6793926767676767,
        "width": 0.3925637254901959,
        "height": 0.011320707070707092,
        "page": 9
      },
      {
        "left": 0.5195343137254902,
        "top": 0.693229797979798,
        "width": 0.3948153594771242,
        "height": 0.011320707070707092,
        "page": 9
      }
    ],
    "section": "9 CONCLUSION",
    "prob": 0.7373347282409668,
    "is_author_statement": true,
    "is_in_expected_section": true
  },
  {
    "text": "In this work, we adapt similar visualization concepts with the goal to create an interpretable gesture space.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.4041045751633987,
        "top": 0.7875732323232324,
        "width": 0.07797875816993471,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08736437908496732,
        "top": 0.8014103535353535,
        "width": 0.3931078431372549,
        "height": 0.011320707070707092,
        "page": 2
      },
      {
        "left": 0.08790522875816993,
        "top": 0.8152474747474748,
        "width": 0.1641062091503268,
        "height": 0.011320707070707092,
        "page": 2
      }
    ],
    "section": "2 RELATEDWORK 2.3 Visualization of High Dimensional Data",
    "prob": 0.7108747363090515,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "This feature helps to adjust the viewport to support exploration of datadense areas, and deal with the fact that landmark representations are discrete indicators for the continuous space.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.886281045751634,
        "top": 0.3289835858585859,
        "width": 0.02581209150326802,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3428207070707071,
        "width": 0.39504084967320263,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.3566578282828283,
        "width": 0.39256209150326793,
        "height": 0.011320707070707092,
        "page": 3
      },
      {
        "left": 0.5195343137254902,
        "top": 0.37049368686868683,
        "width": 0.28556209150326795,
        "height": 0.011320707070707092,
        "page": 3
      }
    ],
    "section": "3 GESTUREMAP CONCEPT 3.3 Map Interaction Concepts",
    "prob": 0.5904760956764221,
    "is_author_statement": false,
    "is_in_expected_section": false
  },
  {
    "text": "Our work builds on this idea, extends its data-driven perspective with a visual analytics tool, and introduces a new measure fitting this visualization.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.7942140522875818,
        "top": 0.6861022727272728,
        "width": 0.11787908496732014,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.6999393939393939,
        "width": 0.39256045751633994,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.5195343137254902,
        "top": 0.7137765151515152,
        "width": 0.361483660130719,
        "height": 0.011320707070707092,
        "page": 1
      }
    ],
    "section": "2 RELATEDWORK 2.1 Gesture Elicitation Studies",
    "prob": 0.5869761109352112,
    "is_author_statement": true,
    "is_in_expected_section": false
  },
  {
    "text": "These challenges motivate our work on new quantitative methods and tools for analyzing elicitation data.",
    "label": "Objective",
    "bboxes": [
      {
        "left": 0.10418464052287582,
        "top": 0.7506742424242424,
        "width": 0.3787598039215686,
        "height": 0.011320707070707092,
        "page": 1
      },
      {
        "left": 0.08790522875816993,
        "top": 0.7645113636363637,
        "width": 0.25261437908496737,
        "height": 0.011320707070706981,
        "page": 1
      }
    ],
    "section": "1 INTRODUCTION",
    "prob": 0.5370967388153076,
    "is_author_statement": true,
    "is_in_expected_section": true
  }
]