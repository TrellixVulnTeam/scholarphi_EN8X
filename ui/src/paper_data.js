export const PAPERS = [
  {
    "id": "b1d7f596fc34fd6cc6bbfc22a083bca8d2d38f14",
    "type": "paper",
    "attributes": {
      "s2Id": "b1d7f596fc34fd6cc6bbfc22a083bca8d2d38f14",
      "authors": [
        {
          "id": "1771885",
          "name": "Ding Liu",
          "url": "https://www.semanticscholar.org/author/1771885"
        },
        {
          "id": "1793218",
          "name": "Daniel Gildea",
          "url": "https://www.semanticscholar.org/author/1793218"
        }
      ],
      "year": 2010,
      "title": "Semantic Role Features for Machine Translation",
      "abstract": "We propose semantic role features for a Tree-to-String transducer to model the reordering/deletion of source-side semantic roles. These semantic features, as well as the Tree-to-String templates, are trained based on a conditional log-linear model and are shown to significantly outperform systems trained based on Max-Likelihood and EM. We also show significant improvement in sentence fluency by using the semantic role features in the log-linear model, based on manual evaluation.",
      "url": "https://www.semanticscholar.org/paper/b1d7f596fc34fd6cc6bbfc22a083bca8d2d38f14",
      "venue": "COLING",
      "citationVelocity": 11,
      "influentialCitationCount": 3
    }
  },
  {
    "id": "29219d826ead654f2b863de6eceb69811850b7d4",
    "type": "paper",
    "attributes": {
      "s2Id": "29219d826ead654f2b863de6eceb69811850b7d4",
      "authors": [
        {
          "id": "39798499",
          "name": "Yang Liu",
          "url": "https://www.semanticscholar.org/author/39798499"
        },
        {
          "id": "1747893",
          "name": "Mirella Lapata",
          "url": "https://www.semanticscholar.org/author/1747893"
        }
      ],
      "year": 2018,
      "title": "Learning Structured Text Representations",
      "abstract": "In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional annotations. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.",
      "url": "https://www.semanticscholar.org/paper/29219d826ead654f2b863de6eceb69811850b7d4",
      "venue": "Transactions of the Association for Computational Linguistics",
      "citationVelocity": 28,
      "influentialCitationCount": 8
    }
  },
  {
    "id": "367f2c63a6f6a10b3b64b8729d601e69337ee3cc",
    "type": "paper",
    "attributes": {
      "s2Id": "367f2c63a6f6a10b3b64b8729d601e69337ee3cc",
      "authors": [
        {
          "id": "34961461",
          "name": "Andrew L. Maas",
          "url": "https://www.semanticscholar.org/author/34961461"
        }
      ],
      "year": 2013,
      "title": "Rectifier Nonlinearities Improve Neural Network Acoustic Models",
      "abstract": "Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.",
      "url": "https://www.semanticscholar.org/paper/367f2c63a6f6a10b3b64b8729d601e69337ee3cc",
      "venue": "",
      "citationVelocity": 747,
      "influentialCitationCount": 437
    }
  },
  {
    "id": "8495259ca47c938fbfc6a0a71633b27e907d998b",
    "type": "paper",
    "attributes": {
      "s2Id": "8495259ca47c938fbfc6a0a71633b27e907d998b",
      "authors": [
        {
          "id": "2022957",
          "name": "Diego Marcheggiani",
          "url": "https://www.semanticscholar.org/author/2022957"
        },
        {
          "id": "144222728",
          "name": "A. Frolov",
          "url": "https://www.semanticscholar.org/author/144222728"
        },
        {
          "id": "144889265",
          "name": "Ivan Titov",
          "url": "https://www.semanticscholar.org/author/144889265"
        }
      ],
      "year": 2017,
      "title": "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling",
      "abstract": "We introduce a simple and accurate neural model for dependency-based semantic role labeling. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves competitive performance on English, even without any kind of syntactic information and only using local inference. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.",
      "url": "https://www.semanticscholar.org/paper/8495259ca47c938fbfc6a0a71633b27e907d998b",
      "venue": "CoNLL",
      "citationVelocity": 25,
      "influentialCitationCount": 22
    }
  },
  {
    "id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
    "type": "paper",
    "attributes": {
      "s2Id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
      "authors": [
        {
          "id": "2022957",
          "name": "Diego Marcheggiani",
          "url": "https://www.semanticscholar.org/author/2022957"
        },
        {
          "id": "144889265",
          "name": "Ivan Titov",
          "url": "https://www.semanticscholar.org/author/144889265"
        }
      ],
      "year": 2017,
      "title": "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling",
      "abstract": "Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.",
      "url": "https://www.semanticscholar.org/paper/c3a3c163f25b9181f1fb7e71a32482a7393d2088",
      "venue": "EMNLP",
      "citationVelocity": 124,
      "influentialCitationCount": 56
    }
  },
  {
    "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
    "type": "paper",
    "attributes": {
      "s2Id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
      "authors": [
        {
          "id": "1734174",
          "name": "M. Marcus",
          "url": "https://www.semanticscholar.org/author/1734174"
        },
        {
          "id": "2424234",
          "name": "Beatrice Santorini",
          "url": "https://www.semanticscholar.org/author/2424234"
        },
        {
          "id": "2063206",
          "name": "Mary Ann Marcinkiewicz",
          "url": "https://www.semanticscholar.org/author/2063206"
        }
      ],
      "year": 1993,
      "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
      "abstract": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant.",
      "url": "https://www.semanticscholar.org/paper/0b44fcbeea9415d400c5f5789d6b892b6f98daff",
      "venue": "Comput. Linguistics",
      "citationVelocity": 452,
      "influentialCitationCount": 1269
    }
  },
  {
    "id": "f66821598f4db7a6a2f54a6a4ae43e391649f4c1",
    "type": "paper",
    "attributes": {
      "s2Id": "f66821598f4db7a6a2f54a6a4ae43e391649f4c1",
      "authors": [
        {
          "id": "2241127",
          "name": "Marie-Catherine de Marneffe",
          "url": "https://www.semanticscholar.org/author/2241127"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        }
      ],
      "year": 2008,
      "title": "The Stanford Typed Dependencies Representation",
      "abstract": "This paper examines the Stanford typed dependencies representation, which was designed to provide a straightforward description of grammatical relations for any user who could benefit from automatic text understanding. For such purposes, we argue that dependency schemes must follow a simple design and provide semantically contentful information, as well as offer an automatic procedure to extract the relations. We consider the underlying design principles of the Stanford scheme from this perspective, and compare it to the GR and PARC representations. Finally, we address the question of the suitability of the Stanford scheme for parser evaluation.",
      "url": "https://www.semanticscholar.org/paper/f66821598f4db7a6a2f54a6a4ae43e391649f4c1",
      "venue": "CF+CDPE@COLING",
      "citationVelocity": 56,
      "influentialCitationCount": 33
    }
  },
  {
    "id": "8d3a318b62d2e970122da35b2a2e70a5d12cc16f",
    "type": "paper",
    "attributes": {
      "s2Id": "8d3a318b62d2e970122da35b2a2e70a5d12cc16f",
      "authors": [
        {
          "id": "143676697",
          "name": "Y. Nesterov",
          "url": "https://www.semanticscholar.org/author/143676697"
        }
      ],
      "year": 1983,
      "title": "A method for solving the convex programming problem with convergence rate O(1/k^2)",
      "abstract": null,
      "url": "https://www.semanticscholar.org/paper/8d3a318b62d2e970122da35b2a2e70a5d12cc16f",
      "venue": "",
      "citationVelocity": 421,
      "influentialCitationCount": 365
    }
  },
  {
    "id": "99d2dcdcf4cf05facaa101a48c7e31d140b4736d",
    "type": "paper",
    "attributes": {
      "s2Id": "99d2dcdcf4cf05facaa101a48c7e31d140b4736d",
      "authors": [
        {
          "id": "145755155",
          "name": "Martha Palmer",
          "url": "https://www.semanticscholar.org/author/145755155"
        },
        {
          "id": "144156677",
          "name": "Paul Kingsbury",
          "url": "https://www.semanticscholar.org/author/144156677"
        },
        {
          "id": "1793218",
          "name": "Daniel Gildea",
          "url": "https://www.semanticscholar.org/author/1793218"
        }
      ],
      "year": 2005,
      "title": "The Proposition Bank: An Annotated Corpus of Semantic Roles",
      "abstract": "The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated. We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty trace categories of the treebank.",
      "url": "https://www.semanticscholar.org/paper/99d2dcdcf4cf05facaa101a48c7e31d140b4736d",
      "venue": "Computational Linguistics",
      "citationVelocity": 137,
      "influentialCitationCount": 367
    }
  },
  {
    "id": "84069287da0a6b488b8c933f3cb5be759cb6237e",
    "type": "paper",
    "attributes": {
      "s2Id": "84069287da0a6b488b8c933f3cb5be759cb6237e",
      "authors": [
        {
          "id": "1996134",
          "name": "Razvan Pascanu",
          "url": "https://www.semanticscholar.org/author/1996134"
        },
        {
          "id": null,
          "name": "Tomas Mikolov",
          "url": null
        },
        {
          "id": "1751762",
          "name": "Yoshua Bengio",
          "url": "https://www.semanticscholar.org/author/1751762"
        }
      ],
      "year": 2013,
      "title": "On the difficulty of training recurrent neural networks",
      "abstract": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.",
      "url": "https://www.semanticscholar.org/paper/84069287da0a6b488b8c933f3cb5be759cb6237e",
      "venue": "ICML",
      "citationVelocity": 673,
      "influentialCitationCount": 238
    }
  },
  {
    "id": "4908fc4d7f58383170c085fe8238a868e9a901f9",
    "type": "paper",
    "attributes": {
      "s2Id": "4908fc4d7f58383170c085fe8238a868e9a901f9",
      "authors": [
        {
          "id": "49349645",
          "name": "Hao Peng",
          "url": "https://www.semanticscholar.org/author/49349645"
        },
        {
          "id": "38094552",
          "name": "Sam Thomson",
          "url": "https://www.semanticscholar.org/author/38094552"
        },
        {
          "id": "144365875",
          "name": "Noah A. Smith",
          "url": "https://www.semanticscholar.org/author/144365875"
        }
      ],
      "year": 2017,
      "title": "Deep Multitask Learning for Semantic Dependency Parsing",
      "abstract": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms. By using efficient, nearly arc-factored inference and a bidirectional-LSTM composed with a multi-layer perceptron, our base system is able to significantly improve the state of the art for semantic dependency parsing, without using hand-engineered features or syntax. We then explore two multitask learning approaches---one that shares parameters across formalisms, and one that uses higher-order structures to predict the graphs jointly. We find that both approaches improve performance across formalisms on average, achieving a new state of the art. Our code is open-source and available at this https URL.",
      "url": "https://www.semanticscholar.org/paper/4908fc4d7f58383170c085fe8238a868e9a901f9",
      "venue": "ACL",
      "citationVelocity": 33,
      "influentialCitationCount": 15
    }
  },
  {
    "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
    "type": "paper",
    "attributes": {
      "s2Id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
      "authors": [
        {
          "id": "143845796",
          "name": "Jeffrey Pennington",
          "url": "https://www.semanticscholar.org/author/143845796"
        },
        {
          "id": "2166511",
          "name": "R. Socher",
          "url": "https://www.semanticscholar.org/author/2166511"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        }
      ],
      "year": 2014,
      "title": "Glove: Global Vectors for Word Representation",
      "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
      "url": "https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5",
      "venue": "EMNLP",
      "citationVelocity": 4212,
      "influentialCitationCount": 2629
    }
  },
  {
    "id": "3febb2bed8865945e7fddc99efd791887bb7e14f",
    "type": "paper",
    "attributes": {
      "s2Id": "3febb2bed8865945e7fddc99efd791887bb7e14f",
      "authors": [
        {
          "id": "39139825",
          "name": "Matthew E. Peters",
          "url": "https://www.semanticscholar.org/author/39139825"
        },
        {
          "id": "50043859",
          "name": "Mark Neumann",
          "url": "https://www.semanticscholar.org/author/50043859"
        },
        {
          "id": "2136562",
          "name": "Mohit Iyyer",
          "url": "https://www.semanticscholar.org/author/2136562"
        },
        {
          "id": "40642935",
          "name": "Matt Gardner",
          "url": "https://www.semanticscholar.org/author/40642935"
        },
        {
          "id": "143997772",
          "name": "Christopher Clark",
          "url": "https://www.semanticscholar.org/author/143997772"
        },
        {
          "id": "2544107",
          "name": "Kenton Lee",
          "url": "https://www.semanticscholar.org/author/2544107"
        },
        {
          "id": "1982950",
          "name": "Luke Zettlemoyer",
          "url": "https://www.semanticscholar.org/author/1982950"
        }
      ],
      "year": 2018,
      "title": "Deep contextualized word representations",
      "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
      "url": "https://www.semanticscholar.org/paper/3febb2bed8865945e7fddc99efd791887bb7e14f",
      "venue": "NAACL-HLT",
      "citationVelocity": 1608,
      "influentialCitationCount": 994
    }
  },
  {
    "id": "c92970286c535992a86539b761357761e97a37ee",
    "type": "paper",
    "attributes": {
      "s2Id": "c92970286c535992a86539b761357761e97a37ee",
      "authors": [
        {
          "id": "1735131",
          "name": "Sameer Pradhan",
          "url": "https://www.semanticscholar.org/author/1735131"
        },
        {
          "id": "1719404",
          "name": "Alessandro Moschitti",
          "url": "https://www.semanticscholar.org/author/1719404"
        },
        {
          "id": "1702849",
          "name": "N. Xue",
          "url": "https://www.semanticscholar.org/author/1702849"
        },
        {
          "id": "34789794",
          "name": "H. Ng",
          "url": "https://www.semanticscholar.org/author/34789794"
        },
        {
          "id": "1737207",
          "name": "Anders Björkelund",
          "url": "https://www.semanticscholar.org/author/1737207"
        },
        {
          "id": "143835479",
          "name": "O. Uryupina",
          "url": "https://www.semanticscholar.org/author/143835479"
        },
        {
          "id": null,
          "name": "Yuchen Zhang",
          "url": null
        },
        {
          "id": "144574004",
          "name": "Z. Zhong",
          "url": "https://www.semanticscholar.org/author/144574004"
        }
      ],
      "year": 2013,
      "title": "Towards Robust Linguistic Analysis using OntoNotes",
      "abstract": "Large-scale linguistically annotated corpora have played a crucial role in advancing the state of the art of key natural language technologies such as syntactic, semantic and discourse analyzers, and they serve as training data as well as evaluation benchmarks. Up till now, however, most of the evaluation has been done on monolithic corpora such as the Penn Treebank, the Proposition Bank. As a result, it is still unclear how the state-of-the-art analyzers perform in general on data from a variety of genres or domains. The completion of the OntoNotes corpus, a large-scale, multi-genre, multilingual corpus manually annotated with syntactic, semantic and discourse information, makes it possible to perform such an evaluation. This paper presents an analysis of the performance of publicly available, state-of-the-art tools on all layers and languages in the OntoNotes v5.0 corpus. This should set the benchmark for future development of various NLP components in syntax and semantics, and possibly encourage research towards an integrated system that makes use of the various layers jointly to improve overall performance.",
      "url": "https://www.semanticscholar.org/paper/c92970286c535992a86539b761357761e97a37ee",
      "venue": "CoNLL",
      "citationVelocity": 49,
      "influentialCitationCount": 63
    }
  },
  {
    "id": "1ae5c1646ea445a670fe6cc8bf72b589dd9f6e5c",
    "type": "paper",
    "attributes": {
      "s2Id": "1ae5c1646ea445a670fe6cc8bf72b589dd9f6e5c",
      "authors": [
        {
          "id": "1735131",
          "name": "Sameer Pradhan",
          "url": "https://www.semanticscholar.org/author/1735131"
        },
        {
          "id": "1866226",
          "name": "W. Ward",
          "url": "https://www.semanticscholar.org/author/1866226"
        },
        {
          "id": "2483422",
          "name": "K. Hacioglu",
          "url": "https://www.semanticscholar.org/author/2483422"
        },
        {
          "id": "10796472",
          "name": "James H. Martin",
          "url": "https://www.semanticscholar.org/author/10796472"
        },
        {
          "id": "1746807",
          "name": "Dan Jurafsky",
          "url": "https://www.semanticscholar.org/author/1746807"
        }
      ],
      "year": 2005,
      "title": "Semantic Role Labeling Using Different Syntactic Views",
      "abstract": "Semantic role labeling is the process of annotating the predicate-argument structure in text with semantic labels. In this paper we present a state-of-the-art baseline semantic role labeling system based on Support Vector Machine classifiers. We show improvements on this system by: i) adding new features including features extracted from dependency parses, ii) performing feature selection and calibration and iii) combining parses obtained from semantic parsers trained using different syntactic views. Error analysis of the baseline system showed that approximately half of the argument identification errors resulted from parse errors in which there was no syntactic constituent that aligned with the correct argument. In order to address this problem, we combined semantic parses from a Minipar syntactic parse and from a chunked syntactic representation with our original baseline system which was based on Charniak parses. All of the reported techniques resulted in performance improvements.",
      "url": "https://www.semanticscholar.org/paper/1ae5c1646ea445a670fe6cc8bf72b589dd9f6e5c",
      "venue": "ACL",
      "citationVelocity": 8,
      "influentialCitationCount": 20
    }
  },
  {
    "id": "b5c6f0d18fd783536b4e6c2205d75b7c4477c6d2",
    "type": "paper",
    "attributes": {
      "s2Id": "b5c6f0d18fd783536b4e6c2205d75b7c4477c6d2",
      "authors": [
        {
          "id": "2474158",
          "name": "Vasin Punyakanok",
          "url": "https://www.semanticscholar.org/author/2474158"
        },
        {
          "id": "144590225",
          "name": "D. Roth",
          "url": "https://www.semanticscholar.org/author/144590225"
        },
        {
          "id": "144105277",
          "name": "Wen-tau Yih",
          "url": "https://www.semanticscholar.org/author/144105277"
        }
      ],
      "year": 2008,
      "title": "The Importance of Syntactic Parsing and Inference in Semantic Role Labeling",
      "abstract": "We present a general framework for semantic role labeling. The framework combines a machine-learning technique with an integer linear programming-based inference procedure, which incorporates linguistic and structural constraints into a global decision process. Within this framework, we study the role of syntactic parsing information in semantic role labeling. We show that full syntactic parsing information is, by far, most relevant in identifying the argument, especially, in the very first stagethe pruning stage. Surprisingly, the quality of the pruning stage cannot be solely determined based on its recall and precision. Instead, it depends on the characteristics of the output candidates that determine the difficulty of the downstream problems. Motivated by this observation, we propose an effective and simple approach of combining different semantic role labeling systems through joint inference, which significantly improves its performance. Our system has been evaluated in the CoNLL-2005 shared task on semantic role labeling, and achieves the highest F1 score among 19 participants.",
      "url": "https://www.semanticscholar.org/paper/b5c6f0d18fd783536b4e6c2205d75b7c4477c6d2",
      "venue": "Computational Linguistics",
      "citationVelocity": 35,
      "influentialCitationCount": 40
    }
  },
  {
    "id": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
    "type": "paper",
    "attributes": {
      "s2Id": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
      "authors": [
        {
          "id": "1700433",
          "name": "S. Ross",
          "url": "https://www.semanticscholar.org/author/1700433"
        },
        {
          "id": "21889436",
          "name": "G. Gordon",
          "url": "https://www.semanticscholar.org/author/21889436"
        },
        {
          "id": "1756566",
          "name": "J. Bagnell",
          "url": "https://www.semanticscholar.org/author/1756566"
        }
      ],
      "year": 2011,
      "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
      "abstract": "Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem.",
      "url": "https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e",
      "venue": "AISTATS",
      "citationVelocity": 313,
      "influentialCitationCount": 249
    }
  },
  {
    "id": "70d3d2e0a8f34d6c3cb7890e249e2ed6a574ce50",
    "type": "paper",
    "attributes": {
      "s2Id": "70d3d2e0a8f34d6c3cb7890e249e2ed6a574ce50",
      "authors": [
        {
          "id": "46617131",
          "name": "Michael Roth",
          "url": "https://www.semanticscholar.org/author/46617131"
        },
        {
          "id": "1747893",
          "name": "Mirella Lapata",
          "url": "https://www.semanticscholar.org/author/1747893"
        }
      ],
      "year": 2016,
      "title": "Neural Semantic Role Labeling with Dependency Path Embeddings",
      "abstract": "This paper introduces a novel model for semantic role labeling that makes use of neural sequence modeling techniques. Our approach is motivated by the observation that complex syntactic structures and related phenomena, such as nested subordinations and nominal predicates, are not handled well by existing models. Our model treats such instances as subsequences of lexicalized dependency paths and learns suitable embedding representations. We experimentally demonstrate that such embeddings can improve results over previous state-of-the-art semantic role labelers, and showcase qualitative improvements obtained by our method.",
      "url": "https://www.semanticscholar.org/paper/70d3d2e0a8f34d6c3cb7890e249e2ed6a574ce50",
      "venue": "ACL",
      "citationVelocity": 33,
      "influentialCitationCount": 17
    }
  },
  {
    "id": "03ad06583c9721855ccd82c3d969a01360218d86",
    "type": "paper",
    "attributes": {
      "s2Id": "03ad06583c9721855ccd82c3d969a01360218d86",
      "authors": [
        {
          "id": "1700187",
          "name": "Anders Søgaard",
          "url": "https://www.semanticscholar.org/author/1700187"
        },
        {
          "id": "79775260",
          "name": "Y. Goldberg",
          "url": "https://www.semanticscholar.org/author/79775260"
        }
      ],
      "year": 2016,
      "title": "Deep multi-task learning with low level tasks supervised at lower layers",
      "abstract": "In all previous work on deep multi-task learning we are aware of, all task supervisions are on the same (outermost) layer. We present a multi-task learning architecture with deep bi-directional RNNs, where different tasks supervision can happen at different layers. We present experiments in syntactic chunking and CCG supertagging, coupled with the additional task of POS-tagging. We show that it is consistently better to have POS supervision at the innermost rather than the outermost layer. We argue that this is because “lowlevel” tasks are better kept at the lower layers, enabling the higher-level tasks to make use of the shared representation of the lower-level tasks. Finally, we also show how this architecture can be used for domain adaptation.",
      "url": "https://www.semanticscholar.org/paper/03ad06583c9721855ccd82c3d969a01360218d86",
      "venue": "ACL",
      "citationVelocity": 87,
      "influentialCitationCount": 17
    }
  },
  {
    "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
    "type": "paper",
    "attributes": {
      "s2Id": "34f25a8704614163c4095b3ee2fc969b60de4698",
      "authors": [
        {
          "id": "2897313",
          "name": "Nitish Srivastava",
          "url": "https://www.semanticscholar.org/author/2897313"
        },
        {
          "id": "1695689",
          "name": "Geoffrey E. Hinton",
          "url": "https://www.semanticscholar.org/author/1695689"
        },
        {
          "id": "2064160",
          "name": "A. Krizhevsky",
          "url": "https://www.semanticscholar.org/author/2064160"
        },
        {
          "id": "1701686",
          "name": "Ilya Sutskever",
          "url": "https://www.semanticscholar.org/author/1701686"
        },
        {
          "id": "145124475",
          "name": "R. Salakhutdinov",
          "url": "https://www.semanticscholar.org/author/145124475"
        }
      ],
      "year": 2014,
      "title": "Dropout: a simple way to prevent neural networks from overfitting",
      "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.",
      "url": "https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698",
      "venue": "J. Mach. Learn. Res.",
      "citationVelocity": 5192,
      "influentialCitationCount": 1804
    }
  },
  {
    "id": "dee93d4481ac590f6debcd2816f1f8fd27b627d9",
    "type": "paper",
    "attributes": {
      "s2Id": "dee93d4481ac590f6debcd2816f1f8fd27b627d9",
      "authors": [
        {
          "id": "1760868",
          "name": "M. Surdeanu",
          "url": "https://www.semanticscholar.org/author/1760868"
        },
        {
          "id": "3049328",
          "name": "Lluís Màrquez i Villodre",
          "url": "https://www.semanticscholar.org/author/3049328"
        },
        {
          "id": "1701734",
          "name": "X. Carreras",
          "url": "https://www.semanticscholar.org/author/1701734"
        },
        {
          "id": "143624632",
          "name": "P. Comas",
          "url": "https://www.semanticscholar.org/author/143624632"
        }
      ],
      "year": 2007,
      "title": "Combination Strategies for Semantic Role Labeling",
      "abstract": "This paper introduces and analyzes a battery of inference models for the problem of semantic role labeling: one based on constraint satisfaction, and several strategies that model the inference as a meta-learning problem using discriminative classifiers. These classifiers are developed with a rich set of novel features that encode proposition and sentence-level information. To our knowledge, this is the first work that: (a) performs a thorough analysis of learning-based inference models for semantic role labeling, and (b) compares several inference strategies in this context. We evaluate the proposed inference strategies in the framework of the CoNLL-2005 shared task using only automatically-generated syntactic information. The extensive experimental evaluation and analysis indicates that all the proposed inference strategies are successful - they all outperform the current best results reported in the CoNLL-2005 evaluation exercise - but each of the proposed approaches has its advantages and disadvantages. Several important traits of a state-of-the-art SRL combination strategy emerge from this analysis: (i) individual models should be combined at the granularity of candidate arguments rather than at the granularity of complete solutions; (ii) the best combination strategy uses an inference model based in learning; and (iii) the learning-based inference benefits from max-margin classifiers and global feedback.",
      "url": "https://www.semanticscholar.org/paper/dee93d4481ac590f6debcd2816f1f8fd27b627d9",
      "venue": "J. Artif. Intell. Res.",
      "citationVelocity": 0,
      "influentialCitationCount": 10
    }
  },
  {
    "id": "48b4524a3b1207157b1b2f87885c434c96fc7a19",
    "type": "paper",
    "attributes": {
      "s2Id": "48b4524a3b1207157b1b2f87885c434c96fc7a19",
      "authors": [
        {
          "id": "153768309",
          "name": "Charles A. Sutton",
          "url": "https://www.semanticscholar.org/author/153768309"
        },
        {
          "id": "143753639",
          "name": "A. McCallum",
          "url": "https://www.semanticscholar.org/author/143753639"
        }
      ],
      "year": 2005,
      "title": "Joint Parsing and Semantic Role Labeling",
      "abstract": "A striking feature of human syntactic processing is that it is context-dependent, that is, it seems to take into account semantic information from the discourse context and world knowledge. In this paper, we attempt to use this insight to bridge the gap between SRL results from gold parses and from automatically-generated parses. To do this, we jointly perform parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a probabilistic parser. Our current results are negative, because a locally-trained SRL model can return inaccurate probability estimates.",
      "url": "https://www.semanticscholar.org/paper/48b4524a3b1207157b1b2f87885c434c96fc7a19",
      "venue": "CoNLL",
      "citationVelocity": 0,
      "influentialCitationCount": 3
    }
  },
  {
    "id": "b836405eebd5722b7782ea994c598e2991474850",
    "type": "paper",
    "attributes": {
      "s2Id": "b836405eebd5722b7782ea994c598e2991474850",
      "authors": [
        {
          "id": "2705113",
          "name": "Swabha Swayamdipta",
          "url": "https://www.semanticscholar.org/author/2705113"
        },
        {
          "id": "38094552",
          "name": "Sam Thomson",
          "url": "https://www.semanticscholar.org/author/38094552"
        },
        {
          "id": "1745899",
          "name": "Chris Dyer",
          "url": "https://www.semanticscholar.org/author/1745899"
        },
        {
          "id": "144365875",
          "name": "Noah A. Smith",
          "url": "https://www.semanticscholar.org/author/144365875"
        }
      ],
      "year": 2017,
      "title": "Frame-Semantic Parsing with Softmax-Margin Segmental RNNs and a Syntactic Scaffold",
      "abstract": "We present a new, efficient frame-semantic parser that labels semantic arguments to FrameNet predicates. Built using an extension to the segmental RNN that emphasizes recall, our basic system achieves competitive performance without any calls to a syntactic parser. We then introduce a method that uses phrase-syntactic annotations from the Penn Treebank during training only, through a multitask objective; no parsing is required at training or test time. This \"syntactic scaffold\" offers a cheaper alternative to traditional syntactic pipelining, and achieves state-of-the-art performance.",
      "url": "https://www.semanticscholar.org/paper/b836405eebd5722b7782ea994c598e2991474850",
      "venue": "ArXiv",
      "citationVelocity": 17,
      "influentialCitationCount": 10
    }
  },
  {
    "id": "af9b9235a68307c782d14d4bf12cb80d662d247f",
    "type": "paper",
    "attributes": {
      "s2Id": "af9b9235a68307c782d14d4bf12cb80d662d247f",
      "authors": [
        {
          "id": "2556289",
          "name": "Oscar Täckström",
          "url": "https://www.semanticscholar.org/author/2556289"
        },
        {
          "id": "144422385",
          "name": "K. Ganchev",
          "url": "https://www.semanticscholar.org/author/144422385"
        },
        {
          "id": "143790066",
          "name": "Dipanjan Das",
          "url": "https://www.semanticscholar.org/author/143790066"
        }
      ],
      "year": 2015,
      "title": "Efficient Inference and Structured Learning for Semantic Role Labeling",
      "abstract": "We present a dynamic programming algorithm for efficient constrained inference in semantic role labeling. The algorithm tractably captures a majority of the structural constraints examined by prior work in this area, which has resorted to either approximate methods or off-the-shelf integer linear programming solvers. In addition, it allows training a globally-normalized log-linear model with respect to constrained conditional likelihood. We show that the dynamic program is several times faster than an off-the-shelf integer linear programming solver, while reaching the same solution. Furthermore, we show that our structured model results in significant improvements over its local counterpart, achieving state-of-the-art results on both PropBank- and FrameNet-annotated corpora.",
      "url": "https://www.semanticscholar.org/paper/af9b9235a68307c782d14d4bf12cb80d662d247f",
      "venue": "Transactions of the Association for Computational Linguistics",
      "citationVelocity": 13,
      "influentialCitationCount": 17
    }
  },
  {
    "id": "6ed376a26045ff0048ec2b216785d396960d6ed1",
    "type": "paper",
    "attributes": {
      "s2Id": "6ed376a26045ff0048ec2b216785d396960d6ed1",
      "authors": [
        {
          "id": "3468510",
          "name": "Zhixing Tan",
          "url": "https://www.semanticscholar.org/author/3468510"
        },
        {
          "id": "2067908",
          "name": "Mingxuan Wang",
          "url": "https://www.semanticscholar.org/author/2067908"
        },
        {
          "id": "145626731",
          "name": "J. Xie",
          "url": "https://www.semanticscholar.org/author/145626731"
        },
        {
          "id": "1747212",
          "name": "Y. Chen",
          "url": "https://www.semanticscholar.org/author/1747212"
        },
        {
          "id": "1755321",
          "name": "X. Shi",
          "url": "https://www.semanticscholar.org/author/1755321"
        }
      ],
      "year": 2018,
      "title": "Deep Semantic Role Labeling with Self-Attention",
      "abstract": "Semantic Role Labeling (SRL) is believed to be a crucial step towards natural language understanding and has been widely studied. Recent years, end-to-end SRL with recurrent neural networks (RNN) has gained increasing attention. However, it remains a major challenge for RNNs to handle structural information and long range dependencies. In this paper, we present a simple and effective architecture for SRL which aims to address these problems. Our model is based on self-attention which can directly capture the relationships between two tokens regardless of their distance. Our single model achieves F$_1=83.4$ on the CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared task dataset, which outperforms the previous state-of-the-art results by $1.8$ and $1.0$ F$_1$ score respectively. Besides, our model is computationally efficient, and the parsing speed is 50K tokens per second on a single Titan X GPU.",
      "url": "https://www.semanticscholar.org/paper/6ed376a26045ff0048ec2b216785d396960d6ed1",
      "venue": "AAAI",
      "citationVelocity": 61,
      "influentialCitationCount": 19
    }
  },
  {
    "id": "7ed7a41c275f2870b840a5e6c3eaec8888c9480c",
    "type": "paper",
    "attributes": {
      "s2Id": "7ed7a41c275f2870b840a5e6c3eaec8888c9480c",
      "authors": [
        {
          "id": "3259253",
          "name": "Kristina Toutanova",
          "url": "https://www.semanticscholar.org/author/3259253"
        },
        {
          "id": "1761880",
          "name": "A. Haghighi",
          "url": "https://www.semanticscholar.org/author/1761880"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        }
      ],
      "year": 2008,
      "title": "A Global Joint Model for Semantic Role Labeling",
      "abstract": "We present a model for semantic role labeling that effectively captures the linguistic intuition that a semantic argument frame is a joint structure, with strong dependencies among the arguments. We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases. The proposed model substantially outperforms a similar state-of-the-art local model that does not include dependencies among different arguments. We evaluate the gains from incorporating this joint information on the Propbank corpus, when using correct syntactic parse trees as input, and when using automatically derived parse trees. The gains amount to 24.1% error reduction on all arguments and 36.8% on core arguments for gold-standard parse trees on Propbank. For automatic parse trees, the error reductions are 8.3% and 10.3% on all and core arguments, respectively. We also present results on the CoNLL 2005 shared task data set. Additionally, we explore considering multiple syntactic analyses to cope with parser noise and uncertainty.",
      "url": "https://www.semanticscholar.org/paper/7ed7a41c275f2870b840a5e6c3eaec8888c9480c",
      "venue": "Computational Linguistics",
      "citationVelocity": 8,
      "influentialCitationCount": 13
    }
  },
  {
    "id": "eb42a490cf4f186d3383c92963817d100afd81e2",
    "type": "paper",
    "attributes": {
      "s2Id": "eb42a490cf4f186d3383c92963817d100afd81e2",
      "authors": [
        {
          "id": "3259253",
          "name": "Kristina Toutanova",
          "url": "https://www.semanticscholar.org/author/3259253"
        },
        {
          "id": "38666915",
          "name": "D. Klein",
          "url": "https://www.semanticscholar.org/author/38666915"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        },
        {
          "id": "1740765",
          "name": "Y. Singer",
          "url": "https://www.semanticscholar.org/author/1740765"
        }
      ],
      "year": 2003,
      "title": "Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network",
      "abstract": "We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.",
      "url": "https://www.semanticscholar.org/paper/eb42a490cf4f186d3383c92963817d100afd81e2",
      "venue": "HLT-NAACL",
      "citationVelocity": 221,
      "influentialCitationCount": 263
    }
  },
  {
    "id": "825655fbfc32bedb93781fa14eb0c07e2f0abf5b",
    "type": "paper",
    "attributes": {
      "s2Id": "825655fbfc32bedb93781fa14eb0c07e2f0abf5b",
      "authors": [
        {
          "id": "144241030",
          "name": "F. Park",
          "url": "https://www.semanticscholar.org/author/144241030"
        }
      ],
      "year": 2005,
      "title": "SEMI-SUPERVISED LEARNING FOR SPOKEN LANGUAGE UNDERSTANDING USING SEMANTIC ROLE LABELING",
      "abstract": "In a goal-oriented spoken dialog system, the major aim of language understanding is to classify utterances into one or more of the pre-defined intents and extract the associated named entities. Typically, the intents are designed by a human expert according to the application domain. Furthermore, these systems are trained using large amounts of data manually labeled using an already prepared labeling guide. In this paper, we propose a semi-supervised spoken language understanding approach based on the taskindependent semantic role labeling of the utterances. The goal is to extract the predicates and the associated arguments from spoken language by using semantic role labeling and determine the intents based on these predicate/argument pairs. We propose an iterative approach using the automatically labeled utterances with semantic roles as the seed training data for intent classification. We have evaluated this understanding approach using two AT&T spoken dialog system applications used for customer care. We have shown that the semantic parses obtained without using any syntactically or semantically labeled in-domain data can represent the semantic intents without a need for manual intent and labeling guide design and labeling phases. Using this approach on automatic speech recognizer transcriptions, for both applications, we have achieved the 86.5% of the performance of a classification model trained with thousands of labeled utterances.",
      "url": "https://www.semanticscholar.org/paper/825655fbfc32bedb93781fa14eb0c07e2f0abf5b",
      "venue": "",
      "citationVelocity": 0,
      "influentialCitationCount": 0
    }
  },
  {
    "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
    "type": "paper",
    "attributes": {
      "s2Id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
      "authors": [
        {
          "id": "40348417",
          "name": "Ashish Vaswani",
          "url": "https://www.semanticscholar.org/author/40348417"
        },
        {
          "id": "1846258",
          "name": "Noam Shazeer",
          "url": "https://www.semanticscholar.org/author/1846258"
        },
        {
          "id": "3877127",
          "name": "Niki Parmar",
          "url": "https://www.semanticscholar.org/author/3877127"
        },
        {
          "id": "39328010",
          "name": "Jakob Uszkoreit",
          "url": "https://www.semanticscholar.org/author/39328010"
        },
        {
          "id": "145024664",
          "name": "Llion Jones",
          "url": "https://www.semanticscholar.org/author/145024664"
        },
        {
          "id": "19177000",
          "name": "Aidan N. Gomez",
          "url": "https://www.semanticscholar.org/author/19177000"
        },
        {
          "id": "40527594",
          "name": "L. Kaiser",
          "url": "https://www.semanticscholar.org/author/40527594"
        },
        {
          "id": "3443442",
          "name": "Illia Polosukhin",
          "url": "https://www.semanticscholar.org/author/3443442"
        }
      ],
      "year": 2017,
      "title": "Attention is All you Need",
      "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "url": "https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776",
      "venue": "NIPS",
      "citationVelocity": 4658,
      "influentialCitationCount": 3474
    }
  },
  {
    "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
    "type": "paper",
    "attributes": {
      "s2Id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
      "authors": [
        {
          "id": "40348417",
          "name": "Ashish Vaswani",
          "url": "https://www.semanticscholar.org/author/40348417"
        },
        {
          "id": "1846258",
          "name": "Noam Shazeer",
          "url": "https://www.semanticscholar.org/author/1846258"
        },
        {
          "id": "3877127",
          "name": "Niki Parmar",
          "url": "https://www.semanticscholar.org/author/3877127"
        },
        {
          "id": "39328010",
          "name": "Jakob Uszkoreit",
          "url": "https://www.semanticscholar.org/author/39328010"
        },
        {
          "id": "145024664",
          "name": "Llion Jones",
          "url": "https://www.semanticscholar.org/author/145024664"
        },
        {
          "id": "19177000",
          "name": "Aidan N. Gomez",
          "url": "https://www.semanticscholar.org/author/19177000"
        },
        {
          "id": "40527594",
          "name": "L. Kaiser",
          "url": "https://www.semanticscholar.org/author/40527594"
        },
        {
          "id": "3443442",
          "name": "Illia Polosukhin",
          "url": "https://www.semanticscholar.org/author/3443442"
        }
      ],
      "year": 2017,
      "title": "Attention is All you Need",
      "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "url": "https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776",
      "venue": "NIPS",
      "citationVelocity": 4658,
      "influentialCitationCount": 3474
    }
  },
  {
    "id": "999f0acfac28215db2e4c69ff42711fd4f56511d",
    "type": "paper",
    "attributes": {
      "s2Id": "999f0acfac28215db2e4c69ff42711fd4f56511d",
      "authors": [
        {
          "id": "48016277",
          "name": "Hai Wang",
          "url": "https://www.semanticscholar.org/author/48016277"
        },
        {
          "id": "143977268",
          "name": "Mohit Bansal",
          "url": "https://www.semanticscholar.org/author/143977268"
        },
        {
          "id": "1700980",
          "name": "Kevin Gimpel",
          "url": "https://www.semanticscholar.org/author/1700980"
        },
        {
          "id": "145689002",
          "name": "David A. McAllester",
          "url": "https://www.semanticscholar.org/author/145689002"
        }
      ],
      "year": 2015,
      "title": "Machine Comprehension with Syntax, Frames, and Semantics",
      "abstract": "We demonstrate significant improvement on the MCTest question answering task (Richardson et al., 2013) by augmenting baseline features with features based on syntax, frame semantics, coreference, and word embeddings, and combining them in a max-margin learning framework. We achieve the best results we are aware of on this dataset, outperforming concurrentlypublished results. These results demonstrate a significant performance gradient for the use of linguistic structure in machine comprehension.",
      "url": "https://www.semanticscholar.org/paper/999f0acfac28215db2e4c69ff42711fd4f56511d",
      "venue": "ACL",
      "citationVelocity": 17,
      "influentialCitationCount": 11
    }
  },
  {
    "id": "9405d0388f90ba1432ef13c21309d8363860e22e",
    "type": "paper",
    "attributes": {
      "s2Id": "9405d0388f90ba1432ef13c21309d8363860e22e",
      "authors": [
        {
          "id": "2022124",
          "name": "Barbara Plank",
          "url": "https://www.semanticscholar.org/author/2022124"
        },
        {
          "id": "3017695",
          "name": "Héctor Martínez Alonso",
          "url": "https://www.semanticscholar.org/author/3017695"
        }
      ],
      "year": 2017,
      "title": "When is multitask learning effective? Semantic sequence prediction under varying data conditions",
      "abstract": "Multitask learning has been applied successfully to a range of tasks, mostly morphosyntactic. However, little is known on when MTL works and whether there are data characteristics that help to determine its success. In this paper we evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine different auxiliary tasks, amongst which a novel setup, and correlate their impact to data-dependent conditions. Our results show that MTL is not always effective, significant improvements are obtained only for 1 out of 5 tasks. When successful, auxiliary tasks with compact and more uniform label distributions are preferable.",
      "url": "https://www.semanticscholar.org/paper/9405d0388f90ba1432ef13c21309d8363860e22e",
      "venue": "EACL",
      "citationVelocity": 31,
      "influentialCitationCount": 17
    }
  },
  {
    "id": "6789e0dbd294cccb3b7dd4e001c9e8ba4813f334",
    "type": "paper",
    "attributes": {
      "s2Id": "6789e0dbd294cccb3b7dd4e001c9e8ba4813f334",
      "authors": [
        {
          "id": "143668305",
          "name": "Miguel Ballesteros",
          "url": "https://www.semanticscholar.org/author/143668305"
        },
        {
          "id": "2089067",
          "name": "Y. Goldberg",
          "url": "https://www.semanticscholar.org/author/2089067"
        },
        {
          "id": "1745899",
          "name": "Chris Dyer",
          "url": "https://www.semanticscholar.org/author/1745899"
        },
        {
          "id": "144365875",
          "name": "Noah A. Smith",
          "url": "https://www.semanticscholar.org/author/144365875"
        }
      ],
      "year": 2016,
      "title": "Training with Exploration Improves a Greedy Stack LSTM Parser",
      "abstract": "We adapt the greedy Stack-LSTM dependency parser of Dyer et al. (2015) to support a training-with-exploration procedure using dynamic oracles(Goldberg and Nivre, 2013) instead of cross-entropy minimization. This form of training, which accounts for model predictions at training time rather than assuming an error-free action history, improves parsing accuracies for both English and Chinese, obtaining very strong results for both languages. We discuss some modifications needed in order to get training with exploration to work well for a probabilistic neural-network.",
      "url": "https://www.semanticscholar.org/paper/6789e0dbd294cccb3b7dd4e001c9e8ba4813f334",
      "venue": "EMNLP",
      "citationVelocity": 14,
      "influentialCitationCount": 7
    }
  },
  {
    "id": "ad90fa2a6e97e87dfcea36cbcffabdfe62f57e6f",
    "type": "paper",
    "attributes": {
      "s2Id": "ad90fa2a6e97e87dfcea36cbcffabdfe62f57e6f",
      "authors": [
        {
          "id": "3261695",
          "name": "M. Bazrafshan",
          "url": "https://www.semanticscholar.org/author/3261695"
        },
        {
          "id": "1793218",
          "name": "Daniel Gildea",
          "url": "https://www.semanticscholar.org/author/1793218"
        }
      ],
      "year": 2013,
      "title": "Semantic Roles for String to Tree Machine Translation",
      "abstract": "We experiment with adding semantic role information to a string-to-tree machine translation system based on the rule extraction procedure of Galley et al. (2004). We compare methods based on augmenting the set of nonterminals by adding semantic role labels, and altering the rule extraction process to produce a separate set of rules for each predicate that encompass its entire predicate-argument structure. Our results demonstrate that the second approach is effective in increasing the quality of translations.",
      "url": "https://www.semanticscholar.org/paper/ad90fa2a6e97e87dfcea36cbcffabdfe62f57e6f",
      "venue": "ACL",
      "citationVelocity": 0,
      "influentialCitationCount": 1
    }
  },
  {
    "id": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
    "type": "paper",
    "attributes": {
      "s2Id": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
      "authors": [
        {
          "id": "1751569",
          "name": "S. Bengio",
          "url": "https://www.semanticscholar.org/author/1751569"
        },
        {
          "id": "1689108",
          "name": "Oriol Vinyals",
          "url": "https://www.semanticscholar.org/author/1689108"
        },
        {
          "id": "3111912",
          "name": "Navdeep Jaitly",
          "url": "https://www.semanticscholar.org/author/3111912"
        },
        {
          "id": "1846258",
          "name": "Noam Shazeer",
          "url": "https://www.semanticscholar.org/author/1846258"
        }
      ],
      "year": 2015,
      "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks",
      "abstract": "Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used succesfully in our winning entry to the MSCOCO image captioning challenge, 2015.",
      "url": "https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
      "venue": "NIPS",
      "citationVelocity": 269,
      "influentialCitationCount": 112
    }
  },
  {
    "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
    "type": "paper",
    "attributes": {
      "s2Id": "d0be39ee052d246ae99c082a565aba25b811be2d",
      "authors": [
        {
          "id": "1751762",
          "name": "Yoshua Bengio",
          "url": "https://www.semanticscholar.org/author/1751762"
        },
        {
          "id": "2812486",
          "name": "P. Simard",
          "url": "https://www.semanticscholar.org/author/2812486"
        },
        {
          "id": "1688235",
          "name": "P. Frasconi",
          "url": "https://www.semanticscholar.org/author/1688235"
        }
      ],
      "year": 1994,
      "title": "Learning long-term dependencies with gradient descent is difficult",
      "abstract": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.",
      "url": "https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d",
      "venue": "IEEE Trans. Neural Networks",
      "citationVelocity": 937,
      "influentialCitationCount": 227
    }
  },
  {
    "id": "6396ab37641d36be4c26420e58adeb8665914c3b",
    "type": "paper",
    "attributes": {
      "s2Id": "6396ab37641d36be4c26420e58adeb8665914c3b",
      "authors": [
        {
          "id": "1750652",
          "name": "Jonathan Berant",
          "url": "https://www.semanticscholar.org/author/1750652"
        },
        {
          "id": "3052879",
          "name": "V. Srikumar",
          "url": "https://www.semanticscholar.org/author/3052879"
        },
        {
          "id": "49490552",
          "name": "P. Chen",
          "url": "https://www.semanticscholar.org/author/49490552"
        },
        {
          "id": "1824195",
          "name": "A. V. Linden",
          "url": "https://www.semanticscholar.org/author/1824195"
        },
        {
          "id": "144521450",
          "name": "Brittany Harding",
          "url": "https://www.semanticscholar.org/author/144521450"
        },
        {
          "id": "2988874",
          "name": "Brad Huang",
          "url": "https://www.semanticscholar.org/author/2988874"
        },
        {
          "id": "48323507",
          "name": "Peter Clark",
          "url": "https://www.semanticscholar.org/author/48323507"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        }
      ],
      "year": 2014,
      "title": "Modeling Biological Processes for Reading Comprehension",
      "abstract": "Machine reading calls for programs that read and understand text, but most current work only attempts to extract facts from redundant web-scale corpora. In this paper, we focus on a new reading comprehension task that requires complex reasoning over a single document. The input is a paragraph describing a biological process, and the goal is to answer questions that require an understanding of the relations between entities and events in the process. To answer the questions, we first predict a rich structure representing the process in the paragraph. Then, we map the question to a formal query, which is executed against the predicted structure. We demonstrate that answering questions via predicted structures substantially improves accuracy over baselines that use shallower representations.",
      "url": "https://www.semanticscholar.org/paper/6396ab37641d36be4c26420e58adeb8665914c3b",
      "venue": "EMNLP",
      "citationVelocity": 20,
      "influentialCitationCount": 10
    }
  },
  {
    "id": "1b02204b210f822dabf8d68b7e3ea7ac14ee1268",
    "type": "paper",
    "attributes": {
      "s2Id": "1b02204b210f822dabf8d68b7e3ea7ac14ee1268",
      "authors": [
        {
          "id": "1700187",
          "name": "Anders Søgaard",
          "url": "https://www.semanticscholar.org/author/1700187"
        },
        {
          "id": "3053695",
          "name": "Joachim Bingel",
          "url": "https://www.semanticscholar.org/author/3053695"
        }
      ],
      "year": 2017,
      "title": "Identifying beneficial task relations for multi-task learning in deep neural networks",
      "abstract": "Multi-task learning (MTL) in deep neural networks for NLP has recently received increasing interest due to some compelling benefits, including its potential to efficiently regularize models and to reduce the need for labeled data. While it has brought significant improvements in a number of NLP tasks, mixed results have been reported, and little is known about the conditions under which MTL leads to gains in NLP. This paper sheds light on the specific task relations that can lead to gains from MTL models over single-task setups.",
      "url": "https://www.semanticscholar.org/paper/1b02204b210f822dabf8d68b7e3ea7ac14ee1268",
      "venue": "EACL",
      "citationVelocity": 46,
      "influentialCitationCount": 5
    }
  },
  {
    "id": "25e7efa59a5cf68e0fc9401e4c6fa7b2bfe3f1ae",
    "type": "paper",
    "attributes": {
      "s2Id": "25e7efa59a5cf68e0fc9401e4c6fa7b2bfe3f1ae",
      "authors": [
        {
          "id": "1701734",
          "name": "X. Carreras",
          "url": "https://www.semanticscholar.org/author/1701734"
        },
        {
          "id": "3049328",
          "name": "Lluís Màrquez i Villodre",
          "url": "https://www.semanticscholar.org/author/3049328"
        }
      ],
      "year": 2005,
      "title": "Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling",
      "abstract": "In this paper we describe the CoNLL-2005 shared task on Semantic Role Labeling. We introduce the specification and goals of the task, describe the data sets and evaluation methods, and present a general overview of the 19 systems that have contributed to the task, providing a comparative description and results.",
      "url": "https://www.semanticscholar.org/paper/25e7efa59a5cf68e0fc9401e4c6fa7b2bfe3f1ae",
      "venue": "CoNLL",
      "citationVelocity": 35,
      "influentialCitationCount": 79
    }
  },
  {
    "id": "9464d15f4f8d578f93332db4aa1c9c182fd51735",
    "type": "paper",
    "attributes": {
      "s2Id": "9464d15f4f8d578f93332db4aa1c9c182fd51735",
      "authors": [
        {
          "id": "145727186",
          "name": "R. Caruana",
          "url": "https://www.semanticscholar.org/author/145727186"
        }
      ],
      "year": 1993,
      "title": "Multitask Learning: A Knowledge-Based Source of Inductive Bias",
      "abstract": "This paper suggests that it may be easier to learn several hard tasks at one time than to learn these same tasks separately. In effect, the information provided by the training signal for each task serves as a domain-specific inductive bias for the other tasks. Frequently the world gives us clusters of related tasks to learn. When it does not, it is often straightforward to create additional tasks. For many domains, acquiring inductive bias by collecting additional teaching signal may be more practical than the traditional approach of codifying domain-specific biases acquired from human expertise. We call this approach Multitask Learning (MTL). Since much of the power of an inductive learner follows directly from its inductive bias, multitask learning may yield more powerful learning. An empirical example of multitask connectionist learning is presented where learning improves by training one network on several related tasks at the same time. Multitask decision tree induction is also outlined.",
      "url": "https://www.semanticscholar.org/paper/9464d15f4f8d578f93332db4aa1c9c182fd51735",
      "venue": "ICML",
      "citationVelocity": 105,
      "influentialCitationCount": 64
    }
  },
  {
    "id": "ed02ce4a53407d460eff371f506bfea1e13187d2",
    "type": "paper",
    "attributes": {
      "s2Id": "ed02ce4a53407d460eff371f506bfea1e13187d2",
      "authors": [
        {
          "id": "2782886",
          "name": "Kai-Wei Chang",
          "url": "https://www.semanticscholar.org/author/2782886"
        },
        {
          "id": "37019006",
          "name": "A. Krishnamurthy",
          "url": "https://www.semanticscholar.org/author/37019006"
        },
        {
          "id": "40333747",
          "name": "A. Agarwal",
          "url": "https://www.semanticscholar.org/author/40333747"
        },
        {
          "id": "1722360",
          "name": "Hal Daumé",
          "url": "https://www.semanticscholar.org/author/1722360"
        },
        {
          "id": "144162125",
          "name": "J. Langford",
          "url": "https://www.semanticscholar.org/author/144162125"
        }
      ],
      "year": 2015,
      "title": "Learning to Search Better than Your Teacher",
      "abstract": "Methods for learning to search for structured prediction typically imitate a reference policy, with existing theoretical guarantees demonstrating low regret compared to that reference. This is unsatisfactory in many applications where the reference policy is suboptimal and the goal of learning is to improve upon it. Can learning to search work even when the reference is poor? \n \nWe provide a new learning to search algorithm, LOLS, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee. Consequently, LOLS can improve upon the reference policy, unlike previous algorithms. This enables us to develop structured contextual bandits, a partial information structured prediction setting with many potential applications.",
      "url": "https://www.semanticscholar.org/paper/ed02ce4a53407d460eff371f506bfea1e13187d2",
      "venue": "ICML",
      "citationVelocity": 37,
      "influentialCitationCount": 26
    }
  },
  {
    "id": "df2cf1f95d7a37d073b6c01ee8143f1b15fdf9e9",
    "type": "paper",
    "attributes": {
      "s2Id": "df2cf1f95d7a37d073b6c01ee8143f1b15fdf9e9",
      "authors": [
        {
          "id": "1725643",
          "name": "Yun-Nung (Vivian) Chen",
          "url": "https://www.semanticscholar.org/author/1725643"
        },
        {
          "id": "1682479",
          "name": "William Yang Wang",
          "url": "https://www.semanticscholar.org/author/1682479"
        },
        {
          "id": "1783635",
          "name": "Alexander I. Rudnicky",
          "url": "https://www.semanticscholar.org/author/1783635"
        }
      ],
      "year": 2013,
      "title": "Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing",
      "abstract": "Spoken dialogue systems typically use predefined semantic slots to parse users' natural language inputs into unified semantic representations. To define the slots, domain experts and professional annotators are often involved, and the cost can be expensive. In this paper, we ask the following question: given a collection of unlabeled raw audios, can we use the frame semantics theory to automatically induce and fill the semantic slots in an unsupervised fashion? To do this, we propose the use of a state-of-the-art frame-semantic parser, and a spectral clustering based slot ranking model that adapts the generic output of the parser to the target semantic space. Empirical experiments on a real-world spoken dialogue dataset show that the automatically induced semantic slots are in line with the reference slots created by domain experts: we observe a mean averaged precision of 69.36% using ASR-transcribed data. Our slot filling evaluations also indicate the promising future of this proposed approach.",
      "url": "https://www.semanticscholar.org/paper/df2cf1f95d7a37d073b6c01ee8143f1b15fdf9e9",
      "venue": "2013 IEEE Workshop on Automatic Speech Recognition and Understanding",
      "citationVelocity": 10,
      "influentialCitationCount": 0
    }
  },
  {
    "id": "11aa6801c417dd97552737c587fd8d7f480d10ab",
    "type": "paper",
    "attributes": {
      "s2Id": "11aa6801c417dd97552737c587fd8d7f480d10ab",
      "authors": [
        {
          "id": "4724587",
          "name": "Jinho D. Choi",
          "url": "https://www.semanticscholar.org/author/4724587"
        },
        {
          "id": "145755155",
          "name": "Martha Palmer",
          "url": "https://www.semanticscholar.org/author/145755155"
        }
      ],
      "year": 2011,
      "title": "Getting the Most out of Transition-based Dependency Parsing",
      "abstract": "This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-the-art performance with respect to other parsing approaches evaluated on the same data set.",
      "url": "https://www.semanticscholar.org/paper/11aa6801c417dd97552737c587fd8d7f480d10ab",
      "venue": "ACL",
      "citationVelocity": 0,
      "influentialCitationCount": 2
    }
  },
  {
    "id": "bc1022b031dc6c7019696492e8116598097a8c12",
    "type": "paper",
    "attributes": {
      "s2Id": "bc1022b031dc6c7019696492e8116598097a8c12",
      "authors": [
        {
          "id": "2939803",
          "name": "Ronan Collobert",
          "url": "https://www.semanticscholar.org/author/2939803"
        },
        {
          "id": "145183709",
          "name": "J. Weston",
          "url": "https://www.semanticscholar.org/author/145183709"
        },
        {
          "id": "52184096",
          "name": "L. Bottou",
          "url": "https://www.semanticscholar.org/author/52184096"
        },
        {
          "id": "21432929",
          "name": "Michael Karlen",
          "url": "https://www.semanticscholar.org/author/21432929"
        },
        {
          "id": "2645384",
          "name": "K. Kavukcuoglu",
          "url": "https://www.semanticscholar.org/author/2645384"
        },
        {
          "id": "46283650",
          "name": "P. Kuksa",
          "url": "https://www.semanticscholar.org/author/46283650"
        }
      ],
      "year": 2011,
      "title": "Natural Language Processing (Almost) from Scratch",
      "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.",
      "url": "https://www.semanticscholar.org/paper/bc1022b031dc6c7019696492e8116598097a8c12",
      "venue": "J. Mach. Learn. Res.",
      "citationVelocity": 1006,
      "influentialCitationCount": 627
    }
  },
  {
    "id": "3c9d9f3c6f7508f4e29730924529dc993c27cddc",
    "type": "paper",
    "attributes": {
      "s2Id": "3c9d9f3c6f7508f4e29730924529dc993c27cddc",
      "authors": [
        {
          "id": "1722360",
          "name": "Hal Daumé",
          "url": "https://www.semanticscholar.org/author/1722360"
        },
        {
          "id": "144162125",
          "name": "J. Langford",
          "url": "https://www.semanticscholar.org/author/144162125"
        },
        {
          "id": "1695463",
          "name": "D. Marcu",
          "url": "https://www.semanticscholar.org/author/1695463"
        }
      ],
      "year": 2009,
      "title": "Search-based structured prediction",
      "abstract": "We present Searn, an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision. Searn is a meta-algorithm that transforms these complex problems into simple classification problems to which any binary classifier may be applied. Unlike current algorithms for structured learning that require decomposition of both the loss function and the feature functions over the predicted structure, Searn is able to learn prediction functions for any loss function and any class of features. Moreover, Searn comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies good performance on the structured prediction problem.",
      "url": "https://www.semanticscholar.org/paper/3c9d9f3c6f7508f4e29730924529dc993c27cddc",
      "venue": "Machine Learning",
      "citationVelocity": 61,
      "influentialCitationCount": 48
    }
  },
  {
    "id": "d44efdc542f2cc5e196f04bc76bc783bfd7084af",
    "type": "paper",
    "attributes": {
      "s2Id": "d44efdc542f2cc5e196f04bc76bc783bfd7084af",
      "authors": [
        {
          "id": "2277385",
          "name": "Timothy Dozat",
          "url": "https://www.semanticscholar.org/author/2277385"
        }
      ],
      "year": 2016,
      "title": "Incorporating Nesterov Momentum into Adam",
      "abstract": null,
      "url": "https://www.semanticscholar.org/paper/d44efdc542f2cc5e196f04bc76bc783bfd7084af",
      "venue": "",
      "citationVelocity": 217,
      "influentialCitationCount": 92
    }
  },
  {
    "id": "8cbef23c9ee2ae7c35cc691a0c1d713a6377c9f2",
    "type": "paper",
    "attributes": {
      "s2Id": "8cbef23c9ee2ae7c35cc691a0c1d713a6377c9f2",
      "authors": [
        {
          "id": "2277385",
          "name": "Timothy Dozat",
          "url": "https://www.semanticscholar.org/author/2277385"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        }
      ],
      "year": 2017,
      "title": "Deep Biaffine Attention for Neural Dependency Parsing",
      "abstract": "This paper builds off recent work from Kiperwasser & Goldberg (2016) using neural attention in a simple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other recent BiLSTM-based approaches, with biaffine classifiers to predict arcs and labels. Our parser gets state of the art or near state of the art performance on standard treebanks for six different languages, achieving 95.7% UAS and 94.1% LAS on the most popular English PTB dataset. This makes it the highest-performing graph-based parser on this benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and 2.2%---and comparable to the highest performing transition-based parser (Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show which hyperparameter choices had a significant effect on parsing accuracy, allowing us to achieve large gains over other graph-based approaches.",
      "url": "https://www.semanticscholar.org/paper/8cbef23c9ee2ae7c35cc691a0c1d713a6377c9f2",
      "venue": "ICLR",
      "citationVelocity": 153,
      "influentialCitationCount": 70
    }
  },
  {
    "id": "c6b8c1728e6d2572b16ca2bfa5c3c82bb0fd8be6",
    "type": "paper",
    "attributes": {
      "s2Id": "c6b8c1728e6d2572b16ca2bfa5c3c82bb0fd8be6",
      "authors": [
        {
          "id": "143883142",
          "name": "Nicholas FitzGerald",
          "url": "https://www.semanticscholar.org/author/143883142"
        },
        {
          "id": "2556289",
          "name": "Oscar Täckström",
          "url": "https://www.semanticscholar.org/author/2556289"
        },
        {
          "id": "144422385",
          "name": "K. Ganchev",
          "url": "https://www.semanticscholar.org/author/144422385"
        },
        {
          "id": "143790066",
          "name": "Dipanjan Das",
          "url": "https://www.semanticscholar.org/author/143790066"
        }
      ],
      "year": 2015,
      "title": "Semantic Role Labeling with Neural Network Factors",
      "abstract": "We present a new method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space for a given predicate. These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task. We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model. We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset.",
      "url": "https://www.semanticscholar.org/paper/c6b8c1728e6d2572b16ca2bfa5c3c82bb0fd8be6",
      "venue": "EMNLP",
      "citationVelocity": 24,
      "influentialCitationCount": 17
    }
  },
  {
    "id": "d4bd0035fe14832626279e6c3c72b73c21c7f5d8",
    "type": "paper",
    "attributes": {
      "s2Id": "d4bd0035fe14832626279e6c3c72b73c21c7f5d8",
      "authors": [
        {
          "id": "2089067",
          "name": "Y. Goldberg",
          "url": "https://www.semanticscholar.org/author/2089067"
        },
        {
          "id": "1720988",
          "name": "Joakim Nivre",
          "url": "https://www.semanticscholar.org/author/1720988"
        }
      ],
      "year": 2012,
      "title": "A Dynamic Oracle for Arc-Eager Dependency Parsing",
      "abstract": "The standard training regime for transition-based dependency parsers makes use of an oracle, which predicts an optimal transition sequence for a sentence and its gold tree. We present an improved oracle for the arc-eager transition system, which provides a set of optimal transitions for every valid parser configuration, including configurations from which the gold tree is not reachable. In such cases, the oracle provides transitions that will lead to the best reachable tree from the given configuration. The oracle is efficient to implement and provably correct. We use the oracle to train a deterministic left-to-right dependency parser that is less sensitive to error propagation, using an online training procedure that also explores parser configurations resulting from non-optimal sequences of transitions. This new parser outperforms greedy parsers trained using conventional oracles on a range of data sets, with an average improvement of over 1.2 LAS points and up to almost 3 LAS points on some data sets.",
      "url": "https://www.semanticscholar.org/paper/d4bd0035fe14832626279e6c3c72b73c21c7f5d8",
      "venue": "COLING",
      "citationVelocity": 27,
      "influentialCitationCount": 9
    }
  },
  {
    "id": "ade0c116120b54b57a91da51235108b75c28375a",
    "type": "paper",
    "attributes": {
      "s2Id": "ade0c116120b54b57a91da51235108b75c28375a",
      "authors": [
        {
          "id": "20851195",
          "name": "Kazuma Hashimoto",
          "url": "https://www.semanticscholar.org/author/20851195"
        },
        {
          "id": "2228109",
          "name": "Caiming Xiong",
          "url": "https://www.semanticscholar.org/author/2228109"
        },
        {
          "id": "143946906",
          "name": "Yoshimasa Tsuruoka",
          "url": "https://www.semanticscholar.org/author/143946906"
        },
        {
          "id": "2166511",
          "name": "R. Socher",
          "url": "https://www.semanticscholar.org/author/2166511"
        }
      ],
      "year": 2017,
      "title": "A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks",
      "abstract": "Transfer and multi-task learning have traditionally focused on either a single source-target pair or very few, similar tasks. Ideally, the linguistic levels of morphology, syntax and semantics would benefit each other by being trained in a single model. We introduce a joint many-task model together with a strategy for successively growing its depth to solve increasingly complex tasks. Higher layers include shortcut connections to lower-level task predictions to reflect linguistic hierarchies. We use a simple regularization term to allow for optimizing all model weights to improve one task’s loss without exhibiting catastrophic interference of the other tasks. Our single end-to-end model obtains state-of-the-art or competitive results on five different tasks from tagging, parsing, relatedness, and entailment tasks.",
      "url": "https://www.semanticscholar.org/paper/ade0c116120b54b57a91da51235108b75c28375a",
      "venue": "EMNLP",
      "citationVelocity": 109,
      "influentialCitationCount": 36
    }
  },
  {
    "id": "7442a18a55f257a68f21d0cbb8b1395f8915a452",
    "type": "paper",
    "attributes": {
      "s2Id": "7442a18a55f257a68f21d0cbb8b1395f8915a452",
      "authors": [
        {
          "id": "2265599",
          "name": "Luheng He",
          "url": "https://www.semanticscholar.org/author/2265599"
        },
        {
          "id": "2544107",
          "name": "Kenton Lee",
          "url": "https://www.semanticscholar.org/author/2544107"
        },
        {
          "id": "39455775",
          "name": "Omer Levy",
          "url": "https://www.semanticscholar.org/author/39455775"
        },
        {
          "id": "1982950",
          "name": "Luke Zettlemoyer",
          "url": "https://www.semanticscholar.org/author/1982950"
        }
      ],
      "year": 2018,
      "title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling",
      "abstract": "Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features. We propose an end-to-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.",
      "url": "https://www.semanticscholar.org/paper/7442a18a55f257a68f21d0cbb8b1395f8915a452",
      "venue": "ACL",
      "citationVelocity": 38,
      "influentialCitationCount": 23
    }
  },
  {
    "id": "a4dd3beea286a20c4e4f66436875932d597190bc",
    "type": "paper",
    "attributes": {
      "s2Id": "a4dd3beea286a20c4e4f66436875932d597190bc",
      "authors": [
        {
          "id": "2265599",
          "name": "Luheng He",
          "url": "https://www.semanticscholar.org/author/2265599"
        },
        {
          "id": "2544107",
          "name": "Kenton Lee",
          "url": "https://www.semanticscholar.org/author/2544107"
        },
        {
          "id": "35084211",
          "name": "M. Lewis",
          "url": "https://www.semanticscholar.org/author/35084211"
        },
        {
          "id": "1982950",
          "name": "Luke Zettlemoyer",
          "url": "https://www.semanticscholar.org/author/1982950"
        }
      ],
      "year": 2017,
      "title": "Deep Semantic Role Labeling: What Works and What's Next",
      "abstract": "We introduce a new deep learning model for semantic role labeling (SRL) that significantly improves the state of the art, along with detailed analyses to reveal its strengths and limitations. We use a deep highway BiLSTM architecture with constrained decoding, while observing a number of recent best practices for initialization and regularization. Our 8-layer ensemble model achieves 83.2 F1 on theCoNLL 2005 test set and 83.4 F1 on CoNLL 2012, roughly a 10% relative error reduction over the previous state of the art. Extensive empirical analysis of these gains show that (1) deep models excel at recovering long-distance dependencies but can still make surprisingly obvious errors, and (2) that there is still room for syntactic parsers to improve these results.",
      "url": "https://www.semanticscholar.org/paper/a4dd3beea286a20c4e4f66436875932d597190bc",
      "venue": "ACL",
      "citationVelocity": 90,
      "influentialCitationCount": 58
    }
  },
  {
    "id": "2791e0d36ba23763195ac984453d61dbaff555da",
    "type": "paper",
    "attributes": {
      "s2Id": "2791e0d36ba23763195ac984453d61dbaff555da",
      "authors": [
        {
          "id": "145341661",
          "name": "Richard Johansson",
          "url": "https://www.semanticscholar.org/author/145341661"
        },
        {
          "id": "1754406",
          "name": "P. Nugues",
          "url": "https://www.semanticscholar.org/author/1754406"
        }
      ],
      "year": 2008,
      "title": "Dependency-based Semantic Role Labeling of PropBank",
      "abstract": "We present a PropBank semantic role labeling system for English that is integrated with a dependency parser. To tackle the problem of joint syntactic--semantic analysis, the system relies on a syntactic and a semantic subcomponent. The syntactic model is a projective parser using pseudo-projective transformations, and the semantic model uses global inference mechanisms on top of a pipeline of classifiers. The complete syntactic-semantic output is selected from a candidate pool generated by the subsystems. \n \nWe evaluate the system on the CoNLL-2005 test sets using segment-based and dependency-based metrics. Using the segment-based CoNLL-2005 metric, our system achieves a near state-of-the-art F1 figure of 77.97 on the WSJ+Brown test set, or 78.84 if punctuation is treated consistently. Using a dependency-based metric, the F1 figure of our system is 84.29 on the test set from CoNLL-2008. Our system is the first dependency-based semantic role labeler for PropBank that rivals constituent-based systems in terms of performance.",
      "url": "https://www.semanticscholar.org/paper/2791e0d36ba23763195ac984453d61dbaff555da",
      "venue": "EMNLP",
      "citationVelocity": 10,
      "influentialCitationCount": 12
    }
  },
  {
    "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
    "type": "paper",
    "attributes": {
      "s2Id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
      "authors": [
        {
          "id": "1726807",
          "name": "Diederik P. Kingma",
          "url": "https://www.semanticscholar.org/author/1726807"
        },
        {
          "id": "2503659",
          "name": "Jimmy Ba",
          "url": "https://www.semanticscholar.org/author/2503659"
        }
      ],
      "year": 2015,
      "title": "Adam: A Method for Stochastic Optimization",
      "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",
      "url": "https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8",
      "venue": "ICLR",
      "citationVelocity": 16057,
      "influentialCitationCount": 9609
    }
  },
  {
    "id": "eec3a236ecd185712ce65fb336141f8656eea13d",
    "type": "paper",
    "attributes": {
      "s2Id": "eec3a236ecd185712ce65fb336141f8656eea13d",
      "authors": [
        {
          "id": "2022679",
          "name": "E. Kiperwasser",
          "url": "https://www.semanticscholar.org/author/2022679"
        },
        {
          "id": "2089067",
          "name": "Y. Goldberg",
          "url": "https://www.semanticscholar.org/author/2089067"
        }
      ],
      "year": 2016,
      "title": "Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations",
      "abstract": "We present a simple and effective scheme for dependency parsing which is based on bidirectional-LSTMs (BiLSTMs). Each sentence token is associated with a BiLSTM vector representing the token in its sentential context, and feature vectors are constructed by concatenating a few BiLSTM vectors. The BiLSTM is trained jointly with the parser objective, resulting in very effective feature extractors for parsing. We demonstrate the effectiveness of the approach by applying it to a greedy transition-based parser as well as to a globally optimized graph-based parser. The resulting parsers have very simple architectures, and match or surpass the state-of-the-art accuracies on English and Chinese.",
      "url": "https://www.semanticscholar.org/paper/eec3a236ecd185712ce65fb336141f8656eea13d",
      "venue": "Transactions of the Association for Computational Linguistics",
      "citationVelocity": 119,
      "influentialCitationCount": 49
    }
  },
  {
    "id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
    "type": "paper",
    "attributes": {
      "s2Id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
      "authors": [
        {
          "id": "2022957",
          "name": "Diego Marcheggiani",
          "url": "https://www.semanticscholar.org/author/2022957"
        },
        {
          "id": "144889265",
          "name": "Ivan Titov",
          "url": "https://www.semanticscholar.org/author/144889265"
        }
      ],
      "year": 2017,
      "title": "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling",
      "abstract": "Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.",
      "url": "https://www.semanticscholar.org/paper/c3a3c163f25b9181f1fb7e71a32482a7393d2088",
      "venue": "EMNLP",
      "citationVelocity": 124,
      "influentialCitationCount": 56
    }
  },
  {
    "id": "8ae1af4a424f5e464d46903bc3d18fe1cf1434ff",
    "type": "paper",
    "attributes": {
      "s2Id": "8ae1af4a424f5e464d46903bc3d18fe1cf1434ff",
      "authors": [
        {
          "id": "2544107",
          "name": "Kenton Lee",
          "url": "https://www.semanticscholar.org/author/2544107"
        },
        {
          "id": "2265599",
          "name": "Luheng He",
          "url": "https://www.semanticscholar.org/author/2265599"
        },
        {
          "id": "35084211",
          "name": "M. Lewis",
          "url": "https://www.semanticscholar.org/author/35084211"
        },
        {
          "id": "1982950",
          "name": "Luke Zettlemoyer",
          "url": "https://www.semanticscholar.org/author/1982950"
        }
      ],
      "year": 2017,
      "title": "End-to-end Neural Coreference Resolution",
      "abstract": "We introduce the first end-to-end coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or hand-engineered mention detector. The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each. The model computes span embeddings that combine context-dependent boundary representations with a head-finding attention mechanism. It is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions. Experiments demonstrate state-of-the-art performance, with a gain of 1.5 F1 on the OntoNotes benchmark and by 3.1 F1 using a 5-model ensemble, despite the fact that this is the first approach to be successfully trained with no external resources.",
      "url": "https://www.semanticscholar.org/paper/8ae1af4a424f5e464d46903bc3d18fe1cf1434ff",
      "venue": "EMNLP",
      "citationVelocity": 121,
      "influentialCitationCount": 82
    }
  },
  {
    "id": "6cbc1eb25f4ab29a613418b3b0740e74141a0f17",
    "type": "paper",
    "attributes": {
      "s2Id": "6cbc1eb25f4ab29a613418b3b0740e74141a0f17",
      "authors": [
        {
          "id": "145091160",
          "name": "B. Levin",
          "url": "https://www.semanticscholar.org/author/145091160"
        }
      ],
      "year": 1993,
      "title": "English Verb Classes and Alternations: A Preliminary Investigation",
      "abstract": "In this rich reference work, Beth Levin classifies over 3,000 English verbs according to shared meaning and behavior. Levin starts with the hypothesis that a verb's meaning influences its syntactic behavior and develops it into a powerful tool for studying the English verb lexicon. She shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning. The first part of the book sets out alternate ways in which verbs can express their arguments. The second presents classes of verbs that share a kernel of meaning and explores in detail the behavior of each class, drawing on the alternations in the first part. Levin's discussion of each class and alternation includes lists of relevant verbs, illustrative examples, comments on noteworthy properties, and bibliographic references. The result is an original, systematic picture of the organization of the verb inventory. Easy to use, \"English Verb Classes and Alternations\" sets the stage for further explorations of the interface between lexical semantics and syntax. It will prove indispensable for theoretical and computational linguists, psycholinguists, cognitive scientists, lexicographers, and teachers of English as a second language. Beth Levin is associate professor of linguistics at Northwestern University.",
      "url": "https://www.semanticscholar.org/paper/6cbc1eb25f4ab29a613418b3b0740e74141a0f17",
      "venue": "",
      "citationVelocity": 115,
      "influentialCitationCount": 342
    }
  },
  {
    "id": "5894c9fbe9d14be08a48e34d0467da4213b6399c",
    "type": "paper",
    "attributes": {
      "s2Id": "5894c9fbe9d14be08a48e34d0467da4213b6399c",
      "authors": [
        {
          "id": "35084211",
          "name": "M. Lewis",
          "url": "https://www.semanticscholar.org/author/35084211"
        },
        {
          "id": "2265599",
          "name": "Luheng He",
          "url": "https://www.semanticscholar.org/author/2265599"
        },
        {
          "id": "1982950",
          "name": "Luke Zettlemoyer",
          "url": "https://www.semanticscholar.org/author/1982950"
        }
      ],
      "year": 2015,
      "title": "Joint A* CCG Parsing and Semantic Role Labelling",
      "abstract": "Joint models of syntactic and semantic parsing have the potential to improve performance on both tasks—but to date, the best results have been achieved with pipelines. We introduce a joint model using CCG, which is motivated by the close link between CCG syntax and semantics. Semantic roles are recovered by labelling the deep dependency structures produced by the grammar. Furthermore, because CCG is lexicalized, we show it is possible to factor the parsing model over words and introduce a new A parsing algorithm— which we demonstrate is faster and more accurate than adaptive supertagging. Our joint model is the first to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model.",
      "url": "https://www.semanticscholar.org/paper/5894c9fbe9d14be08a48e34d0467da4213b6399c",
      "venue": "EMNLP",
      "citationVelocity": 9,
      "influentialCitationCount": 11
    }
  },
  {
    "id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
    "type": "paper",
    "attributes": {
      "s2Id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
      "authors": [
        {
          "id": "40410858",
          "name": "R. J. Williams",
          "url": "https://www.semanticscholar.org/author/40410858"
        },
        {
          "id": "1895771",
          "name": "D. Zipser",
          "url": "https://www.semanticscholar.org/author/1895771"
        }
      ],
      "year": 1989,
      "title": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks",
      "abstract": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length.",
      "url": "https://www.semanticscholar.org/paper/ce9a21b93ba29d4145a8ef6bf401e77f261848de",
      "venue": "Neural Computation",
      "citationVelocity": 286,
      "influentialCitationCount": 260
    }
  },
  {
    "id": "9fbeebb98f479405dadd912e95796ba0256b74ac",
    "type": "paper",
    "attributes": {
      "s2Id": "9fbeebb98f479405dadd912e95796ba0256b74ac",
      "authors": [
        {
          "id": "1771298",
          "name": "D. Zeman",
          "url": "https://www.semanticscholar.org/author/1771298"
        },
        {
          "id": "48857526",
          "name": "M. Popel",
          "url": "https://www.semanticscholar.org/author/48857526"
        },
        {
          "id": "2757959",
          "name": "M. Straka",
          "url": "https://www.semanticscholar.org/author/2757959"
        },
        {
          "id": "144002335",
          "name": "Jan Hajic",
          "url": "https://www.semanticscholar.org/author/144002335"
        },
        {
          "id": "1720988",
          "name": "Joakim Nivre",
          "url": "https://www.semanticscholar.org/author/1720988"
        },
        {
          "id": "1694491",
          "name": "F. Ginter",
          "url": "https://www.semanticscholar.org/author/1694491"
        },
        {
          "id": "1794453",
          "name": "Juhani Luotolahti",
          "url": "https://www.semanticscholar.org/author/1794453"
        },
        {
          "id": "1708916",
          "name": "Sampo Pyysalo",
          "url": "https://www.semanticscholar.org/author/1708916"
        },
        {
          "id": "1754497",
          "name": "Slav Petrov",
          "url": "https://www.semanticscholar.org/author/1754497"
        },
        {
          "id": "3046200",
          "name": "Martin Potthast",
          "url": "https://www.semanticscholar.org/author/3046200"
        },
        {
          "id": "50813669",
          "name": "Francis Tyers",
          "url": "https://www.semanticscholar.org/author/50813669"
        },
        {
          "id": "8634820",
          "name": "E. Badmaeva",
          "url": "https://www.semanticscholar.org/author/8634820"
        },
        {
          "id": "1399432033",
          "name": "Memduh Gökirmak",
          "url": "https://www.semanticscholar.org/author/1399432033"
        },
        {
          "id": "3045946",
          "name": "A. Nedoluzhko",
          "url": "https://www.semanticscholar.org/author/3045946"
        },
        {
          "id": "84182496",
          "name": "Silvie",
          "url": "https://www.semanticscholar.org/author/84182496"
        },
        {
          "id": "1399432025",
          "name": "Cinková",
          "url": "https://www.semanticscholar.org/author/1399432025"
        },
        {
          "id": "2489033",
          "name": "Jaroslava Hlavácová",
          "url": "https://www.semanticscholar.org/author/2489033"
        },
        {
          "id": "2371631",
          "name": "Václava Kettnerová",
          "url": "https://www.semanticscholar.org/author/2371631"
        },
        {
          "id": "3344673",
          "name": "Zdenka Uresová",
          "url": "https://www.semanticscholar.org/author/3344673"
        },
        {
          "id": "1776599",
          "name": "J. Kanerva",
          "url": "https://www.semanticscholar.org/author/1776599"
        },
        {
          "id": "46865075",
          "name": "S. Ojala",
          "url": "https://www.semanticscholar.org/author/46865075"
        },
        {
          "id": "2813341",
          "name": "Anna Missilä",
          "url": "https://www.semanticscholar.org/author/2813341"
        },
        {
          "id": "144783904",
          "name": "Christopher D. Manning",
          "url": "https://www.semanticscholar.org/author/144783904"
        },
        {
          "id": "77523655",
          "name": "Sébastian",
          "url": "https://www.semanticscholar.org/author/77523655"
        },
        {
          "id": "123348284",
          "name": "Schuster",
          "url": "https://www.semanticscholar.org/author/123348284"
        },
        {
          "id": "23481497",
          "name": "Siva Reddy",
          "url": "https://www.semanticscholar.org/author/23481497"
        },
        {
          "id": "3405525",
          "name": "Dima Taji",
          "url": "https://www.semanticscholar.org/author/3405525"
        },
        {
          "id": "1696645",
          "name": "Nizar Habash",
          "url": "https://www.semanticscholar.org/author/1696645"
        },
        {
          "id": "34885426",
          "name": "H. Leung",
          "url": "https://www.semanticscholar.org/author/34885426"
        },
        {
          "id": "2241127",
          "name": "Marie-Catherine de Marneffe",
          "url": "https://www.semanticscholar.org/author/2241127"
        },
        {
          "id": "2040952",
          "name": "M. Sanguinetti",
          "url": "https://www.semanticscholar.org/author/2040952"
        },
        {
          "id": "35184435",
          "name": "M. Simi",
          "url": "https://www.semanticscholar.org/author/35184435"
        },
        {
          "id": "152185235",
          "name": "Hiroshi",
          "url": "https://www.semanticscholar.org/author/152185235"
        },
        {
          "id": "103676048",
          "name": "Kanayama",
          "url": "https://www.semanticscholar.org/author/103676048"
        },
        {
          "id": "143893075",
          "name": "Valeria de Paiva",
          "url": "https://www.semanticscholar.org/author/143893075"
        },
        {
          "id": "22341186",
          "name": "Kira Droganova",
          "url": "https://www.semanticscholar.org/author/22341186"
        },
        {
          "id": "3017695",
          "name": "Héctor Martínez Alonso",
          "url": "https://www.semanticscholar.org/author/3017695"
        },
        {
          "id": "84169336",
          "name": "Çağrı",
          "url": "https://www.semanticscholar.org/author/84169336"
        },
        {
          "id": "1394430850",
          "name": "Çöltekin",
          "url": "https://www.semanticscholar.org/author/1394430850"
        },
        {
          "id": "3461272",
          "name": "Umut Sulubacak",
          "url": "https://www.semanticscholar.org/author/3461272"
        },
        {
          "id": "1781790",
          "name": "H. Uszkoreit",
          "url": "https://www.semanticscholar.org/author/1781790"
        },
        {
          "id": "22330068",
          "name": "Vivien Macketanz",
          "url": "https://www.semanticscholar.org/author/22330068"
        },
        {
          "id": "108189086",
          "name": "Aljoscha",
          "url": "https://www.semanticscholar.org/author/108189086"
        },
        {
          "id": "30096931",
          "name": "Burchardt",
          "url": "https://www.semanticscholar.org/author/30096931"
        },
        {
          "id": "32222085",
          "name": "K. Harris",
          "url": "https://www.semanticscholar.org/author/32222085"
        },
        {
          "id": "71792678",
          "name": "Katrin Marheinecke",
          "url": "https://www.semanticscholar.org/author/71792678"
        },
        {
          "id": "2156673",
          "name": "Georg Rehm",
          "url": "https://www.semanticscholar.org/author/2156673"
        },
        {
          "id": "73345985",
          "name": "Tolga Kayadelen",
          "url": "https://www.semanticscholar.org/author/73345985"
        },
        {
          "id": "144643789",
          "name": "Mohammed Attia",
          "url": "https://www.semanticscholar.org/author/144643789"
        },
        {
          "id": "35309245",
          "name": "A. Elkahky",
          "url": "https://www.semanticscholar.org/author/35309245"
        },
        {
          "id": "47055541",
          "name": "Zhuoran Yu",
          "url": "https://www.semanticscholar.org/author/47055541"
        },
        {
          "id": "2585932",
          "name": "Emily Pitler",
          "url": "https://www.semanticscholar.org/author/2585932"
        },
        {
          "id": "73041331",
          "name": "Saran Lertpradit",
          "url": "https://www.semanticscholar.org/author/73041331"
        },
        {
          "id": "3848524",
          "name": "M. Mandl",
          "url": "https://www.semanticscholar.org/author/3848524"
        },
        {
          "id": "49996036",
          "name": "J. Kirchner",
          "url": "https://www.semanticscholar.org/author/49996036"
        },
        {
          "id": "71067580",
          "name": "Héctor Fernández Alcalde",
          "url": "https://www.semanticscholar.org/author/71067580"
        },
        {
          "id": "72151653",
          "name": "Jana Strnadová",
          "url": "https://www.semanticscholar.org/author/72151653"
        },
        {
          "id": "66459409",
          "name": "Esha",
          "url": "https://www.semanticscholar.org/author/66459409"
        },
        {
          "id": "122737053",
          "name": "Banerjee",
          "url": "https://www.semanticscholar.org/author/122737053"
        },
        {
          "id": "3217460",
          "name": "R. Manurung",
          "url": "https://www.semanticscholar.org/author/3217460"
        },
        {
          "id": "50372685",
          "name": "A. Stella",
          "url": "https://www.semanticscholar.org/author/50372685"
        },
        {
          "id": "47788077",
          "name": "A. Shimada",
          "url": "https://www.semanticscholar.org/author/47788077"
        },
        {
          "id": "144816713",
          "name": "Sookyoung Kwak",
          "url": "https://www.semanticscholar.org/author/144816713"
        },
        {
          "id": "121499708",
          "name": "Gustavo Mendonça",
          "url": "https://www.semanticscholar.org/author/121499708"
        },
        {
          "id": "31682812",
          "name": "T. Lando",
          "url": "https://www.semanticscholar.org/author/31682812"
        },
        {
          "id": "2116910",
          "name": "Rattima Nitisaroj",
          "url": "https://www.semanticscholar.org/author/2116910"
        },
        {
          "id": "71003945",
          "name": "Josie Li",
          "url": "https://www.semanticscholar.org/author/71003945"
        }
      ],
      "year": 2017,
      "title": "CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies",
      "abstract": "The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.",
      "url": "https://www.semanticscholar.org/paper/9fbeebb98f479405dadd912e95796ba0256b74ac",
      "venue": "CoNLL Shared Task",
      "citationVelocity": 73,
      "influentialCitationCount": 23
    }
  },
  {
    "id": "0c133f79b23e8c680891d2e49a66f0e3d37f1466",
    "type": "paper",
    "attributes": {
      "s2Id": "0c133f79b23e8c680891d2e49a66f0e3d37f1466",
      "authors": [
        {
          "id": "49890124",
          "name": "Y. Zhang",
          "url": "https://www.semanticscholar.org/author/49890124"
        },
        {
          "id": "145045509",
          "name": "D. Weiss",
          "url": "https://www.semanticscholar.org/author/145045509"
        }
      ],
      "year": 2016,
      "title": "Stack-propagation: Improved Representation Learning for Syntax",
      "abstract": "Traditional syntax models typically leverage part-of-speech (POS) information by constructing features from hand-tuned templates. We demonstrate that a better approach is to utilize POS tags as a regularizer of learned representations. We propose a simple method for learning a stacked pipeline of models which we call “stack-propagation”. We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser. At test time, our parser does not require predicted POS tags. On 19 languages from the Universal Dependencies, our method is 1.3% (absolute) more accurate than a state-of-the-art graph-based approach and 2.7% more accurate than the most comparable greedy model.",
      "url": "https://www.semanticscholar.org/paper/0c133f79b23e8c680891d2e49a66f0e3d37f1466",
      "venue": "ACL",
      "citationVelocity": 16,
      "influentialCitationCount": 10
    }
  },
  {
    "id": "c34e41312b47f60986458759d5cc546c2b53f748",
    "type": "paper",
    "attributes": {
      "s2Id": "c34e41312b47f60986458759d5cc546c2b53f748",
      "authors": [
        {
          "id": null,
          "name": "Jie Zhou",
          "url": null
        },
        {
          "id": "145738410",
          "name": "W. Xu",
          "url": "https://www.semanticscholar.org/author/145738410"
        }
      ],
      "year": 2015,
      "title": "End-to-end learning of semantic role labeling using recurrent neural networks",
      "abstract": "Semantic role labeling (SRL) is one of the basic natural language processing (NLP) problems. To this date, most of the successful SRL systems were built on top of some form of parsing results (Koomen et al., 2005; Palmer et al., 2010; Pradhan et al., 2013), where pre-defined feature templates over the syntactic structure are used. The attempts of building an end-to-end SRL learning system without using parsing were less successful (Collobert et al., 2011). In this work, we propose to use deep bi-directional recurrent network as an end-to-end system for SRL. We take only original text information as input feature, without using any syntactic knowledge. The proposed algorithm for semantic role labeling was mainly evaluated on CoNLL-2005 shared task and achieved F1 score of 81.07. This result outperforms the previous state-of-the-art system from the combination of different parsing trees or models. We also obtained the same conclusion with F1 = 81.27 on CoNLL2012 shared task. As a result of simplicity, our model is also computationally efficient that the parsing speed is 6.7k tokens per second. Our analysis shows that our model is better at handling longer sentences than traditional models. And the latent variables of our model implicitly capture the syntactic structure of a sentence.",
      "url": "https://www.semanticscholar.org/paper/c34e41312b47f60986458759d5cc546c2b53f748",
      "venue": "ACL",
      "citationVelocity": 57,
      "influentialCitationCount": 17
    }
  }
]
